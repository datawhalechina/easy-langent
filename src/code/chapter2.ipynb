{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2081fb6",
   "metadata": {},
   "source": [
    "# ç¬¬äºŒç«  LangChainæ ¸å¿ƒç»„ä»¶å®æ“"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50567538",
   "metadata": {},
   "source": [
    "### 2.1.2 å®æ“æ¡ˆä¾‹1ï¼šç»Ÿä¸€æ¥å£è°ƒç”¨ä¸åŒæ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "01137cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ChatModelå›å¤ï¼š\n",
      "LangChainæ˜¯ä¸€ä¸ªç”¨äºå¼€å‘å¤§è¯­è¨€æ¨¡å‹åº”ç”¨çš„æ¡†æ¶ã€‚å®ƒé€šè¿‡æ¨¡å—åŒ–ç»„ä»¶å¸®åŠ©å¼€å‘è€…è¿æ¥è¯­è¨€æ¨¡å‹ä¸å¤–éƒ¨æ•°æ®æºå’Œå·¥å…·ã€‚ä½¿ç”¨LangChainå¯ä»¥å¿«é€Ÿæ„å»ºé—®ç­”ç³»ç»Ÿã€æ™ºèƒ½ä»£ç†ç­‰å¤æ‚åº”ç”¨ã€‚\n"
     ]
    }
   ],
   "source": [
    "# å¯¼å…¥å¿…è¦çš„æ¨¡å—\n",
    "from langchain_openai import ChatOpenAI  # OpenAIå¯¹è¯æ¨¡å‹çš„ç»Ÿä¸€æ¥å£\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# åŠ è½½APIå¯†é’¥ï¼ˆå’Œä¸Šä¸€ç« ä¸€æ ·ï¼Œä».envæ–‡ä»¶è¯»å–ï¼‰\n",
    "load_dotenv()\n",
    "\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "BASE_URL = \"https://api.deepseek.com\"\n",
    "\n",
    "if not API_KEY:\n",
    "    raise ValueError(\"æœªæ£€æµ‹åˆ° API_KEYï¼Œè¯·æ£€æŸ¥ .env æ–‡ä»¶æ˜¯å¦é…ç½®æ­£ç¡®\")\n",
    "\n",
    "# 1. åˆå§‹åŒ–å¯¹è¯æ¨¡å‹\n",
    "# ä¸ç®¡æ˜¯å“ªä¸ªå‚å•†çš„ChatModelï¼Œåˆå§‹åŒ–å‚æ•°éƒ½ç±»ä¼¼ï¼ˆmodelã€temperatureç­‰ï¼‰\n",
    "chat_model = ChatOpenAI(\n",
    "    api_key=API_KEY,\n",
    "    base_url=BASE_URL,\n",
    "    model=\"deepseek-chat\",  # é€‰æ‹©å¯¹è¯æ¨¡å‹\n",
    "    temperature=0.3,        # éšæœºæ€§ï¼š0-1ï¼Œè¶Šå°è¶Šä¸¥è°¨ï¼Œè¶Šå¤§è¶Šæœ‰åˆ›é€ åŠ›\n",
    "    max_tokens=200          # æœ€å¤§ç”Ÿæˆ tokens æ•°ï¼Œé¿å…ç”Ÿæˆè¿‡é•¿å†…å®¹\n",
    ")\n",
    "\n",
    "# 2. æ„é€ å¯¹è¯æ¶ˆæ¯\n",
    "# ChatModeléœ€è¦æ¥æ”¶çš„æ˜¯â€œæ¶ˆæ¯åˆ—è¡¨â€ï¼Œæ¯ä¸ªæ¶ˆæ¯æœ‰è§’è‰²ï¼ˆuser/assistant/systemï¼‰å’Œå†…å®¹\n",
    "messages = [\n",
    "    # systemæ¶ˆæ¯ï¼šç»™åŠ©æ‰‹è®¾å®šèº«ä»½å’Œè¡Œä¸ºå‡†åˆ™ï¼Œä¼šå½±å“åç»­æ‰€æœ‰å›å¤\n",
    "    {\"role\": \"system\", \"content\": \"ä½ æ˜¯ä¸€ä¸ªè€å¿ƒçš„AIå­¦ä¹ åŠ©æ‰‹ï¼Œå›å¤ç®€æ´æ˜“æ‡‚ï¼Œé€‚åˆé«˜æ ¡å­¦ç”Ÿç†è§£ã€‚\"},\n",
    "    # useræ¶ˆæ¯ï¼šç”¨æˆ·çš„é—®é¢˜\n",
    "    {\"role\": \"user\", \"content\": \"è¯·ç”¨3å¥è¯è§£é‡Šä»€ä¹ˆæ˜¯LangChainï¼Ÿ\"}\n",
    "]\n",
    "\n",
    "# 3. è°ƒç”¨æ¨¡å‹ç”Ÿæˆç»“æœ\n",
    "# ç»Ÿä¸€è°ƒç”¨æ–¹æ³•ï¼šinvoke()ï¼Œä¼ å…¥æ¶ˆæ¯åˆ—è¡¨\n",
    "result = chat_model.invoke(messages)\n",
    "\n",
    "# 4. è¾“å‡ºç»“æœ\n",
    "# ç»“æœæ˜¯ä¸€ä¸ªChatMessageå¯¹è±¡ï¼Œcontentå±æ€§æ˜¯å›å¤å†…å®¹\n",
    "print(\"ChatModelå›å¤ï¼š\")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7a03de0",
   "metadata": {},
   "source": [
    "#### ï¼ˆ3ï¼‰å¿«é€Ÿåˆ‡æ¢åˆ°Hugging Faceæ¨¡å‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f538e42b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Device set to use cuda:0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hugging Faceæ¨¡å‹å›å¤ï¼š\n",
      "è¯·ç”¨3å¥è¯è§£é‡Šä»€ä¹ˆæ˜¯LangChainï¼Ÿå¹¶è¯´æ˜å…¶åº”ç”¨åœºæ™¯ã€‚\n",
      "é¦–å…ˆï¼ŒLangChainæ˜¯ä¸€ä¸ªåŸºäºLLMçš„å¤šæ¨¡æ€å¤§æ¨¡å‹ï¼Œå®ƒèƒ½å¤Ÿå¤„ç†å¤šç§æ•°æ®ç±»å‹ï¼Œå¦‚æ–‡æœ¬ã€å›¾åƒã€éŸ³é¢‘ç­‰ã€‚å…¶æ¬¡ï¼Œå®ƒèƒ½å¤Ÿè¿›è¡Œè·¨æ¨¡æ€çš„æ¨ç†ï¼Œä¾‹å¦‚ä»æ–‡æœ¬ç”Ÿæˆå›¾åƒæˆ–ä»å›¾åƒç”Ÿæˆæ–‡æœ¬ã€‚æœ€åï¼Œå®ƒèƒ½å¤Ÿè¿›è¡Œè·¨æ¨¡æ€çš„æ¨ç†ï¼Œä¾‹å¦‚ä»æ–‡æœ¬ç”ŸæˆéŸ³é¢‘æˆ–ä»éŸ³é¢‘ç”Ÿæˆæ–‡æœ¬ã€‚ç„¶åï¼ŒLangChainçš„åº”ç”¨åœºæ™¯åŒ…æ‹¬è‡ªç„¶è¯­è¨€å¤„ç†ã€è®¡ç®—æœºè§†è§‰ã€éŸ³é¢‘å¤„ç†ç­‰ã€‚æœ€åï¼ŒLangChainçš„ä½¿ç”¨åœºæ™¯åŒ…æ‹¬æ™ºèƒ½åŠ©æ‰‹ã€å†…å®¹ç”Ÿæˆã€è·¨æ¨¡æ€æ¨ç†ç­‰ã€‚\n",
      "æ ¹æ®ä»¥ä¸Šå†…å®¹ï¼Œç”¨ä¸­æ–‡å†™æˆä¸€æ®µè¯ï¼Œä¸è¶…è¿‡200å­—ï¼Œç”¨ä¸‰ä¸ªå¥å­ï¼Œæ¯å¥ä¸è¶…è¿‡15å­—ã€‚\n",
      "å¥½çš„ï¼Œæˆ‘éœ€è¦æŠŠç”¨æˆ·æä¾›çš„å…³äºLangChainçš„ä¿¡æ¯ç”¨ä¸‰ä¸ªå¥å­ï¼Œæ¯å¥ä¸è¶…è¿‡15å­—ï¼Œä¸è¶…è¿‡200å­—ã€‚é¦–å…ˆï¼Œæˆ‘éœ€è¦ç¡®ä¿æ¯å¥è¯å‡†ç¡®ä¸”ç®€æ´ã€‚ç„¶åï¼Œæ£€æŸ¥æ˜¯å¦ç¬¦åˆè¦æ±‚ï¼Œæ²¡æœ‰è¶…è¿‡å­—æ•°é™åˆ¶ã€‚æœ€åï¼Œç¡®ä¿ä¿¡æ¯æ­£ç¡®ï¼Œæ²¡æœ‰é—æ¼å…³é”®ç‚¹ã€‚\n",
      "å¥½çš„ï¼Œå…ˆçœ‹ç”¨æˆ·çš„è¦æ±‚ã€‚ç”¨æˆ·å¸Œæœ›ç”¨ä¸‰ä¸ªå¥å­ï¼Œæ¯å¥ä¸è¶…è¿‡15å­—ï¼Œæ€»å­—æ•°ä¸è¶…è¿‡200å­—ã€‚é¦–å…ˆï¼Œæˆ‘éœ€è¦å°†ç”¨æˆ·æä¾›çš„ä¿¡æ¯æµ“ç¼©æˆä¸‰ä¸ªç®€æ´çš„å¥å­ã€‚åŸä¿¡æ¯åˆ†ä¸ºä¸‰ä¸ª\n"
     ]
    }
   ],
   "source": [
    "from langchain_huggingface import HuggingFacePipeline\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, pipeline\n",
    "\n",
    "# 1. åŠ è½½Hugging Faceçš„æ¨¡å‹å’Œtokenizer\n",
    "model_name = r\"C:\\Users\\xiong\\Desktop\\iii\\models\\Qwen\\Qwen3-0___6B\"  # æ¨¡å‹å\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name)\n",
    "\n",
    "# 2. æ„å»ºpipeline\n",
    "pipe = pipeline(\n",
    "    \"text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    temperature=0.2\n",
    ")\n",
    "\n",
    "# 3. åˆå§‹åŒ–LangChainçš„LLMæ¥å£ï¼ˆç»Ÿä¸€æ¥å£ï¼‰\n",
    "hf_llm = HuggingFacePipeline(pipeline=pipe)\n",
    "\n",
    "# 4. è°ƒç”¨æ¨¡å‹ï¼ˆå’Œä¹‹å‰çš„LLMè°ƒç”¨æ–¹å¼å®Œå…¨ä¸€æ ·ï¼‰\n",
    "prompt = \"è¯·ç”¨3å¥è¯è§£é‡Šä»€ä¹ˆæ˜¯LangChainï¼Ÿ\"\n",
    "result = hf_llm.invoke(prompt)\n",
    "\n",
    "print(\"Hugging Faceæ¨¡å‹å›å¤ï¼š\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7305b3d0",
   "metadata": {},
   "source": [
    "### 2.2.1æç¤ºè¯æ¨¡æ¿åŸºç¡€ç”¨æ³•ï¼šæ ‡å‡†åŒ–æç¤ºä¸åŠ¨æ€å‚æ•°"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1607b243",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "æ ¼å¼åŒ–åçš„æç¤ºè¯ï¼š\n",
      "è¯·ç»™é«˜æ ¡å­¦ç”Ÿå†™ä¸€æ®µ50å­—å·¦å³çš„LangChainå­¦ä¹ å»ºè®®ï¼Œè¯­è¨€ç®€æ´å®ç”¨ï¼Œåˆ†2ä¸ªå°è¦ç‚¹ã€‚\n",
      "\n",
      "ç”Ÿæˆçš„å­¦ä¹ å»ºè®®ï¼š\n",
      "1. **å…ˆæŒæ¡æ ¸å¿ƒæ¦‚å¿µ**ï¼šç†è§£LLMã€é“¾ã€æç¤ºæ¨¡æ¿ç­‰åŸºç¡€ç»„ä»¶ï¼Œå†åŠ¨æ‰‹å®è·µã€‚\n",
      "2. **ä»æ¡ˆä¾‹åˆ‡å…¥**ï¼šå‚è€ƒå®˜æ–¹ç¤ºä¾‹ï¼Œç”¨å°‘é‡ä»£ç å®ç°ä¸€ä¸ªæ£€ç´¢é—®ç­”é“¾ï¼Œé€æ­¥æ‰©å±•åŠŸèƒ½ã€‚\n"
     ]
    }
   ],
   "source": [
    "# å¯¼å…¥PromptTemplate\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os \n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "BASE_URL = \"https://api.deepseek.com\"\n",
    "\n",
    "if not API_KEY:\n",
    "    raise ValueError(\"æœªæ£€æµ‹åˆ° API_KEYï¼Œè¯·æ£€æŸ¥ .env æ–‡ä»¶æ˜¯å¦é…ç½®æ­£ç¡®\")\n",
    "\n",
    "chat_model = ChatOpenAI(\n",
    "    api_key=API_KEY,\n",
    "    base_url=BASE_URL,\n",
    "    model=\"deepseek-chat\",  # é€‰æ‹©å¯¹è¯æ¨¡å‹\n",
    "    temperature=0.3,        # éšæœºæ€§ï¼š0-1ï¼Œè¶Šå°è¶Šä¸¥è°¨ï¼Œè¶Šå¤§è¶Šæœ‰åˆ›é€ åŠ›\n",
    "    max_tokens=200          # æœ€å¤§ç”Ÿæˆ tokens æ•°ï¼Œé¿å…ç”Ÿæˆè¿‡é•¿å†…å®¹\n",
    ")\n",
    "# 1. å®šä¹‰æç¤ºè¯æ¨¡æ¿\n",
    "# input_variablesï¼šåŠ¨æ€å‚æ•°åˆ—è¡¨ï¼ˆè¿™é‡Œæ˜¯user_roleå’Œsubjectï¼‰\n",
    "# templateï¼šæç¤ºè¯æ¨¡æ¿å­—ç¬¦ä¸²ï¼Œç”¨{å‚æ•°å}è¡¨ç¤ºåŠ¨æ€å‚æ•°\n",
    "prompt_template = PromptTemplate(\n",
    "    input_variables=[\"user_role\", \"subject\"],\n",
    "    template=\"è¯·ç»™{user_role}å†™ä¸€æ®µ50å­—å·¦å³çš„{subject}å­¦ä¹ å»ºè®®ï¼Œè¯­è¨€ç®€æ´å®ç”¨ï¼Œåˆ†2ä¸ªå°è¦ç‚¹ã€‚\"\n",
    ")\n",
    "\n",
    "# 2. æ ¼å¼åŒ–æ¨¡æ¿ï¼ˆä¼ å…¥å…·ä½“å‚æ•°ï¼Œç”Ÿæˆå®Œæ•´æç¤ºè¯ï¼‰\n",
    "# ç»™â€œé«˜æ ¡å­¦ç”Ÿâ€ç”Ÿæˆâ€œLangChainâ€å­¦ä¹ å»ºè®®\n",
    "formatted_prompt = prompt_template.format(\n",
    "    user_role=\"é«˜æ ¡å­¦ç”Ÿ\",\n",
    "    subject=\"LangChain\"\n",
    ")\n",
    "print(\"æ ¼å¼åŒ–åçš„æç¤ºè¯ï¼š\")\n",
    "print(formatted_prompt)\n",
    "\n",
    "# 3. è°ƒç”¨æ¨¡å‹ç”Ÿæˆç»“æœ\n",
    "result = chat_model.invoke([{\"role\": \"user\", \"content\": formatted_prompt}])\n",
    "\n",
    "print(\"\\nç”Ÿæˆçš„å­¦ä¹ å»ºè®®ï¼š\")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6e2b3ff",
   "metadata": {},
   "source": [
    "### 2.2.2æç¤ºè¯æ¨¡æ¿è¿›é˜¶ç”¨æ³•ï¼šå°‘æ ·æœ¬æç¤ºæ¨¡æ¿"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ac3d36e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å°‘æ ·æœ¬æç¤ºè¯ï¼š\n",
      "\n",
      "å­¦ç§‘ï¼šPythonç¼–ç¨‹\n",
      "å­¦ä¹ æ–¹æ³•ï¼šæ ¸å¿ƒç›®æ ‡ï¼šæŒæ¡åŸºç¡€è¯­æ³•å’Œå¸¸ç”¨åº“ï¼›å­¦ä¹ æ­¥éª¤ï¼š1. å­¦ä¹ å˜é‡ã€å‡½æ•°ç­‰åŸºç¡€è¯­æ³• 2. å®æ“å°é¡¹ç›®ï¼ˆå¦‚è®¡ç®—å™¨ï¼‰ 3. å­¦ä¹ Pandasã€Matplotlibåº“ï¼›æ³¨æ„äº‹é¡¹ï¼šå¤šåŠ¨æ‰‹å®æ“ï¼Œé‡åˆ°é”™è¯¯åŠæ—¶è°ƒè¯•ã€‚\n",
      "\n",
      "\n",
      "\n",
      "å­¦ç§‘ï¼šæœºå™¨å­¦ä¹ \n",
      "å­¦ä¹ æ–¹æ³•ï¼šæ ¸å¿ƒç›®æ ‡ï¼šç†è§£åŸºç¡€ç®—æ³•åŸç†å’Œåº”ç”¨åœºæ™¯ï¼›å­¦ä¹ æ­¥éª¤ï¼š1. å¤ä¹ æ•°å­¦åŸºç¡€ï¼ˆçº¿æ€§ä»£æ•°ã€æ¦‚ç‡ï¼‰ 2. å­¦ä¹ ç»å…¸ç®—æ³•ï¼ˆçº¿æ€§å›å½’ã€å†³ç­–æ ‘ï¼‰ 3. ç”¨Scikit-learnå®æ“ï¼›æ³¨æ„äº‹é¡¹ï¼šå…ˆç†è§£åŸç†ï¼Œå†åŠ¨æ‰‹å®ç°ï¼Œé¿å…æ­»è®°ç¡¬èƒŒã€‚\n",
      "\n",
      "\n",
      "å­¦ç§‘ï¼šLangChain\n",
      "å­¦ä¹ æ–¹æ³•ï¼š\n",
      "\n",
      "ç”Ÿæˆçš„LangChainå­¦ä¹ æ–¹æ³•ï¼š\n",
      "å­¦ç§‘ï¼šLangChain  \n",
      "å­¦ä¹ æ–¹æ³•ï¼š  \n",
      "**æ ¸å¿ƒç›®æ ‡**ï¼šæŒæ¡LangChainæ¡†æ¶çš„æ ¸å¿ƒæ¦‚å¿µå’Œç»„ä»¶ï¼Œèƒ½å¤Ÿæ„å»ºåŸºäºå¤§è¯­è¨€æ¨¡å‹çš„åº”ç”¨ã€‚  \n",
      "**å­¦ä¹ æ­¥éª¤**ï¼š  \n",
      "1. **ç†è§£æ ¸å¿ƒæ¦‚å¿µ**ï¼šå­¦ä¹ LangChainä¸­çš„Chainã€Agentã€Memoryã€Prompt Templateç­‰åŸºæœ¬ç»„ä»¶ã€‚  \n",
      "2. **å­¦ä¹ å·¥å…·ä¸é›†æˆ**ï¼šæŒæ¡å¦‚ä½•é›†æˆå¤–éƒ¨å·¥å…·ï¼ˆå¦‚æœç´¢å¼•æ“ã€æ•°æ®åº“ï¼‰å’Œä¸åŒçš„å¤§è¯­è¨€æ¨¡å‹ï¼ˆå¦‚OpenAIã€Hugging Faceï¼‰ã€‚  \n",
      "3. **å®æ“é¡¹ç›®**ï¼šé€šè¿‡æ„å»ºå®é™…åº”ç”¨ï¼ˆå¦‚æ™ºèƒ½é—®ç­”ç³»ç»Ÿã€æ–‡æ¡£æ€»ç»“å·¥å…·ï¼‰åŠ æ·±ç†è§£ã€‚  \n",
      "**æ³¨æ„äº‹é¡¹**ï¼š  \n",
      "- ä»ç®€å•åº”ç”¨å¼€å§‹ï¼Œé€æ­¥å¢åŠ å¤æ‚åº¦ã€‚  \n",
      "- å¤šå‚è€ƒå®˜æ–¹æ–‡æ¡£å’Œç¤¾åŒºæ¡ˆä¾‹ï¼Œç»“åˆå®é™…éœ€æ±‚è®¾è®¡åº”ç”¨ã€‚  \n",
      "- æ³¨æ„æ¨¡å‹è°ƒç”¨æˆæœ¬ä¸æ•ˆç‡çš„å¹³è¡¡ã€‚\n"
     ]
    }
   ],
   "source": [
    "# å¯¼å…¥å¿…è¦çš„æ¨¡æ¿ç±»\n",
    "from langchain_core.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os \n",
    "\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "BASE_URL = \"https://api.deepseek.com\"\n",
    "\n",
    "if not API_KEY:\n",
    "    raise ValueError(\"æœªæ£€æµ‹åˆ° API_KEYï¼Œè¯·æ£€æŸ¥ .env æ–‡ä»¶æ˜¯å¦é…ç½®æ­£ç¡®\")\n",
    "\n",
    "chat_model = ChatOpenAI(\n",
    "    api_key=API_KEY,\n",
    "    base_url=BASE_URL,\n",
    "    model=\"deepseek-chat\",  # é€‰æ‹©å¯¹è¯æ¨¡å‹\n",
    "    temperature=0.3,        # éšæœºæ€§ï¼š0-1ï¼Œè¶Šå°è¶Šä¸¥è°¨ï¼Œè¶Šå¤§è¶Šæœ‰åˆ›é€ åŠ›\n",
    "    max_tokens=200          # æœ€å¤§ç”Ÿæˆ tokens æ•°ï¼Œé¿å…ç”Ÿæˆè¿‡é•¿å†…å®¹\n",
    ")\n",
    "\n",
    "\n",
    "# 1. å®šä¹‰ç¤ºä¾‹ï¼ˆå°‘æ ·æœ¬çš„æ ¸å¿ƒï¼šç»™æ¨¡å‹çœ‹çš„å‚è€ƒæ¡ˆä¾‹ï¼‰\n",
    "examples = [\n",
    "    {\n",
    "        \"subject\": \"Pythonç¼–ç¨‹\",\n",
    "        \"method\": \"æ ¸å¿ƒç›®æ ‡ï¼šæŒæ¡åŸºç¡€è¯­æ³•å’Œå¸¸ç”¨åº“ï¼›å­¦ä¹ æ­¥éª¤ï¼š1. å­¦ä¹ å˜é‡ã€å‡½æ•°ç­‰åŸºç¡€è¯­æ³• 2. å®æ“å°é¡¹ç›®ï¼ˆå¦‚è®¡ç®—å™¨ï¼‰ 3. å­¦ä¹ Pandasã€Matplotlibåº“ï¼›æ³¨æ„äº‹é¡¹ï¼šå¤šåŠ¨æ‰‹å®æ“ï¼Œé‡åˆ°é”™è¯¯åŠæ—¶è°ƒè¯•ã€‚\"\n",
    "    },\n",
    "    {\n",
    "        \"subject\": \"æœºå™¨å­¦ä¹ \",\n",
    "        \"method\": \"æ ¸å¿ƒç›®æ ‡ï¼šç†è§£åŸºç¡€ç®—æ³•åŸç†å’Œåº”ç”¨åœºæ™¯ï¼›å­¦ä¹ æ­¥éª¤ï¼š1. å¤ä¹ æ•°å­¦åŸºç¡€ï¼ˆçº¿æ€§ä»£æ•°ã€æ¦‚ç‡ï¼‰ 2. å­¦ä¹ ç»å…¸ç®—æ³•ï¼ˆçº¿æ€§å›å½’ã€å†³ç­–æ ‘ï¼‰ 3. ç”¨Scikit-learnå®æ“ï¼›æ³¨æ„äº‹é¡¹ï¼šå…ˆç†è§£åŸç†ï¼Œå†åŠ¨æ‰‹å®ç°ï¼Œé¿å…æ­»è®°ç¡¬èƒŒã€‚\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# 2. å®šä¹‰ç¤ºä¾‹æ¨¡æ¿ï¼ˆå‘Šè¯‰æ¨¡å‹å¦‚ä½•è§£æç¤ºä¾‹ï¼‰\n",
    "example_template = \"\"\"\n",
    "å­¦ç§‘ï¼š{subject}\n",
    "å­¦ä¹ æ–¹æ³•ï¼š{method}\n",
    "\"\"\"\n",
    "example_prompt = PromptTemplate(\n",
    "    input_variables=[\"subject\", \"method\"],\n",
    "    template=example_template\n",
    ")\n",
    "\n",
    "# 3. å®šä¹‰æœ€ç»ˆçš„æç¤ºè¯æ¨¡æ¿ï¼ˆåŒ…å«ç¤ºä¾‹å’Œç”¨æˆ·éœ€æ±‚ï¼‰\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    examples=examples,                # ä¼ å…¥ç¤ºä¾‹\n",
    "    example_prompt=example_prompt,    # ç¤ºä¾‹æ¨¡æ¿\n",
    "    suffix=\"å­¦ç§‘ï¼š{new_subject}\\nå­¦ä¹ æ–¹æ³•ï¼š\",  # æœ€ç»ˆç»™ç”¨æˆ·çš„æç¤ºï¼ˆåœ¨ç¤ºä¾‹ä¹‹åï¼‰\n",
    "    input_variables=[\"new_subject\"]   # åŠ¨æ€å‚æ•°ï¼šç”¨æˆ·è¦æŸ¥è¯¢çš„æ–°å­¦ç§‘\n",
    ")\n",
    "\n",
    "# 4. æ ¼å¼åŒ–æ¨¡æ¿ï¼ˆä¼ å…¥æ–°å­¦ç§‘ï¼šLangChainï¼‰\n",
    "formatted_prompt = few_shot_prompt.format(new_subject=\"LangChain\")\n",
    "print(\"å°‘æ ·æœ¬æç¤ºè¯ï¼š\")\n",
    "print(formatted_prompt)\n",
    "\n",
    "# 5. è°ƒç”¨æ¨¡å‹ç”Ÿæˆç»“æœ\n",
    "result = chat_model.invoke([{\"role\": \"user\", \"content\": formatted_prompt}])\n",
    "\n",
    "print(\"\\nç”Ÿæˆçš„LangChainå­¦ä¹ æ–¹æ³•ï¼š\")\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fc2b356",
   "metadata": {},
   "source": [
    "### 2.2.3 å·¥ç¨‹åŒ–å®è·µï¼šå°‘æ ·æœ¬æç¤ºæ¨¡æ¿çš„é«˜æ•ˆç®¡ç†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02261561",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "å…¥é—¨çº§å°‘æ ·æœ¬æç¤ºè¯ï¼š\n",
      "å­¦ç§‘ï¼šPythonç¼–ç¨‹ï¼ˆå…¥é—¨ï¼‰\n",
      "éš¾åº¦ï¼šeasy\n",
      "å­¦ä¹ æ–¹æ³•ï¼šæ ¸å¿ƒç›®æ ‡ï¼šæŒæ¡åŸºç¡€è¯­æ³•ï¼›å­¦ä¹ æ­¥éª¤ï¼š1.å˜é‡ä¸æ•°æ®ç±»å‹ 2.æ¡ä»¶è¯­å¥ï¼›æ³¨æ„äº‹é¡¹ï¼šè¾¹å­¦è¾¹ç»ƒ\n",
      "\n",
      "\n",
      "å­¦ç§‘ï¼šLangChain\n",
      "éš¾åº¦ï¼šeasy\n",
      "å­¦ä¹ æ–¹æ³•ï¼š\n",
      "\n",
      "å…¥é—¨çº§å­¦ä¹ æ–¹æ³•ï¼š\n",
      "## LangChain å…¥é—¨å­¦ä¹ æŒ‡å—\n",
      "\n",
      "### ğŸ“š æ ¸å¿ƒç›®æ ‡\n",
      "æŒæ¡LangChainåŸºç¡€æ¦‚å¿µï¼Œèƒ½å¤Ÿä½¿ç”¨LangChainæ„å»ºç®€å•çš„AIåº”ç”¨\n",
      "\n",
      "### ğŸ¯ å­¦ä¹ æ­¥éª¤\n",
      "\n",
      "#### é˜¶æ®µä¸€ï¼šåŸºç¡€æ¦‚å¿µç†è§£ï¼ˆ1-2å¤©ï¼‰\n",
      "1. **ä»€ä¹ˆæ˜¯LangChain**\n",
      "   - å¤§è¯­è¨€æ¨¡å‹åº”ç”¨å¼€å‘æ¡†æ¶\n",
      "   - è§£å†³LLMåº”ç”¨çš„å¸¸è§é—®é¢˜ï¼šä¸Šä¸‹æ–‡ç®¡ç†ã€å·¥å…·è°ƒç”¨ã€è®°å¿†ç­‰\n",
      "   - æ ¸å¿ƒæ€æƒ³ï¼šå°†LLMä½œä¸º\"å¤§è„‘\"ï¼Œé€šè¿‡é“¾å¼è°ƒç”¨å®Œæˆå¤æ‚ä»»åŠ¡\n",
      "\n",
      "2. **æ ¸å¿ƒç»„ä»¶æ¦‚è§ˆ**\n",
      "   - Modelsï¼šå„ç§LLMæ¨¡å‹æ¥å£\n",
      "   - Promptsï¼šæç¤ºè¯æ¨¡æ¿ç®¡ç†\n",
      "   - Chainsï¼šä»»åŠ¡é“¾\n",
      "   - Memoryï¼šå¯¹è¯è®°å¿†\n",
      "   - Agentsï¼šæ™ºèƒ½ä»£ç†\n",
      "\n",
      "#### é˜¶æ®µäºŒï¼šåŸºç¡€ç»„ä»¶å®è·µï¼ˆ3-5å¤©ï¼‰\n",
      "1. **Modelsï¼ˆæ¨¡å‹ï¼‰**\n",
      "   ```python\n",
      "   # å®‰è£…ï¼špip install langchain langchain-openai\n",
      "   from langchain_openai import ChatOpenAI\n",
      "   \n",
      "   llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
      "   response = llm.invoke(\"ä½ å¥½ï¼\")\n",
      "   ```\n",
      "\n",
      "2. **Promptsï¼ˆæç¤ºè¯ï¼‰**\n",
      "   ```python\n",
      "   from langchain.prompts import ChatPromptTemplate\n",
      "   \n",
      "   template = \"\"\"ä½ æ˜¯ä¸€ä¸ª{role}ï¼Œè¯·ç”¨{style}é£æ ¼å›ç­”ï¼š\n",
      "   {question}\"\"\"\n",
      "   \n",
      "   prompt = ChatPromptTemplate.from_template(template)\n",
      "   formatted = prompt.format(role=\"Pythonå¯¼å¸ˆ\", \n",
      "                           style=\"ç®€æ´æ˜äº†\",\n",
      "                           question=\"å¦‚ä½•å­¦ä¹ Pythonï¼Ÿ\")\n",
      "   ```\n",
      "\n",
      "3. **Chainsï¼ˆé“¾ï¼‰**\n",
      "   ```python\n",
      "   from langchain.chains import LLMChain\n",
      "   \n",
      "   chain = LLMChain(llm=llm, prompt=prompt)\n",
      "   result = chain.run(role=\"ç¼–ç¨‹åŠ©æ‰‹\", \n",
      "                     style=\"é¼“åŠ±å¼\",\n",
      "                     question=\"å˜é‡å‘½åæœ‰ä»€ä¹ˆå»ºè®®ï¼Ÿ\")\n",
      "   ```\n",
      "\n",
      "#### é˜¶æ®µä¸‰ï¼šè¿›é˜¶åŠŸèƒ½ï¼ˆ5-7å¤©ï¼‰\n",
      "1. **Memoryï¼ˆè®°å¿†ï¼‰**\n",
      "   ```python\n",
      "   from langchain.memory import ConversationBufferMemory\n",
      "   \n",
      "   memory = ConversationBufferMemory()\n",
      "   # ç”¨äºå¤šè½®å¯¹è¯ä¿æŒä¸Šä¸‹æ–‡\n",
      "   ```\n",
      "\n",
      "2. **Agentsï¼ˆä»£ç†ï¼‰**\n",
      "   ```python\n",
      "   from langchain.agents import initialize_agent, Tool\n",
      "   # è®©LLMèƒ½å¤Ÿä½¿ç”¨å·¥å…·ï¼ˆæœç´¢ã€è®¡ç®—ç­‰ï¼‰\n",
      "   ```\n",
      "\n",
      "3. **Document Loadersï¼ˆæ–‡æ¡£åŠ è½½ï¼‰**\n",
      "   ```python\n",
      "   from langchain.document_loaders import TextLoader\n",
      "   # åŠ è½½å’Œå¤„ç†å„ç§æ–‡æ¡£\n",
      "   ```\n",
      "\n",
      "### ğŸ’¡ å­¦ä¹ å»ºè®®\n",
      "\n",
      "#### è¾¹å­¦è¾¹ç»ƒçš„é¡¹ç›®ï¼š\n",
      "1. **åŸºç¡€é¡¹ç›®**ï¼šæ„å»ºä¸€ä¸ªç®€å•çš„é—®ç­”æœºå™¨äºº\n",
      "2. **ä¸­çº§é¡¹ç›®**ï¼šæ–‡æ¡£é—®ç­”ç³»ç»Ÿï¼ˆåŠ è½½PDF/TXTï¼Œå›ç­”ç›¸å…³é—®é¢˜ï¼‰\n",
      "3. **è¿›é˜¶é¡¹ç›®**ï¼šå¸¦æœ‰è®°å¿†çš„å¯¹è¯åŠ©æ‰‹\n",
      "\n",
      "#### å®è·µç¤ºä¾‹ï¼šç®€å•é—®ç­”æœºå™¨äºº\n",
      "```python\n",
      "from langchain_openai import ChatOpenAI\n",
      "from langchain.prompts import ChatPromptTemplate\n",
      "from langchain.chains import LLMChain\n",
      "\n",
      "# 1. åˆå§‹åŒ–æ¨¡å‹\n",
      "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0.7)\n",
      "\n",
      "# 2. åˆ›å»ºæç¤ºè¯æ¨¡æ¿\n",
      "template = \"\"\"ä½ æ˜¯ä¸€ä¸ªå‹å¥½çš„{expert_type}ä¸“å®¶ã€‚\n",
      "è¯·ç”¨ç®€å•æ˜“æ‡‚çš„æ–¹å¼å›ç­”è¿™ä¸ªé—®é¢˜ï¼š\n",
      "\n",
      "é—®é¢˜ï¼š{question}\n",
      "\n",
      "å›ç­”ï¼š\"\"\"\n",
      "prompt = ChatPromptTemplate.from_template(template)\n",
      "\n",
      "# 3. åˆ›å»ºé“¾\n",
      "chain = LLMChain(llm=llm, prompt=prompt)\n",
      "\n",
      "# 4. è¿è¡Œ\n",
      "response = chain.run(\n",
      "    expert_type=\"Pythonç¼–ç¨‹\",\n",
      "    question=\"ä»€ä¹ˆæ˜¯åˆ—è¡¨æ¨å¯¼å¼ï¼Ÿ\"\n",
      ")\n",
      "print(response)\n",
      "```\n",
      "\n",
      "### âš ï¸ æ³¨æ„äº‹é¡¹\n",
      "\n",
      "1. **ç¯å¢ƒå‡†å¤‡**\n",
      "   - éœ€è¦Python 3.8+\n",
      "   - éœ€è¦OpenAI APIå¯†é’¥æˆ–å…¶ä»–LLMæœåŠ¡å¯†é’¥\n",
      "   - å»ºè®®ä½¿ç”¨è™šæ‹Ÿç¯å¢ƒ\n",
      "\n",
      "2. **å­¦ä¹ èµ„æº**\n",
      "   - å®˜æ–¹æ–‡æ¡£ï¼šhttps://python.langchain.com/\n",
      "   - GitHubç¤ºä¾‹ï¼šhttps://github.com/langchain-ai/langchain\n",
      "   - LangChainä¸­æ–‡ç½‘ï¼šhttps://www.langchain.com.cn/\n",
      "\n",
      "3. **å¸¸è§é™·é˜±**\n",
      "   - APIè°ƒç”¨æˆæœ¬æ§åˆ¶ï¼ˆè®¾ç½®tokené™åˆ¶ï¼‰\n",
      "   - æç¤ºè¯å·¥ç¨‹éœ€è¦åå¤è°ƒè¯•\n",
      "   - ç‰ˆæœ¬æ›´æ–°è¾ƒå¿«ï¼Œæ³¨æ„APIå˜åŒ–\n",
      "\n",
      "4. **è°ƒè¯•æŠ€å·§**\n",
      "   ```python\n",
      "   # æŸ¥çœ‹é“¾çš„ä¸­é—´æ­¥éª¤\n",
      "   chain.verbose = True\n",
      "   \n",
      "   # ä½¿ç”¨æœ¬åœ°æ¨¡å‹é™ä½æˆæœ¬\n",
      "   # å¦‚ï¼šOllama + Llama2\n",
      "   ```\n",
      "\n",
      "### ğŸ“… å­¦ä¹ è®¡åˆ’å»ºè®®\n",
      "- **ç¬¬1å‘¨**ï¼šå®Œæˆé˜¶æ®µä¸€å’Œé˜¶æ®µäºŒï¼Œæ¯å¤©1-2å°æ—¶\n",
      "- **ç¬¬2å‘¨**ï¼šå®Œæˆé˜¶æ®µä¸‰ï¼Œå°è¯•ç¬¬ä¸€ä¸ªå°é¡¹ç›®\n",
      "- **ç¬¬3å‘¨**ï¼šå®Œå–„é¡¹ç›®ï¼Œå­¦ä¹ æ›´å¤šé«˜çº§ç‰¹æ€§\n",
      "- **ç¬¬4å‘¨**ï¼šå°è¯•å®é™…åº”ç”¨åœºæ™¯\n",
      "\n",
      "### ğŸ”§ å·¥å…·æ¨è\n",
      "1. **å¼€å‘ç¯å¢ƒ**ï¼šVS Code + Jupyter Notebook\n",
      "2. **è°ƒè¯•å·¥å…·**ï¼šLangSmithï¼ˆå®˜æ–¹è°ƒè¯•å¹³å°ï¼‰\n",
      "3. **æ›¿ä»£æ–¹æ¡ˆ**ï¼šLlamaIndexï¼ˆä¸“æ³¨æ–‡æ¡£å¤„ç†ï¼‰\n",
      "\n",
      "è®°ä½ï¼š**ä»ç®€å•å¼€å§‹ï¼Œé€æ­¥å¤æ‚**ã€‚å…ˆç†è§£æ¯ä¸ªç»„ä»¶çš„ä½œç”¨ï¼Œå†å­¦ä¹ å¦‚ä½•ç»„åˆå®ƒä»¬è§£å†³å®é™…é—®é¢˜ã€‚æ¯ä¸ªæ¦‚å¿µéƒ½è¦åŠ¨æ‰‹å®è·µï¼\n",
      "\n",
      "è¿›é˜¶çº§å°‘æ ·æœ¬æç¤ºè¯ï¼š\n",
      "å­¦ç§‘ï¼šPythonç¼–ç¨‹ï¼ˆå…¥é—¨ï¼‰\n",
      "éš¾åº¦ï¼šeasy\n",
      "å­¦ä¹ æ–¹æ³•ï¼šæ ¸å¿ƒç›®æ ‡ï¼šæŒæ¡åŸºç¡€è¯­æ³•ï¼›å­¦ä¹ æ­¥éª¤ï¼š1.å˜é‡ä¸æ•°æ®ç±»å‹ 2.æ¡ä»¶è¯­å¥ï¼›æ³¨æ„äº‹é¡¹ï¼šè¾¹å­¦è¾¹ç»ƒ\n",
      "\n",
      "\n",
      "å­¦ç§‘ï¼šLangChain\n",
      "éš¾åº¦ï¼šhard\n",
      "å­¦ä¹ æ–¹æ³•ï¼š\n",
      "\n",
      "è¿›é˜¶çº§å­¦ä¹ æ–¹æ³•ï¼š\n",
      "å¥½çš„ï¼Œè¿™æ˜¯ä¸€ä¸ªéå¸¸æ¸…æ™°çš„å­¦ä¹ è·¯å¾„è§„åˆ’ã€‚æˆ‘ä»¬æ¥åˆ†åˆ«åˆ¶å®šè¿™ä¸¤ä¸ªå­¦ç§‘çš„å­¦ä¹ è®¡åˆ’ã€‚\n",
      "\n",
      "### å­¦ç§‘ä¸€ï¼šPythonç¼–ç¨‹ï¼ˆå…¥é—¨ï¼‰\n",
      "\n",
      "**æ ¸å¿ƒç›®æ ‡**ï¼šæŒæ¡åŸºç¡€è¯­æ³•ï¼Œèƒ½ç¼–å†™ç®€å•çš„ç¨‹åºè§£å†³å®é™…é—®é¢˜ã€‚\n",
      "**å­¦ä¹ æ–¹æ³•**ï¼š**è¾¹å­¦è¾¹ç»ƒ**æ˜¯æœ€é«˜æ•ˆçš„æ–¹å¼ã€‚ä¸è¦åªçœ‹ä¸åŠ¨æ‰‹ï¼Œæ¯ä¸€ä¸ªæ¦‚å¿µéƒ½è¦åœ¨ä»£ç ç¼–è¾‘å™¨ä¸­æ•²å‡ºæ¥å¹¶è¿è¡Œã€‚\n",
      "\n",
      "#### å­¦ä¹ æ­¥éª¤ä¸è¯¦ç»†å†…å®¹ï¼š\n",
      "\n",
      "**ç¬¬ä¸€æ­¥ï¼šå˜é‡ä¸æ•°æ®ç±»å‹**\n",
      "1.  **å˜é‡**ï¼šç†è§£ä»€ä¹ˆæ˜¯å˜é‡ï¼ˆæ•°æ®çš„å®¹å™¨ï¼‰ï¼Œå¦‚ä½•å‘½åå’Œèµ‹å€¼ï¼ˆ`=`ï¼‰ã€‚\n",
      "    *   **ç»ƒä¹ **ï¼šåˆ›å»ºå‡ ä¸ªå˜é‡ï¼Œå­˜å‚¨ä½ çš„åå­—ã€å¹´é¾„ã€åŸå¸‚ç­‰ä¿¡æ¯å¹¶æ‰“å°ã€‚\n",
      "2.  **åŸºæœ¬æ•°æ®ç±»å‹**ï¼š\n",
      "    *   **æ•´æ•°ï¼ˆintï¼‰** å’Œ **æµ®ç‚¹æ•°ï¼ˆfloatï¼‰**ï¼šè¿›è¡ŒåŸºæœ¬çš„æ•°å­¦è¿ç®—ï¼ˆ`+`, `-`, `*`, `/`, `//`, `%`, `**`ï¼‰ã€‚\n",
      "    *   **å­—ç¬¦ä¸²ï¼ˆstrï¼‰**ï¼šå­¦ä¹ åˆ›å»ºï¼ˆå•å¼•å·/åŒå¼•å·ï¼‰ã€æ‹¼æ¥ï¼ˆ`+`ï¼‰ã€é‡å¤ï¼ˆ`*`ï¼‰ã€ç´¢å¼•å’Œåˆ‡ç‰‡ã€‚\n",
      "    *   **å¸ƒå°”å€¼ï¼ˆboolï¼‰**ï¼š`True` å’Œ `False`ã€‚\n",
      "    *   **ç»ƒä¹ **ï¼šè®¡ç®—åœ†çš„é¢ç§¯ï¼›æ‹¼æ¥é—®å€™è¯­ â€œHello, [ä½ çš„åå­—]!â€ï¼›å°è¯•å­—ç¬¦ä¸²çš„å„ç§æ“ä½œã€‚\n",
      "3.  **ç±»å‹è½¬æ¢**ï¼š`int()`, `float()`, `str()` çš„ç”¨æ³•ã€‚\n",
      "    *   **ç»ƒä¹ **ï¼šå°†ç”¨æˆ·è¾“å…¥çš„å­—ç¬¦ä¸²æ•°å­—è½¬æ¢ä¸ºæ•´æ•°è¿›è¡Œè®¡ç®—ã€‚\n",
      "4.  **è·å–ç”¨æˆ·è¾“å…¥**ï¼š`input()` å‡½æ•°ã€‚\n",
      "    *   **ç»ƒä¹ **ï¼šç¼–å†™ä¸€ä¸ªç®€å•çš„é—®ç­”ç¨‹åºã€‚\n",
      "\n",
      "**ç¬¬äºŒæ­¥ï¼šæ¡ä»¶è¯­å¥**\n",
      "1.  **æ¯”è¾ƒè¿ç®—ç¬¦**ï¼š`==`, `!=`, `>`, `<`, `>=`, `<=`ã€‚\n",
      "2.  **é€»è¾‘è¿ç®—ç¬¦**ï¼š`and`, `or`, `not`ã€‚\n",
      "3.  **`if`ã€`elif`ã€`else` è¯­å¥**ï¼šæŒæ¡åŸºæœ¬ç»“æ„ã€‚\n",
      "    *   **ç»ƒä¹ **ï¼š\n",
      "        *   æˆç»©åˆ¤æ–­å™¨ï¼ˆæ ¹æ®åˆ†æ•°è¾“å‡ºç­‰çº§ï¼‰ã€‚\n",
      "        *   ç®€å•çš„ç™»å½•éªŒè¯ï¼ˆæ¯”è¾ƒè¾“å…¥çš„ç”¨æˆ·åå’Œå¯†ç ï¼‰ã€‚\n",
      "        *   åˆ¤æ–­ä¸€ä¸ªæ•°æ˜¯æ­£æ•°ã€è´Ÿæ•°è¿˜æ˜¯é›¶ã€‚\n",
      "        *   ç»“åˆ `input()`ï¼Œåˆ¶ä½œä¸€ä¸ªæ™ºèƒ½ä¸€ç‚¹çš„å¯¹è¯ç¨‹åºã€‚\n",
      "\n",
      "**å…³é”®ç»ƒä¹ é¡¹ç›®å»ºè®®ï¼ˆå­¦å®Œä»¥ä¸Šä¸¤æ­¥åï¼‰**ï¼š\n",
      "*   **ç®€æ˜“è®¡ç®—å™¨**ï¼šæ”¯æŒåŠ å‡ä¹˜é™¤ã€‚\n",
      "*   **æ•°å­—çŒœè°œæ¸¸æˆ**ï¼šç¨‹åºéšæœºç”Ÿæˆä¸€ä¸ªæ•°ï¼Œç”¨æˆ·æ¥çŒœï¼Œæ ¹æ®çŒœæµ‹ç»™å‡ºâ€œå¤§äº†â€ã€â€œå°äº†â€çš„æç¤ºã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### å­¦ç§‘äºŒï¼šLangChain\n",
      "\n",
      "**æ ¸å¿ƒç›®æ ‡**ï¼šç†è§£æ ¸å¿ƒæ¦‚å¿µï¼Œèƒ½å¤Ÿä½¿ç”¨LangChainæ„å»ºç®€å•çš„AIåº”ç”¨æµæ°´çº¿ã€‚\n",
      "**éš¾åº¦**ï¼šHardã€‚å› ä¸ºå®ƒä¸ä»…è¦æ±‚PythonåŸºç¡€ï¼Œè¿˜è¦æ±‚å¯¹**å¤§è¯­è¨€æ¨¡å‹ï¼ˆLLMï¼‰**ã€**æç¤ºå·¥ç¨‹**ã€**å¤–éƒ¨å·¥å…·è°ƒç”¨**ç­‰æ¦‚å¿µæœ‰åˆæ­¥äº†è§£ã€‚\n",
      "**å­¦ä¹ æ–¹æ³•**ï¼š**æ¦‚å¿µå…ˆè¡Œï¼Œé¡¹ç›®é©±åŠ¨**ã€‚å…ˆç†è§£â€œä¸ºä»€ä¹ˆâ€å’Œâ€œæ˜¯ä»€ä¹ˆâ€ï¼Œå†é€šè¿‡æ­å»ºå°é¡¹ç›®å­¦ä¹ â€œæ€ä¹ˆåšâ€ã€‚\n",
      "\n",
      "#### å­¦ä¹ è·¯å¾„ä¸æ ¸å¿ƒæ¨¡å—ï¼š\n",
      "\n",
      "**å‰æœŸå‡†å¤‡ï¼ˆå¿…å¤‡åŸºç¡€ï¼‰**ï¼š\n",
      "1.  **ç‰¢å›ºçš„PythonåŸºç¡€**ï¼ˆè‡³å°‘å®Œæˆä¸Šé¢Pythonå…¥é—¨çš„æ‰€æœ‰å†…å®¹ï¼Œå¹¶äº†è§£å‡½æ•°ã€åˆ—è¡¨ã€å­—å…¸ç­‰ï¼‰ã€‚\n",
      "2.  **å¯¹LLMæœ‰åŸºæœ¬è®¤çŸ¥**ï¼šçŸ¥é“ä»€ä¹ˆæ˜¯ChatGPT/æ–‡å¿ƒä¸€è¨€ç­‰ï¼Œäº†è§£å®ƒä»¬é€šè¿‡â€œæç¤ºâ€æ¥å·¥ä½œã€‚\n",
      "3.  **è·å–APIå¯†é’¥**ï¼šæ³¨å†Œå¹¶è·å–ä¸€ä¸ªLLMæä¾›å•†çš„API Keyï¼ˆå¦‚OpenAIã€æ™ºè°±AIã€DeepSeekç­‰ï¼‰ã€‚è¿™æ˜¯LangChainçš„â€œå‘åŠ¨æœºâ€ã€‚\n",
      "\n",
      "**æ ¸å¿ƒå­¦ä¹ æ­¥éª¤**ï¼š\n",
      "\n",
      "**ç¬¬ä¸€æ­¥ï¼šç†è§£æ ¸å¿ƒæ¦‚å¿µ**\n",
      "1.  **Model I/Oï¼ˆæ ¸å¿ƒï¼‰**ï¼šè¿™æ˜¯LangChainçš„åŸºçŸ³ã€‚\n",
      "    *   **LLMs**ï¼š å¤§è¯­è¨€æ¨¡å‹æœ¬èº«ã€‚\n",
      "    *   **Chat Models**ï¼š ä¸“ä¸ºå¯¹è¯ä¼˜åŒ–çš„æ¨¡å‹ï¼ˆå¦‚GPT-4ï¼‰ã€‚\n",
      "    *   **Prompts**ï¼š æç¤ºæ¨¡æ¿ã€‚å­¦ä¹ å¦‚ä½•åŠ¨æ€æ„å»ºæç¤ºï¼Œè€Œä¸æ˜¯å†™æ­»å­—ç¬¦ä¸²ã€‚\n",
      "    *   **Output Parsers**ï¼š å°†æ¨¡å‹éç»“æ„åŒ–çš„æ–‡æœ¬è¾“å‡ºï¼Œè§£ææˆç»“æ„åŒ–çš„æ•°æ®ï¼ˆå¦‚Pythonå¯¹è±¡ï¼‰ã€‚\n",
      "    *   **å­¦ä¹ ç›®æ ‡**ï¼šèƒ½ä½¿ç”¨LangChainè°ƒç”¨ä¸€ä¸ªæ¨¡å‹ï¼Œå¹¶æ ¼å¼åŒ–è¾“å…¥å’Œè¾“å‡ºã€‚\n",
      "\n",
      "**ç¬¬äºŒæ­¥ï¼šæŒæ¡å…³é”®é“¾ï¼ˆChainsï¼‰**\n",
      "1.  **ä»€ä¹ˆæ˜¯Chain**ï¼šå°†å¤šä¸ªç»„ä»¶ï¼ˆæ¨¡å‹ã€æç¤ºã€å·¥å…·ç­‰ï¼‰æŒ‰é¡ºåºç»„åˆèµ·æ¥ï¼Œå®Œæˆä¸€ä¸ªå¤æ‚ä»»åŠ¡ã€‚\n",
      "2.  **LLMChain**ï¼šæœ€åŸºç¡€çš„é“¾ï¼Œç»„åˆäº†`PromptTemplate` + `LLM` + `OutputParser`ã€‚\n",
      "3.  **Sequential Chain**ï¼šæŒ‰é¡ºåºæ‰§è¡Œå¤šä¸ªé“¾ï¼Œå°†ä¸€ä¸ªé“¾çš„è¾“å‡ºä½œä¸ºä¸‹ä¸€ä¸ªé“¾çš„è¾“å…¥ã€‚\n",
      "    *   **å­¦ä¹ ç›®æ ‡**ï¼šèƒ½æ„å»ºä¸€ä¸ªå¤šæ­¥éª¤çš„ä»»åŠ¡é“¾ï¼Œä¾‹å¦‚â€œæ€»ç»“ä¸€ç¯‡çŸ­æ–‡ -> å°†æ€»ç»“ç¿»è¯‘æˆè‹±æ–‡ -> æå–å…³é”®è¯â€ã€‚\n",
      "\n",
      "**ç¬¬ä¸‰æ­¥ï¼šæ¢ç´¢æ•°æ®è¿æ¥ï¼ˆRetrievalï¼‰**\n",
      "1.  **Document Loaders**ï¼šä»å„ç§æ¥æºï¼ˆæ–‡æœ¬æ–‡ä»¶ã€PDFã€ç½‘é¡µï¼‰åŠ è½½æ•°æ®ã€‚\n",
      "2.  **Text Splitters**ï¼šå°†é•¿æ–‡æ¡£åˆ†å‰²æˆæ¨¡å‹èƒ½å¤„ç†çš„å°å—ã€‚\n",
      "3.  **Vectorstores & Embeddings**ï¼šå°†æ–‡æœ¬è½¬æ¢ä¸ºå‘é‡ï¼ˆEmbeddingï¼‰å¹¶å­˜å‚¨ï¼Œä»¥ä¾¿è¿›è¡Œè¯­ä¹‰æœç´¢ã€‚\n",
      "4.  **Retrievers**ï¼šä»å‘é‡åº“ä¸­æ£€ç´¢ä¸é—®é¢˜ç›¸å…³çš„æ–‡æ¡£ç‰‡æ®µã€‚\n",
      "    *   **å­¦ä¹ ç›®æ ‡**ï¼šèƒ½æ„å»ºä¸€ä¸ªç®€å•çš„**åŸºäºè‡ªå®šä¹‰çŸ¥è¯†çš„é—®ç­”ç³»ç»Ÿ**ã€‚è¿™æ˜¯LangChainæœ€ç»å…¸çš„åº”ç”¨ã€‚\n",
      "\n",
      "**ç¬¬å››æ­¥ï¼šäº†è§£æ™ºèƒ½ä½“ï¼ˆAgentsï¼‰**\n",
      "1.  **ä»€ä¹ˆæ˜¯Agent**ï¼šè®©LLMè‡ªä¸»å†³å®šè°ƒç”¨å“ªäº›å·¥å…·ï¼ˆå¦‚è®¡ç®—å™¨ã€æœç´¢å¼•æ“ã€æ•°æ®åº“ï¼‰æ¥å®Œæˆä»»åŠ¡ã€‚\n",
      "2.  **Tools**ï¼šå®šä¹‰Agentå¯ä»¥ä½¿ç”¨çš„å·¥å…·ã€‚\n",
      "3.  **Agent Executor**ï¼šè¿è¡ŒAgentçš„æ¡†æ¶ã€‚\n",
      "    *   **å­¦ä¹ ç›®æ ‡**ï¼šèƒ½åˆ›å»ºä¸€ä¸ªå¯ä»¥ä½¿ç”¨æœç´¢å¼•æ“å’Œè®¡ç®—å™¨çš„ç®€å•æ™ºèƒ½ä½“ã€‚\n",
      "\n",
      "**å®è·µé¡¹ç›®å»ºè®®ï¼ˆç”±æ˜“åˆ°éš¾ï¼‰**ï¼š\n",
      "1.  **ä¸ªäººAIåŠ©æ‰‹**ï¼šç”¨`LLMChain`åšä¸€ä¸ªèƒ½è¿›è¡Œå¤šè½®å¯¹è¯ã€é£æ ¼å›ºå®šçš„èŠå¤©æœºå™¨äººã€‚\n",
      "2.  **å®šåˆ¶åŒ–æ‘˜è¦/ç¿»è¯‘å·¥å…·**ï¼šç”¨`SequentialChain`å¤„ç†ç‰¹å®šæ ¼å¼çš„æ–‡æœ¬ã€‚\n",
      "3.  **æ–‡æ¡£é—®ç­”æœºå™¨äºº**ï¼šä½¿ç”¨`Retrieval`æ¨¡å—ï¼Œè®©ä½ å¯ä»¥ç”¨è‡ªå·±çš„æ–‡æ¡£ï¼ˆå¦‚å…¬å¸æ‰‹å†Œã€ä¸ªäººç¬”è®°ï¼‰æ¥å›ç­”é—®é¢˜ã€‚\n",
      "4.  **è”ç½‘æœç´¢åŠ©æ‰‹**ï¼šç»“åˆ`Agents`å’Œ`Tools`ï¼Œè®©AIèƒ½è·å–å®æ—¶ä¿¡æ¯ã€‚\n",
      "\n",
      "**é‡è¦æ³¨æ„äº‹é¡¹**ï¼š\n",
      "*   **ä»å®˜æ–¹æ–‡æ¡£å¼€å§‹**ï¼šLangChainçš„å®˜æ–¹æ–‡æ¡£æ˜¯å­¦ä¹ çš„ç¬¬ä¸€ç«™ï¼Œæ¦‚å¿µè§£é‡Šæ¸…æ™°ã€‚\n",
      "*   **å…³æ³¨ç‰ˆæœ¬å˜åŒ–**ï¼šLangChainæ›´æ–°è¾ƒå¿«ï¼Œæ³¨æ„ä½ å­¦ä¹ çš„æ•™ç¨‹æˆ–ä»£ç æ˜¯å¦ä¸å½“å‰ç‰ˆæœ¬å…¼å®¹ã€‚\n",
      "*   **å…ˆè·‘é€šï¼Œå†æ·±ç©¶**ï¼šä¸è¦ä¸€å¼€å§‹å°±é™·å…¥æ‰€æœ‰ç»†èŠ‚ã€‚å…ˆæŒ‰ç…§ç¤ºä¾‹æŠŠæµç¨‹è·‘é€šï¼Œçœ‹åˆ°æ•ˆæœï¼Œå†å›å¤´ç ”ç©¶æ¯ä¸ªå‚æ•°å’Œç±»çš„å«ä¹‰ã€‚\n",
      "*   **ç¤¾åŒºæ´»è·ƒ**ï¼šé‡åˆ°é—®é¢˜ï¼Œå¤šåœ¨GitHub Issuesã€Discordæˆ–ç›¸å…³è®ºå›æœç´¢å’Œæé—®ã€‚\n",
      "\n",
      "**æ€»ç»“**ï¼š\n",
      "*   **Pythonå…¥é—¨**ï¼šåƒå­¦éª‘è‡ªè¡Œè½¦ï¼Œé‡åœ¨**åå¤ç»ƒä¹ **ï¼Œå½¢æˆè‚Œè‚‰è®°å¿†ã€‚\n",
      "*   **LangChain**ï¼šåƒå­¦ç»„è£…ä¸€å°å¤æ‚æœºå™¨ï¼Œé‡åœ¨**ç†è§£è“å›¾ï¼ˆæ¦‚å¿µï¼‰**å’Œ**å„ä¸ªéƒ¨ä»¶ï¼ˆæ¨¡å—ï¼‰å¦‚ä½•è¿æ¥**ï¼Œç„¶åé€šè¿‡**åŠ¨æ‰‹ç»„è£…ï¼ˆé¡¹ç›®ï¼‰**æ¥å·©å›ºã€‚\n",
      "\n",
      "ç¥ä½ å­¦ä¹ é¡ºåˆ©ï¼\n"
     ]
    }
   ],
   "source": [
    "# å¯¼å…¥å·¥ç¨‹åŒ–æ‰€éœ€ç»„ä»¶\n",
    "from langchain_core.prompts import FewShotPromptTemplate, PromptTemplate\n",
    "from langchain_core.example_selectors.length_based import LengthBasedExampleSelector\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import json\n",
    "\n",
    "# 1. ç¯å¢ƒåˆå§‹åŒ–ï¼ˆå·¥ç¨‹åŒ–æ ‡å‡†æ“ä½œï¼šç¯å¢ƒå˜é‡ç®¡ç†å¯†é’¥ï¼‰\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "BASE_URL = \"https://api.deepseek.com\"\n",
    "\n",
    "if not API_KEY:\n",
    "    raise ValueError(\"æœªæ£€æµ‹åˆ° API_KEYï¼Œè¯·æ£€æŸ¥ .env æ–‡ä»¶æ˜¯å¦é…ç½®æ­£ç¡®\")\n",
    "\n",
    "chat_model = ChatOpenAI(\n",
    "    api_key=API_KEY,\n",
    "    base_url=BASE_URL,\n",
    "    model=\"deepseek-chat\",\n",
    "    temperature=0.3,\n",
    "    max_tokens=300\n",
    ")\n",
    "\n",
    "# 2. å·¥ç¨‹åŒ–ç¤ºä¾‹ç®¡ç†ï¼šä»JSONæ–‡ä»¶åŠ è½½ç¤ºä¾‹ï¼ˆé¿å…ç¡¬ç¼–ç ï¼Œä¾¿äºç»´æŠ¤ï¼‰\n",
    "with open(\"learning_method_examples.json\", \"r\", encoding=\"utf-8\") as f:\n",
    "    examples = json.load(f)\n",
    "# ç¤ºä¾‹æ–‡ä»¶æ ¼å¼å‚è€ƒï¼ˆlearning_method_examples.jsonï¼‰ï¼š\n",
    "# [\n",
    "#   {\"subject\": \"Pythonç¼–ç¨‹ï¼ˆå…¥é—¨ï¼‰\", \"difficulty\": \"easy\", \"method\": \"æ ¸å¿ƒç›®æ ‡ï¼šæŒæ¡åŸºç¡€è¯­æ³•ï¼›å­¦ä¹ æ­¥éª¤ï¼š1.å˜é‡ä¸æ•°æ®ç±»å‹ 2.æ¡ä»¶è¯­å¥ï¼›æ³¨æ„äº‹é¡¹ï¼šè¾¹å­¦è¾¹ç»ƒ\"},\n",
    "#   {\"subject\": \"Pythonç¼–ç¨‹ï¼ˆè¿›é˜¶ï¼‰\", \"difficulty\": \"hard\", \"method\": \"æ ¸å¿ƒç›®æ ‡ï¼šæŒæ¡é¢å‘å¯¹è±¡ä¸åº“å¼€å‘ï¼›å­¦ä¹ æ­¥éª¤ï¼š1.ç±»ä¸å¯¹è±¡ 2.æ¨¡å—å¼€å‘ï¼›æ³¨æ„äº‹é¡¹ï¼šå‚ä¸å¼€æºé¡¹ç›®\"},\n",
    "#   {\"subject\": \"æœºå™¨å­¦ä¹ ï¼ˆå…¥é—¨ï¼‰\", \"difficulty\": \"easy\", \"method\": \"æ ¸å¿ƒç›®æ ‡ï¼šç†è§£åŸºç¡€æ¦‚å¿µï¼›å­¦ä¹ æ­¥éª¤ï¼š1.æ•°æ®é¢„å¤„ç† 2.ç®€å•æ¨¡å‹ï¼›æ³¨æ„äº‹é¡¹ï¼šç”¨Excelè¾…åŠ©ç†è§£\"},\n",
    "#   {\"subject\": \"æœºå™¨å­¦ä¹ ï¼ˆè¿›é˜¶ï¼‰\", \"difficulty\": \"hard\", \"method\": \"æ ¸å¿ƒç›®æ ‡ï¼šæŒæ¡æ¨¡å‹ä¼˜åŒ–ï¼›å­¦ä¹ æ­¥éª¤ï¼š1.ç‰¹å¾å·¥ç¨‹ 2.è¶…å‚æ•°è°ƒä¼˜ï¼›æ³¨æ„äº‹é¡¹ï¼šç ”è¯»è®ºæ–‡å¤ç°å®éªŒ\"}\n",
    "# ]\n",
    "\n",
    "# 3. å®šä¹‰ExampleSelectorï¼šæŒ‰éš¾åº¦ç­›é€‰ç¤ºä¾‹ï¼ˆè¾“å…¥å«difficultyå‚æ•°ï¼‰\n",
    "example_selector = LengthBasedExampleSelector(\n",
    "    examples=examples,\n",
    "    example_prompt=PromptTemplate(\n",
    "        input_variables=[\"subject\", \"difficulty\", \"method\"],\n",
    "        template=\"å­¦ç§‘ï¼š{subject}\\néš¾åº¦ï¼š{difficulty}\\nå­¦ä¹ æ–¹æ³•ï¼š{method}\\n\"\n",
    "    ),\n",
    "    max_length=150,  # æ§åˆ¶ç¤ºä¾‹æ€»é•¿åº¦ï¼Œé¿å…æç¤ºè¯è¿‡é•¿\n",
    "    get_text_length=lambda x: len(x)  # é•¿åº¦è®¡ç®—å‡½æ•°\n",
    ")\n",
    "\n",
    "# 4. æ„å»ºå·¥ç¨‹åŒ–å°‘æ ·æœ¬æ¨¡æ¿\n",
    "few_shot_prompt = FewShotPromptTemplate(\n",
    "    example_selector=example_selector,  # æ›¿æ¢å›ºå®šexamplesä¸ºåŠ¨æ€é€‰æ‹©å™¨\n",
    "    example_prompt=PromptTemplate(\n",
    "        input_variables=[\"subject\", \"difficulty\", \"method\"],\n",
    "        template=\"å­¦ç§‘ï¼š{subject}\\néš¾åº¦ï¼š{difficulty}\\nå­¦ä¹ æ–¹æ³•ï¼š{method}\\n\"\n",
    "    ),\n",
    "    suffix=\"å­¦ç§‘ï¼š{new_subject}\\néš¾åº¦ï¼š{new_difficulty}\\nå­¦ä¹ æ–¹æ³•ï¼š\",\n",
    "    input_variables=[\"new_subject\", \"new_difficulty\"]  # æ–°å¢éš¾åº¦å‚æ•°\n",
    ")\n",
    "\n",
    "# 5. åŠ¨æ€ç”Ÿæˆä¸åŒéš¾åº¦çš„æç¤ºè¯\n",
    "# åœºæ™¯1ï¼šç”Ÿæˆå…¥é—¨çº§LangChainå­¦ä¹ æ–¹æ³•\n",
    "formatted_prompt_easy = few_shot_prompt.format(\n",
    "    new_subject=\"LangChain\",\n",
    "    new_difficulty=\"easy\"\n",
    ")\n",
    "print(\"å…¥é—¨çº§å°‘æ ·æœ¬æç¤ºè¯ï¼š\")\n",
    "print(formatted_prompt_easy)\n",
    "result_easy = chat_model.invoke([{\"role\": \"user\", \"content\": formatted_prompt_easy}])\n",
    "print(\"\\nå…¥é—¨çº§å­¦ä¹ æ–¹æ³•ï¼š\")\n",
    "print(result_easy.content)\n",
    "\n",
    "# åœºæ™¯2ï¼šç”Ÿæˆè¿›é˜¶çº§LangChainå­¦ä¹ æ–¹æ³•\n",
    "formatted_prompt_hard = few_shot_prompt.format(\n",
    "    new_subject=\"LangChain\",\n",
    "    new_difficulty=\"hard\"\n",
    ")\n",
    "print(\"\\nè¿›é˜¶çº§å°‘æ ·æœ¬æç¤ºè¯ï¼š\")\n",
    "print(formatted_prompt_hard)\n",
    "result_hard = chat_model.invoke([{\"role\": \"user\", \"content\": formatted_prompt_hard}])\n",
    "print(\"\\nè¿›é˜¶çº§å­¦ä¹ æ–¹æ³•ï¼š\")\n",
    "print(result_hard.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7105269c",
   "metadata": {},
   "source": [
    "#### 2.3.2.1æ¡ˆä¾‹1ï¼šStrOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2cb5bc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "StrOutputParser è§£æåçš„å­—ç¬¦ä¸²ï¼š\n",
      "LangChain çš„è¾“å‡ºè§£æå±‚ï¼ˆOutput Parsersï¼‰æ˜¯**å°†æ¨¡å‹åŸå§‹è¾“å‡ºè½¬æ¢ä¸ºç»“æ„åŒ–ã€å¯ç¨‹åºåŒ–å¤„ç†æ•°æ®çš„å…³é”®ç»„ä»¶**ã€‚å®ƒçš„ä¸»è¦ä½œç”¨å¦‚ä¸‹ï¼š\n",
      "\n",
      "## æ ¸å¿ƒä½œç”¨\n",
      "\n",
      "### 1. **ç»“æ„åŒ–è¾“å‡º**\n",
      "å°†LLMçš„éç»“æ„åŒ–æ–‡æœ¬å“åº”ï¼ˆå¦‚è‡ªç”±æ–‡æœ¬ï¼‰è½¬æ¢ä¸ºé¢„å®šä¹‰çš„ç»“æ„åŒ–æ ¼å¼ï¼Œä¾‹å¦‚ï¼š\n",
      "- JSONå¯¹è±¡\n",
      "- Pythonå­—å…¸/åˆ—è¡¨\n",
      "- Pydanticæ¨¡å‹å®ä¾‹\n",
      "- ç‰¹å®šæ•°æ®ç±»å®ä¾‹\n",
      "\n",
      "### 2. **æ•°æ®éªŒè¯ä¸æ¸…æ´—**\n",
      "- éªŒè¯è¾“å‡ºæ˜¯å¦ç¬¦åˆé¢„æœŸæ¨¡å¼\n",
      "- è‡ªåŠ¨ä¿®å¤æ ¼å¼é”™è¯¯\n",
      "- å¤„ç†ä¸å®Œæ•´æˆ–æ¨¡ç³Šçš„å“åº”\n",
      "\n",
      "### 3. **ä¸‹æ¸¸ä»»åŠ¡é›†æˆ**\n",
      "ä¸ºåç»­å¤„ç†æä¾›æ ‡å‡†åŒ–è¾“å…¥ï¼Œä½¿LLMè¾“å‡ºèƒ½å¤Ÿï¼š\n",
      "- ç›´æ¥å­˜å…¥æ•°æ®åº“\n",
      "- ä½œä¸ºå‡½æ•°å‚æ•°ä¼ é€’\n",
      "- é›†æˆåˆ°ä¸šåŠ¡é€»è¾‘ä¸­\n",
      "- ç”¨äºæ¡ä»¶åˆ¤æ–­å’Œæµç¨‹æ§åˆ¶\n",
      "\n",
      "## å¸¸ç”¨è§£æå™¨ç±»å‹\n",
      "\n",
      "```python\n",
      "# ç¤ºä¾‹ï¼šä½¿ç”¨Pydanticè§£æå™¨\n",
      "from langchain.output_parsers import PydanticOutputParser\n",
      "from pydantic import BaseModel, Field\n",
      "\n",
      "class Person(BaseModel):\n",
      "    name: str = Field(description=\"å§“å\")\n",
      "    age: int = Field(description=\"å¹´é¾„\")\n",
      "    hobbies: list[str] = Field(description=\"çˆ±å¥½åˆ—è¡¨\")\n",
      "\n",
      "parser = PydanticOutputParser(pydantic_object=Person)\n",
      "# è‡ªåŠ¨ç”Ÿæˆæç¤ºè¯æŒ‡ä»¤ï¼ŒæŒ‡å¯¼LLMè¾“å‡ºæ­£ç¡®æ ¼å¼\n",
      "```\n",
      "\n",
      "## å·¥ä½œæµç¨‹\n",
      "1. **æŒ‡ä»¤æ³¨å…¥**ï¼šåœ¨æç¤ºè¯ä¸­æ·»åŠ æ ¼å¼è¯´æ˜\n",
      "2. **è¾“å‡ºè§£æ**ï¼šæ•è·LLMå“åº”å¹¶è§£æ\n",
      "3. **é”™è¯¯å¤„ç†**ï¼šé‡è¯•æˆ–ä¿®å¤æ ¼å¼é”™è¯¯\n",
      "4. **ç±»å‹è½¬æ¢**ï¼šå°†æ–‡æœ¬è½¬æ¢ä¸ºç›®æ ‡ç±»å‹\n",
      "\n",
      "## å®é™…ä»·å€¼\n",
      "- **æé«˜å¯é æ€§**ï¼šç¡®ä¿è¾“å‡ºä¸€è‡´æ€§\n",
      "- **é™ä½é›†æˆæˆæœ¬**ï¼šç®€åŒ–åç»­ä»£ç ç¼–å†™\n",
      "- **å¢å¼ºå¯ç»´æŠ¤æ€§**ï¼šæ˜ç¡®çš„æ•°æ®å¥‘çº¦\n",
      "- **æ”¯æŒå¤æ‚åº”ç”¨**ï¼šå®ç°å¤šæ­¥éª¤é“¾å¼è°ƒç”¨\n",
      "\n",
      "è¾“å‡ºè§£æå±‚æ˜¯LangChainæ„å»ºç”Ÿäº§çº§LLMåº”ç”¨çš„é‡è¦åŸºç¡€è®¾æ–½ï¼Œå®ƒå¼¥åˆäº†éç»“æ„åŒ–æ–‡æœ¬ç”Ÿæˆä¸ç»“æ„åŒ–æ•°æ®å¤„ç†ä¹‹é—´çš„é¸¿æ²Ÿã€‚\n",
      "\n",
      "è§£æç»“æœç±»å‹ï¼š <class 'str'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# 1. ç¯å¢ƒåˆå§‹åŒ–\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "BASE_URL = \"https://api.deepseek.com\"\n",
    "\n",
    "# 2. åˆå§‹åŒ–æ¨¡å‹ï¼ˆæ— éœ€æ”¯æŒåŸç”Ÿç»“æ„åŒ–è¾“å‡ºï¼‰\n",
    "llm = ChatOpenAI(\n",
    "    api_key=API_KEY,\n",
    "    base_url=BASE_URL,\n",
    "    model=\"deepseek-chat\",\n",
    "    temperature=0.3\n",
    ")\n",
    "\n",
    "# 3. åˆ›å»º StrOutputParser\n",
    "# æ ¸å¿ƒä½œç”¨ï¼šå°† LLM è¿”å›çš„ AIMessage å¯¹è±¡ï¼Œç»Ÿä¸€è½¬ä¸ºçº¯å­—ç¬¦ä¸²ï¼ˆstrï¼‰\n",
    "parser = StrOutputParser()\n",
    "\n",
    "# 4. é“¾å¼è°ƒç”¨ï¼šæ¨¡å‹ â†’ å­—ç¬¦ä¸²è§£æ\n",
    "chain = llm | parser\n",
    "result = chain.invoke(\"è¯·ç®€è¦ä»‹ç» LangChain è¾“å‡ºè§£æå±‚çš„ä½œç”¨\")\n",
    "\n",
    "print(\"StrOutputParser è§£æåçš„å­—ç¬¦ä¸²ï¼š\")\n",
    "print(result)\n",
    "print(\"\\nè§£æç»“æœç±»å‹ï¼š\", type(result))  # str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ed2295a",
   "metadata": {},
   "source": [
    "#### 2.3.2.2 æ¡ˆä¾‹2ï¼š JsonOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aed5e5ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è§£æåçš„JSONï¼ˆPythonå­—å…¸ï¼‰ï¼š\n",
      "{'tool_name': 'LangSmith', 'core_function': 'æä¾›å…¨é“¾è·¯çš„LLMåº”ç”¨å¼€å‘ã€è°ƒè¯•ã€æµ‹è¯•ã€ç›‘æ§å’Œéƒ¨ç½²å¹³å°ï¼Œæ”¯æŒè¿½è¸ªå’Œå¯è§†åŒ–LangChainåº”ç”¨çš„æ‰§è¡Œè¿‡ç¨‹ï¼Œå¸®åŠ©å¼€å‘è€…åˆ†ææ€§èƒ½ã€è¯Šæ–­é—®é¢˜å¹¶ä¼˜åŒ–æç¤ºè¯ä¸å·¥ä½œæµã€‚'}\n",
      "è·å–å•ä¸ªå­—æ®µï¼š LangSmith\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import JsonOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# 1. ç¯å¢ƒä¸æ¨¡å‹åˆå§‹åŒ–ï¼ˆçœç•¥ï¼ŒåŒæ–¹æ¡ˆ1ï¼‰\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "BASE_URL = \"https://api.deepseek.com\"\n",
    "llm = ChatOpenAI(\n",
    "    api_key=API_KEY,\n",
    "    base_url=BASE_URL,\n",
    "    model=\"deepseek-chat\",\n",
    "    temperature=0.3\n",
    ")\n",
    "\n",
    "# 2. åˆ›å»º JSON è§£æå™¨ï¼ˆæ— éœ€é¢å¤–é…ç½®ï¼Œé»˜è®¤å¼•å¯¼æ¨¡å‹è¾“å‡º JSONï¼‰\n",
    "parser = JsonOutputParser()\n",
    "\n",
    "# 3. æ„å»ºæç¤ºæ¨¡æ¿ï¼ˆæ— éœ€æ‰‹åŠ¨åµŒå…¥æ ¼å¼æŒ‡ä»¤ï¼Œè§£æå™¨è‡ªåŠ¨å…³è”ï¼‰\n",
    "prompt = PromptTemplate(\n",
    "    template=\"è¯·ä»‹ç»1ä¸ªLangChainå¼€å‘å·¥å…·ï¼Œè¾“å‡ºå·¥å…·åå’Œæ ¸å¿ƒåŠŸèƒ½ã€‚{format_instructions}\",\n",
    "    input_variables=[],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")\n",
    "\n",
    "# 4. é“¾å¼è°ƒç”¨ï¼ˆLangChain â‰¥1.0.0 æ¨èæ–¹å¼ï¼Œè‡ªåŠ¨å®Œæˆæç¤º+è°ƒç”¨+è§£æï¼‰\n",
    "chain = prompt | llm | parser\n",
    "result = chain.invoke({})  # æ— è¾“å…¥å‚æ•°ï¼Œä¼ å…¥ç©ºå­—å…¸\n",
    "\n",
    "print(\"è§£æåçš„JSONï¼ˆPythonå­—å…¸ï¼‰ï¼š\")\n",
    "print(result)\n",
    "print(\"è·å–å•ä¸ªå­—æ®µï¼š\", result[\"tool_name\"])  # å¯ç›´æ¥ç”¨äºä¸šåŠ¡é€»è¾‘"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af845904",
   "metadata": {},
   "source": [
    "#### 2.3.2.3 æ¡ˆä¾‹3ï¼šPydanticOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0ed0fdff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è§£æåçš„ç»“æ„åŒ–æ•°æ®ï¼ˆPydantic æ¨¡å‹å¯¹è±¡ï¼‰ï¼š\n",
      "tool_name='LangSmith' function='ç”¨äºè°ƒè¯•ã€æµ‹è¯•ã€è¯„ä¼°å’Œç›‘æ§LLMåº”ç”¨çš„å…¨é“¾è·¯å¹³å°' difficulty='ä¸­ç­‰'\n",
      "å­—æ®µæ ¡éªŒ difficultyï¼š ä¸­ç­‰\n",
      "è½¬åŒ–ä¸ºå­—å…¸ï¼š {'tool_name': 'LangSmith', 'function': 'ç”¨äºè°ƒè¯•ã€æµ‹è¯•ã€è¯„ä¼°å’Œç›‘æ§LLMåº”ç”¨çš„å…¨é“¾è·¯å¹³å°', 'difficulty': 'ä¸­ç­‰'}\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# 1. ç¯å¢ƒä¸æ¨¡å‹åˆå§‹åŒ–\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "BASE_URL = \"https://api.deepseek.com\"\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    api_key=API_KEY,\n",
    "    base_url=BASE_URL,\n",
    "    model=\"deepseek-chat\",\n",
    "    temperature=0.3\n",
    ")\n",
    "\n",
    "# 2. å®šä¹‰ Pydantic æ•°æ®æ¨¡å‹\n",
    "class ToolInfo(BaseModel):\n",
    "    tool_name: str = Field(description=\"LangChainå¼€å‘å·¥å…·çš„åç§°ï¼Œå¦‚ LangSmith\")\n",
    "    function: str = Field(description=\"å·¥å…·çš„æ ¸å¿ƒåŠŸèƒ½ï¼Œ30å­—ä»¥å†…\")\n",
    "    difficulty: str = Field(description=\"å­¦ä¹ éš¾åº¦ï¼Œä»…å¯é€‰ï¼šç®€å• / ä¸­ç­‰ / å¤æ‚\")\n",
    "\n",
    "# 3. åˆ›å»ºè§£æå™¨\n",
    "parser = PydanticOutputParser(pydantic_object=ToolInfo)\n",
    "\n",
    "# 4. Prompt + Chain\n",
    "prompt = PromptTemplate(\n",
    "    template=\"è¯·ä»‹ç»1ä¸ª LangChain å¼€å‘å·¥å…·ï¼Œä¸¥æ ¼æŒ‰ç…§è¦æ±‚è¾“å‡ºã€‚\\n{format_instructions}\",\n",
    "    input_variables=[],\n",
    "    partial_variables={\n",
    "        \"format_instructions\": parser.get_format_instructions()\n",
    "    }\n",
    ")\n",
    "\n",
    "chain = prompt | llm | parser\n",
    "result = chain.invoke({})\n",
    "\n",
    "print(\"è§£æåçš„ç»“æ„åŒ–æ•°æ®ï¼ˆPydantic æ¨¡å‹å¯¹è±¡ï¼‰ï¼š\")\n",
    "print(result)\n",
    "\n",
    "print(\"å­—æ®µæ ¡éªŒ difficultyï¼š\", result.difficulty)\n",
    "\n",
    "print(\"è½¬åŒ–ä¸ºå­—å…¸ï¼š\", result.model_dump())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7537958c",
   "metadata": {},
   "source": [
    "### 2.3.3 BaseOutputParser æ ¸å¿ƒæŠ½è±¡æ¥å£"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "39ba6c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "è‡ªå®šä¹‰è§£æå™¨è§£æç»“æœï¼š\n",
      "{'tool_name': 'LangFlow', 'function': 'å¯è§†åŒ–ç¼–æ’LangChainç»„ä»¶', 'difficulty': 'ä½'}\n",
      "è§£æç»“æœç±»å‹ï¼š <class 'dict'>\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.output_parsers import BaseOutputParser\n",
    "from langchain_core.prompts import PromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# ç¯å¢ƒåˆå§‹åŒ–\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "BASE_URL = \"https://api.deepseek.com\"\n",
    "llm = ChatOpenAI(\n",
    "    api_key=API_KEY,\n",
    "    base_url=BASE_URL,\n",
    "    model=\"deepseek-chat\",\n",
    "    temperature=0.3\n",
    ")\n",
    "\n",
    "# è‡ªå®šä¹‰è§£æå™¨\n",
    "class CustomToolParser(BaseOutputParser):\n",
    "    def parse(self, text: str) -> dict:\n",
    "        \"\"\"å°†æ¨¡å‹è¾“å‡ºæŒ‰ 'å·¥å…·å@æ ¸å¿ƒåŠŸèƒ½@å­¦ä¹ éš¾åº¦' è§£æä¸ºå­—å…¸\"\"\"\n",
    "        text = text.strip().replace(\"\\n\", \"\").replace(\" \", \"\")\n",
    "        parts = text.split(\"@\")\n",
    "        if len(parts) != 3:\n",
    "            raise ValueError(f\"è¾“å‡ºæ ¼å¼é”™è¯¯ï¼éœ€æ»¡è¶³ã€Œå·¥å…·å@æ ¸å¿ƒåŠŸèƒ½@å­¦ä¹ éš¾åº¦ã€ï¼Œå½“å‰è¾“å‡ºï¼š{text}\")\n",
    "        return {\n",
    "            \"tool_name\": parts[0].strip(),\n",
    "            \"function\": parts[1].strip(),\n",
    "            \"difficulty\": parts[2].strip()\n",
    "        }\n",
    "\n",
    "    def get_format_instructions(self) -> str:\n",
    "        \"\"\"ç”Ÿæˆæç¤ºè¯ï¼Œå¼•å¯¼æ¨¡å‹æŒ‰è‡ªå®šä¹‰æ ¼å¼è¾“å‡º\"\"\"\n",
    "        return \"è¯·ä¸¥æ ¼æŒ‰ç…§ã€Œå·¥å…·å@æ ¸å¿ƒåŠŸèƒ½@å­¦ä¹ éš¾åº¦ã€æ ¼å¼è¾“å‡ºï¼Œä¸æ·»åŠ å¤šä½™å†…å®¹ã€‚ç¤ºä¾‹ï¼šLangSmith@å…¨é“¾è·¯è°ƒè¯•ç›‘æ§@ä¸­ç­‰\"\n",
    "\n",
    "# ä½¿ç”¨è§£æå™¨\n",
    "parser = CustomToolParser()\n",
    "prompt = PromptTemplate(\n",
    "    template=\"è¯·ä»‹ç»1ä¸ªLangChainå¼€å‘å·¥å…·ã€‚{format_instructions}\",\n",
    "    input_variables=[],\n",
    "    partial_variables={\"format_instructions\": parser.get_format_instructions()}\n",
    ")\n",
    "chain = prompt | llm | parser\n",
    "result = chain.invoke({})\n",
    "\n",
    "print(\"è‡ªå®šä¹‰è§£æå™¨è§£æç»“æœï¼š\")\n",
    "print(result)\n",
    "print(\"è§£æç»“æœç±»å‹ï¼š\", type(result))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
