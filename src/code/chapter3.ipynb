{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f969cdc2",
   "metadata": {},
   "source": [
    "# ç¬¬ä¸‰ç«  LangChainè¿›é˜¶ç»„ä»¶å®æ“"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c77e6e",
   "metadata": {},
   "source": [
    "#### 3.1.2.1 å…¨é‡è®°å¿†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "668c9af8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\anaconda\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "åŠ©æ‰‹å›å¤1ï¼š ä½ å¥½å°æ˜ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ï¼ç¼–ç¨‹æ˜¯ä¸ªéå¸¸æ£’çš„çˆ±å¥½ï¼Œèƒ½åˆ›é€ ã€è§£å†³é—®é¢˜ï¼Œè¿˜èƒ½å®ç°å„ç§æœ‰è¶£çš„æƒ³æ³•ã€‚ä½ ä¸»è¦å¯¹å“ªç§ç¼–ç¨‹è¯­è¨€æˆ–é¢†åŸŸæ„Ÿå…´è¶£å‘¢ï¼Ÿæ¯”å¦‚ç½‘é¡µå¼€å‘ã€æ•°æ®åˆ†æã€æ¸¸æˆè®¾è®¡ï¼Œè¿˜æ˜¯å…¶ä»–æ–¹å‘ï¼Ÿ ğŸ˜Š\n",
      "åŠ©æ‰‹å›å¤2ï¼š ä½ åˆšæ‰æåˆ°ä½ å–œæ¬¢ç¼–ç¨‹ï¼éœ€è¦æˆ‘æ¨èä¸€äº›å­¦ä¹ èµ„æºã€é¡¹ç›®çµæ„Ÿï¼Œæˆ–è€…èŠèŠç¼–ç¨‹ç›¸å…³çš„è¯é¢˜å—ï¼Ÿ ğŸ˜„\n",
      "\n",
      "å…¨é‡è®°å¿†çš„å¯¹è¯å†å²ï¼š\n",
      "human: æˆ‘å«å°æ˜ï¼Œå–œæ¬¢ç¼–ç¨‹\n",
      "ai: ä½ å¥½å°æ˜ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ï¼ç¼–ç¨‹æ˜¯ä¸ªéå¸¸æ£’çš„çˆ±å¥½ï¼Œèƒ½åˆ›é€ ã€è§£å†³é—®é¢˜ï¼Œè¿˜èƒ½å®ç°å„ç§æœ‰è¶£çš„æƒ³æ³•ã€‚ä½ ä¸»è¦å¯¹å“ªç§ç¼–ç¨‹è¯­è¨€æˆ–é¢†åŸŸæ„Ÿå…´è¶£å‘¢ï¼Ÿæ¯”å¦‚ç½‘é¡µå¼€å‘ã€æ•°æ®åˆ†æã€æ¸¸æˆè®¾è®¡ï¼Œè¿˜æ˜¯å…¶ä»–æ–¹å‘ï¼Ÿ ğŸ˜Š\n",
      "human: æˆ‘åˆšæ‰è¯´æˆ‘å–œæ¬¢ä»€ä¹ˆï¼Ÿ\n",
      "ai: ä½ åˆšæ‰æåˆ°ä½ å–œæ¬¢ç¼–ç¨‹ï¼éœ€è¦æˆ‘æ¨èä¸€äº›å­¦ä¹ èµ„æºã€é¡¹ç›®çµæ„Ÿï¼Œæˆ–è€…èŠèŠç¼–ç¨‹ç›¸å…³çš„è¯é¢˜å—ï¼Ÿ ğŸ˜„\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.chat_history import BaseChatMessageHistory, InMemoryChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# åŠ è½½ç¯å¢ƒå˜é‡ï¼ˆç¡®ä¿.envæ–‡ä»¶ä¸­é…ç½®äº†API_KEYï¼‰\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "BASE_URL = \"https://api.deepseek.com\"\n",
    "\n",
    "# åˆå§‹åŒ–LLMæ¨¡å‹\n",
    "llm = ChatOpenAI(\n",
    "    api_key=API_KEY,\n",
    "    base_url=BASE_URL,\n",
    "    model=\"deepseek-chat\",\n",
    "    temperature=0.3  # é™ä½éšæœºæ€§ï¼Œä¿è¯è¾“å‡ºç¨³å®š\n",
    ")\n",
    "\n",
    "# 1. å®šä¹‰æç¤ºè¯æ¨¡æ¿ï¼ˆåŒ…å«å†å²æ¶ˆæ¯å ä½ç¬¦ï¼‰\n",
    "full_memory_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ä½ æ˜¯å‹å¥½çš„å¯¹è¯åŠ©æ‰‹ï¼Œéœ€åŸºäºå®Œæ•´çš„å†å²å¯¹è¯å›ç­”ç”¨æˆ·é—®é¢˜ã€‚\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),  # å†å²æ¶ˆæ¯å ä½ç¬¦\n",
    "    (\"human\", \"{user_input}\")  # ç”¨æˆ·å½“å‰è¾“å…¥\n",
    "])\n",
    "\n",
    "# 2. æ„å»ºåŸºç¡€é“¾ï¼ˆæç¤ºè¯ + LLMï¼‰\n",
    "base_chain = full_memory_prompt | llm\n",
    "\n",
    "# 3. ä¼šè¯å†å²å­˜å‚¨ï¼ˆå†…å­˜æ¨¡å¼ï¼Œç”Ÿäº§ç¯å¢ƒå¯æ›¿æ¢ä¸ºæ•°æ®åº“å­˜å‚¨ï¼‰\n",
    "full_memory_store = {}\n",
    "\n",
    "# 4. å®šä¹‰ä¼šè¯å†å²è·å–å‡½æ•°ï¼ˆæ ¸å¿ƒï¼šè¿”å›å®Œæ•´å†å²ï¼‰\n",
    "def get_full_memory_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    \"\"\"æ ¹æ®session_idè·å–ä¼šè¯å†å²ï¼Œä¸å­˜åœ¨åˆ™åˆ›å»ºæ–°çš„å†å²è®°å½•\"\"\"\n",
    "    if session_id not in full_memory_store:\n",
    "        full_memory_store[session_id] = InMemoryChatMessageHistory()\n",
    "    return full_memory_store[session_id]\n",
    "\n",
    "# 5. æ„å»ºå¸¦å…¨é‡è®°å¿†çš„å¯¹è¯é“¾\n",
    "full_memory_chain = RunnableWithMessageHistory(\n",
    "    runnable=base_chain,\n",
    "    get_session_history=get_full_memory_history,\n",
    "    input_messages_key=\"user_input\",  # è¾“å…¥ä¸­ç”¨æˆ·é—®é¢˜çš„é”®å\n",
    "    history_messages_key=\"chat_history\"  # ä¼ å…¥æç¤ºè¯çš„å†å²æ¶ˆæ¯é”®å\n",
    ")\n",
    "\n",
    "# æµ‹è¯•å¤šè½®å¯¹è¯ï¼ˆæŒ‡å®šsession_id=user_001ï¼Œéš”ç¦»ä¸åŒç”¨æˆ·ï¼‰\n",
    "config = {\"configurable\": {\"session_id\": \"user_001\"}}\n",
    "\n",
    "# ç¬¬ä¸€è½®å¯¹è¯\n",
    "response1 = full_memory_chain.invoke({\"user_input\": \"æˆ‘å«å°æ˜ï¼Œå–œæ¬¢ç¼–ç¨‹\"}, config=config)\n",
    "print(\"åŠ©æ‰‹å›å¤1ï¼š\", response1.content)\n",
    "# è¾“å‡ºç¤ºä¾‹ï¼šä½ å¥½å°æ˜ï¼ç¼–ç¨‹æ˜¯ä¸€é¡¹å¾ˆæœ‰åˆ›é€ åŠ›çš„æŠ€èƒ½ï¼Œä½ å¹³æ—¶å¸¸ç”¨ä»€ä¹ˆç¼–ç¨‹è¯­è¨€å‘¢ï¼Ÿ\n",
    "\n",
    "# ç¬¬äºŒè½®å¯¹è¯ï¼ˆéªŒè¯è®°å¿†ï¼šè¯¢é—®å†å²ä¿¡æ¯ï¼‰\n",
    "response2 = full_memory_chain.invoke({\"user_input\": \"æˆ‘åˆšæ‰è¯´æˆ‘å–œæ¬¢ä»€ä¹ˆï¼Ÿ\"}, config=config)\n",
    "print(\"åŠ©æ‰‹å›å¤2ï¼š\", response2.content)\n",
    "\n",
    "# æŸ¥çœ‹å®Œæ•´å†å²è®°å½•\n",
    "print(\"\\nå…¨é‡è®°å¿†çš„å¯¹è¯å†å²ï¼š\")\n",
    "for msg in get_full_memory_history(\"user_001\").messages:\n",
    "    print(f\"{msg.type}: {msg.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc2bbb79",
   "metadata": {},
   "source": [
    "#### 3.1.2.2 çª—å£è®°å¿†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ca5e399",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ç¬¬1è½® - åŠ©æ‰‹å›å¤ï¼š ä½ å¥½å°çº¢ï¼å¾ˆé«˜å…´è®¤è¯†ä½ ï¼æœ‰ä»€ä¹ˆæˆ‘å¯ä»¥å¸®åŠ©ä½ çš„å—ï¼Ÿ\n",
      "\n",
      "ç¬¬2è½® - åŠ©æ‰‹å›å¤ï¼š ç”»ç”»æ˜¯å¾ˆæ£’çš„çˆ±å¥½å‘¢ï¼ä½ é€šå¸¸å–œæ¬¢ç”»ä»€ä¹ˆç±»å‹çš„ä½œå“å‘¢ï¼Ÿæ¯”å¦‚é£æ™¯ã€äººç‰©ï¼Œè¿˜æ˜¯æŠ½è±¡ç”»ï¼Ÿ\n",
      "\n",
      "ç¬¬3è½® - åŠ©æ‰‹å›å¤ï¼š ä¸Šæµ·æ˜¯ä¸ªå……æ»¡è‰ºæœ¯æ°”æ¯çš„åŸå¸‚å‘¢ï¼å¤–æ»©çš„å¤œæ™¯ã€çŸ³åº“é—¨çš„è€å»ºç­‘ï¼Œè¿˜æœ‰å„ç§ç¾æœ¯é¦†å’Œåˆ›æ„å›­åŒºï¼Œåº”è¯¥ç»™ä½ å¸¦æ¥ä¸å°‘åˆ›ä½œçµæ„Ÿå§ï¼Ÿä½ å¹³æ—¶ä¼šç”»ä¸€äº›ä¸Šæµ·çš„åŸå¸‚é£æ™¯å—ï¼Ÿ\n",
      "\n",
      "ç¬¬4è½® - åŠ©æ‰‹å›å¤ï¼š å­¦ç”Ÿæ—¶æœŸèƒ½æœ‰æ—¶é—´åšæŒç”»ç”»çœŸçš„å¾ˆçè´µå‘¢ï¼ä½ æ˜¯è‰ºæœ¯ä¸“ä¸šçš„å­¦ç”Ÿï¼Œè¿˜æ˜¯æŠŠç”»ç”»å½“ä½œè¯¾ä½™çˆ±å¥½ï¼Ÿå¦‚æœæ–¹ä¾¿çš„è¯ï¼Œå¯ä»¥åˆ†äº«ä¸€ä¸‹æœ€è¿‘åœ¨ç”»çš„ä½œå“å—ï¼Ÿ\n",
      "\n",
      "ç¬¬5è½® - åŠ©æ‰‹å›å¤ï¼š ä½ åˆšæ‰æåˆ°ä½ æ¥è‡ª**ä¸Šæµ·**ã€‚è¿™åº§åŸå¸‚æ—¢æœ‰ç°ä»£éƒ½å¸‚çš„æ´»åŠ›ï¼Œåˆä¿ç•™ç€ä¸°å¯Œçš„å†å²æ–‡åŒ–ç—•è¿¹ï¼Œç¡®å®å¾ˆé€‚åˆä½œä¸ºè‰ºæœ¯åˆ›ä½œçš„çµæ„Ÿæ¥æºå‘¢ï¼\n",
      "\n",
      "çª—å£è®°å¿†çš„æœ€ç»ˆå¯¹è¯å†å²ï¼ˆæœ€è¿‘2è½®ï¼‰ï¼š\n",
      "human: æˆ‘æ˜¯ä¸€åå­¦ç”Ÿ\n",
      "ai: å­¦ç”Ÿæ—¶æœŸèƒ½æœ‰æ—¶é—´åšæŒç”»ç”»çœŸçš„å¾ˆçè´µå‘¢ï¼ä½ æ˜¯è‰ºæœ¯ä¸“ä¸šçš„å­¦ç”Ÿï¼Œè¿˜æ˜¯æŠŠç”»ç”»å½“ä½œè¯¾ä½™çˆ±å¥½ï¼Ÿå¦‚æœæ–¹ä¾¿çš„è¯ï¼Œå¯ä»¥åˆ†äº«ä¸€ä¸‹æœ€è¿‘åœ¨ç”»çš„ä½œå“å—ï¼Ÿ\n",
      "human: æˆ‘åˆšæ‰è¯´æˆ‘æ¥è‡ªå“ªé‡Œï¼Ÿ\n",
      "ai: ä½ åˆšæ‰æåˆ°ä½ æ¥è‡ª**ä¸Šæµ·**ã€‚è¿™åº§åŸå¸‚æ—¢æœ‰ç°ä»£éƒ½å¸‚çš„æ´»åŠ›ï¼Œåˆä¿ç•™ç€ä¸°å¯Œçš„å†å²æ–‡åŒ–ç—•è¿¹ï¼Œç¡®å®å¾ˆé€‚åˆä½œä¸ºè‰ºæœ¯åˆ›ä½œçš„çµæ„Ÿæ¥æºå‘¢ï¼\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.chat_history import BaseChatMessageHistory, InMemoryChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# åŠ è½½ç¯å¢ƒå˜é‡ï¼ˆç¡®ä¿.envæ–‡ä»¶ä¸­é…ç½®äº†API_KEYï¼‰\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "BASE_URL = \"https://api.deepseek.com\"\n",
    "\n",
    "# åˆå§‹åŒ–LLMæ¨¡å‹\n",
    "llm = ChatOpenAI(\n",
    "    api_key=API_KEY,\n",
    "    base_url=BASE_URL,\n",
    "    model=\"deepseek-chat\",\n",
    "    temperature=0.3  # é™ä½éšæœºæ€§ï¼Œä¿è¯è¾“å‡ºç¨³å®š\n",
    ")\n",
    "\n",
    "# 1. å®šä¹‰æç¤ºè¯æ¨¡æ¿ï¼ˆä¸å…¨é‡è®°å¿†é€šç”¨ï¼Œå¯å¤ç”¨ï¼‰\n",
    "window_memory_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ä½ æ˜¯å‹å¥½çš„å¯¹è¯åŠ©æ‰‹ï¼Œéœ€åŸºäºæœ€è¿‘çš„å¯¹è¯å†å²å›ç­”ç”¨æˆ·é—®é¢˜ã€‚\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{user_input}\")\n",
    "])\n",
    "\n",
    "# 2. æ„å»ºåŸºç¡€é“¾\n",
    "window_base_chain = window_memory_prompt | llm\n",
    "\n",
    "# 3. ä¼šè¯å†å²å­˜å‚¨\n",
    "window_memory_store = {}\n",
    "WINDOW_SIZE = 2  # ä¿ç•™æœ€è¿‘2è½®å¯¹è¯ï¼ˆå³æœ€è¿‘4æ¡æ¶ˆæ¯ï¼šç”¨æˆ·-åŠ©æ‰‹-ç”¨æˆ·-åŠ©æ‰‹ï¼‰\n",
    "\n",
    "# 4. å®šä¹‰å¸¦çª—å£é™åˆ¶çš„ä¼šè¯å†å²è·å–å‡½æ•°\n",
    "def get_window_memory_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    \"\"\"è·å–ä¼šè¯å†å²ï¼Œä»…ä¿ç•™æœ€è¿‘WINDOW_SIZEè½®å¯¹è¯\"\"\"\n",
    "    if session_id not in window_memory_store:\n",
    "        window_memory_store[session_id] = InMemoryChatMessageHistory()\n",
    "    \n",
    "    # è·å–å®Œæ•´å†å²ï¼Œæˆªå–æœ€è¿‘WINDOW_SIZEè½®ï¼ˆæ¯è½®2æ¡æ¶ˆæ¯ï¼‰\n",
    "    history = window_memory_store[session_id]\n",
    "    if len(history.messages) > 2 * WINDOW_SIZE:\n",
    "        # æˆªå–åWINDOW_SIZEè½®æ¶ˆæ¯ï¼ˆä¿ç•™æœ€æ–°çš„ï¼‰\n",
    "        history.messages = history.messages[-2 * WINDOW_SIZE:]\n",
    "    return history\n",
    "\n",
    "# 5. æ„å»ºå¸¦çª—å£è®°å¿†çš„å¯¹è¯é“¾\n",
    "window_memory_chain = RunnableWithMessageHistory(\n",
    "    runnable=window_base_chain,\n",
    "    get_session_history=get_window_memory_history,\n",
    "    input_messages_key=\"user_input\",\n",
    "    history_messages_key=\"chat_history\"\n",
    ")\n",
    "\n",
    "# æµ‹è¯•å¤šè½®å¯¹è¯ï¼ˆsession_id=user_002ï¼Œä¸å…¨é‡è®°å¿†ä¼šè¯éš”ç¦»ï¼‰\n",
    "config = {\"configurable\": {\"session_id\": \"user_002\"}}\n",
    "\n",
    "# æ¨¡æ‹Ÿ5è½®å¯¹è¯ï¼ŒéªŒè¯çª—å£è®°å¿†çš„æˆªæ–­æ•ˆæœ\n",
    "inputs = [\n",
    "    \"æˆ‘å«å°çº¢\",\n",
    "    \"æˆ‘å–œæ¬¢ç”»ç”»\",\n",
    "    \"æˆ‘æ¥è‡ªä¸Šæµ·\",\n",
    "    \"æˆ‘æ˜¯ä¸€åå­¦ç”Ÿ\",\n",
    "    \"æˆ‘åˆšæ‰è¯´æˆ‘æ¥è‡ªå“ªé‡Œï¼Ÿ\"  # ç¬¬5è½®ï¼šè¯¢é—®ç¬¬3è½®çš„ä¿¡æ¯ï¼ŒéªŒè¯çª—å£æˆªæ–­\n",
    "]\n",
    "\n",
    "for i, user_input in enumerate(inputs, 1):\n",
    "    response = window_memory_chain.invoke({\"user_input\": user_input}, config=config)\n",
    "    print(f\"\\nç¬¬{i}è½® - åŠ©æ‰‹å›å¤ï¼š\", response.content)\n",
    "\n",
    "# æŸ¥çœ‹çª—å£è®°å¿†çš„æœ€ç»ˆå†å²ï¼ˆä»…ä¿ç•™æœ€è¿‘2è½®ï¼‰\n",
    "print(\"\\nçª—å£è®°å¿†çš„æœ€ç»ˆå¯¹è¯å†å²ï¼ˆæœ€è¿‘2è½®ï¼‰ï¼š\")\n",
    "for msg in get_window_memory_history(\"user_002\").messages:\n",
    "    print(f\"{msg.type}: {msg.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0081a3",
   "metadata": {},
   "source": [
    "#### 3.1.2.3 æ‘˜è¦è®°å¿†"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d09703c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ç¬¬1è½® - åŠ©æ‰‹å›å¤ï¼š ä½ å¥½å°æï¼å¾ˆé«˜å…´è®¤è¯†ä½ ï¼ä½œä¸ºäº§å“ç»ç†ï¼Œä½ çš„å·¥ä½œä¸€å®šå……æ»¡æŒ‘æˆ˜å’Œåˆ›æ„å§ï¼Ÿå¦‚æœéœ€è¦è®¨è®ºäº§å“è®¾è®¡ã€ç”¨æˆ·éœ€æ±‚æˆ–ä»»ä½•ç›¸å…³è¯é¢˜ï¼Œæˆ‘éšæ—¶å¯ä»¥å¸®å¿™å“¦ï¼ ğŸ˜Š\n",
      "\n",
      "ç¬¬2è½® - åŠ©æ‰‹å›å¤ï¼š å¾ˆé«˜å…´èƒ½ä¸ºæ‚¨æä¾›æ”¯æŒï¼ä½œä¸ºäº§å“ç»ç†ï¼Œæ‚¨å¯¹ç”µå•†APPçš„è¿­ä»£æœ‰ä»€ä¹ˆå…·ä½“æƒ³æ³•æˆ–éœ€è¦è®¨è®ºçš„æ–¹å‘å—ï¼Ÿæ¯”å¦‚ç”¨æˆ·éœ€æ±‚åˆ†æã€åŠŸèƒ½ä¼˜åŒ–ï¼Œè¿˜æ˜¯ç”¨æˆ·ä½“éªŒè®¾è®¡ï¼Ÿ\n",
      "\n",
      "ç¬¬3è½® - åŠ©æ‰‹å›å¤ï¼š å¥½çš„ï¼Œå°æã€‚ä¼˜åŒ–ä¸‹å•æµç¨‹æ˜¯æå‡è½¬åŒ–ç‡å’Œç”¨æˆ·ä½“éªŒçš„å…³é”®ã€‚åŸºäºæˆ‘ä»¬ä¹‹å‰çš„è®¨è®ºï¼Œæˆ‘ä»¬å¯ä»¥ä»å‡ ä¸ªæ ¸å¿ƒæ–¹å‘åˆ‡å…¥ï¼š\n",
      "\n",
      "1.  **ç®€åŒ–ä¸æé€Ÿ**ï¼šè¿™æ˜¯æœ€ç›´æ¥çš„ä¼˜åŒ–ç‚¹ã€‚æˆ‘ä»¬å¯ä»¥åˆ†æå½“å‰æµç¨‹çš„æ­¥éª¤æ•°ã€å¿…å¡«å­—æ®µå’Œé¡µé¢è·³è½¬ã€‚ç›®æ ‡æ˜¯è®©æ ¸å¿ƒç”¨æˆ·ï¼ˆå¦‚å·²ç™»å½•ã€æœ‰é»˜è®¤åœ°å€ï¼‰èƒ½åœ¨**3æ­¥å†…ã€15ç§’å†…**å®Œæˆä¸‹å•ã€‚å…·ä½“å¯ä»¥ï¼š\n",
      "    *   **å‡å°‘éå¿…è¦ä¿¡æ¯**ï¼šä¾‹å¦‚ï¼Œå¯¹å¤§éƒ¨åˆ†å•†å“éšè—â€œå‘ç¥¨ä¿¡æ¯â€å¡«å†™ï¼Œæ”¹ä¸ºå¯é€‰é¡¹ã€‚\n",
      "    *   **æ™ºèƒ½å¡«å……ä¸é¢„æµ‹**ï¼šåœ°å€è‡ªåŠ¨è”æƒ³ï¼Œæ ¹æ®å†å²è´­ä¹°è®°å½•é¢„é€‰æ”¯ä»˜æ–¹å¼ã€‚\n",
      "    *   **æµç¨‹åˆå¹¶**ï¼šå°†â€œç¡®è®¤è®¢å•â€å’Œâ€œæ”¯ä»˜â€é¡µé¢çš„ä¿¡æ¯å†æ¬¡ç²¾ç®€ï¼Œå°è¯•â€œä¸€é”®ä¸‹å•â€æ¨¡å¼ï¼ˆåœ¨å•†å“é¡µç›´æ¥ç»“ç®—ï¼‰ã€‚\n",
      "\n",
      "2.  **æ¸…æ™°ä¸ä¿¡ä»»**ï¼šåœ¨ç®€åŒ–åŒæ—¶ï¼Œå¿…é¡»ç¡®ä¿å…³é”®ä¿¡æ¯é€æ˜ï¼Œæ¶ˆé™¤ç”¨æˆ·ç–‘è™‘ã€‚\n",
      "    *   **è´¹ç”¨æ˜ç»†å®æ—¶æ±‡æ€»**ï¼šå•†å“ä»·ã€è¿è´¹ã€ä¼˜æƒ åˆ¸æŠµæ‰£ã€å®ä»˜é‡‘é¢å¿…é¡»æ¸…æ™°ã€å®æ—¶è®¡ç®—å¹¶çªå‡ºæ˜¾ç¤ºã€‚\n",
      "    *   **åº“å­˜ä¸æ—¶æ•ˆå¼ºåŒ–æç¤º**ï¼šå¯¹ç´§ä¿å•†å“ï¼Œåœ¨è®¢å•é¡µæ˜æ˜¾æç¤ºåº“å­˜æ•°é‡ï¼›é¢„ä¼°é€è¾¾æ—¶é—´éœ€è¦æ›´é†’ç›®ã€‚\n",
      "    *   **ä¿¡ä»»ç¬¦å·**ï¼šåœ¨æ”¯ä»˜æŒ‰é’®é™„è¿‘å±•ç¤ºå®‰å…¨æ”¯ä»˜ã€éšç§ä¿æŠ¤ç­‰å›¾æ ‡æˆ–ç®€çŸ­æ–‡æ¡ˆã€‚\n",
      "\n",
      "3.  **å®¹é”™ä¸å¼•å¯¼**ï¼šä¼˜åŒ–ä¸ä»…è¦ä¸ºé¡ºåˆ©æµç¨‹è®¾è®¡ï¼Œä¹Ÿè¦ä¸ºä¸­æ–­å’ŒçŠ¹è±«è®¾è®¡ã€‚\n",
      "    *   **éšæ—¶å¯è¿”å›ä¿®æ”¹**ï¼šç”¨æˆ·èƒ½æ–¹ä¾¿åœ°è¿”å›ä¿®æ”¹åœ°å€ã€ä¼˜æƒ åˆ¸æˆ–å•†å“æ•°é‡ï¼Œè€Œæ— éœ€å–æ¶ˆæ•´ä¸ªè®¢å•ã€‚\n",
      "    *   **å¼‚å¸¸çŠ¶æ€å‹å¥½æç¤º**ï¼šå¦‚å•†å“ä»·æ ¼å˜åŠ¨ã€åº“å­˜å”®ç½„ï¼Œæç¤ºè¯­è¦æ¸…æ™°å¹¶ç»™å‡ºæ˜ç¡®æ›¿ä»£æ–¹æ¡ˆï¼ˆå¦‚â€œè¯¥å•†å“å·²å”®ç½„ï¼ŒæŸ¥çœ‹ç›¸ä¼¼å•†å“â€ï¼‰ã€‚\n",
      "    *   **ä¿ƒè¿›å†³ç­–**ï¼šåœ¨ç”¨æˆ·åœç•™æ—¶é—´è¾ƒé•¿çš„ç¯èŠ‚ï¼ˆå¦‚é€‰æ‹©ä¼˜æƒ åˆ¸æ—¶ï¼‰ï¼Œå¯ä»¥åŠ å…¥â€œXX%çš„ç”¨æˆ·é€‰æ‹©äº†XXæ”¯ä»˜â€ç­‰è½»é‡å¼•å¯¼ã€‚\n",
      "\n",
      "**ä¸ºäº†ç²¾å‡†æ¨è¿›ï¼Œæˆ‘å»ºè®®æˆ‘ä»¬ä¸‹ä¸€æ­¥ï¼š**\n",
      "\n",
      "*   **æ•°æ®è¯Šæ–­**ï¼šæˆ‘ä»¬å…ˆæ‹‰å–æœ€è¿‘ä¸€ä¸ªæœˆçš„ä¸‹å•è½¬åŒ–æ¼æ–—æ•°æ®ï¼Œå®šä½æµå¤±æœ€é«˜çš„å…·ä½“æ­¥éª¤ã€‚\n",
      "*   **ç”¨æˆ·è°ƒç ”**ï¼šå¯¹åœ¨å…³é”®æ­¥éª¤æµå¤±çš„ç”¨æˆ·è¿›è¡ŒæŠ½æ ·è®¿è°ˆï¼Œäº†è§£ä»–ä»¬çš„å…·ä½“å›°æƒ‘æˆ–æ”¾å¼ƒåŸå› ã€‚\n",
      "*   **ç«å“å¯¹æ¯”**ï¼šå¿«é€Ÿèµ°æŸ¥2-3ä¸ªä¸»æµç«å“çš„æœ€æ–°ä¸‹å•æµç¨‹ï¼Œæˆªå›¾æ ‡æ³¨å¯å€Ÿé‰´ç‚¹ã€‚\n",
      "\n",
      "ä½ æ›´æƒ³ä¼˜å…ˆä»å“ªä¸ªç¯èŠ‚å¼€å§‹æ·±æŒ–ï¼Ÿæˆ–è€…å¯¹ä¸Šè¿°æ–¹å‘æœ‰ä»€ä¹ˆè¡¥å……æƒ³æ³•ï¼Ÿ\n",
      "\n",
      "ç¬¬4è½® - åŠ©æ‰‹å›å¤ï¼š é’ˆå¯¹ç”¨æˆ·æµå¤±ç‡é«˜çš„é—®é¢˜ï¼Œç»“åˆæ‚¨ä¹‹å‰å…³æ³¨çš„**ä¸‹å•æµç¨‹ä¼˜åŒ–**ï¼Œå»ºè®®ä»ä»¥ä¸‹è§’åº¦åˆ‡å…¥æ’æŸ¥ä¸æ”¹è¿›ï¼š\n",
      "\n",
      "---\n",
      "\n",
      "### 1ï¸âƒ£ **ä¼˜å…ˆè¯Šæ–­æµå¤±å…³é”®èŠ‚ç‚¹**\n",
      "- **æ•°æ®åˆ†æ**ï¼šé€šè¿‡ç”¨æˆ·è¡Œä¸ºæ¼æ–—ï¼ˆå¦‚æµè§ˆâ†’åŠ è´­â†’ä¸‹å•â†’æ”¯ä»˜ï¼‰ï¼Œå®šä½æµå¤±æœ€ä¸¥é‡çš„æ­¥éª¤ï¼ˆä¾‹å¦‚æ˜¯å¦åœ¨æ”¯ä»˜å‰å¤§é‡æ”¾å¼ƒï¼Ÿï¼‰ã€‚\n",
      "- **ç”¨æˆ·åé¦ˆ**ï¼šæ”¶é›†æµå¤±ç”¨æˆ·çš„è°ƒç ”æˆ–å®¢æœè®°å½•ï¼Œå…³æ³¨â€œæµç¨‹å¤æ‚â€â€œä¿¡æ¯ä¸é€æ˜â€â€œæ“ä½œå¤±è¯¯åæ— æ³•æŒ½å›â€ç­‰é«˜é¢‘é—®é¢˜ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### 2ï¸âƒ£ **é’ˆå¯¹æ€§ä¼˜åŒ–ä¸‹å•æµç¨‹**\n",
      "- **ç®€åŒ–æ­¥éª¤**ï¼šå¦‚åˆå¹¶éå¿…è¦é¡µé¢ï¼ˆåœ°å€/æ”¯ä»˜æ–¹å¼é€‰æ‹©ï¼‰ã€æä¾›â€œä¸€é”®é‡æ–°è´­ä¹°â€åŠŸèƒ½ã€‚\n",
      "- **æå‡é€æ˜åº¦**ï¼šæ˜ç¡®å±•ç¤ºè¿è´¹ã€ä¼˜æƒ åˆ¸æŠµæ‰£ã€é¢„è®¡é€è¾¾æ—¶é—´ï¼Œå‡å°‘ç»“ç®—æ—¶çš„â€œæ„å¤–æˆæœ¬â€ã€‚\n",
      "- **å¼ºåŒ–å®¹é”™ä¸å¼•å¯¼**ï¼š  \n",
      "  - æ”¯ä»˜å¤±è´¥æ—¶è‡ªåŠ¨ä¿å­˜è®¢å•ï¼Œå¹¶æä¾›æ¸…æ™°çš„é”™è¯¯åŸå› ä¸è§£å†³å»ºè®®ï¼ˆå¦‚æ›´æ¢æ”¯ä»˜æ–¹å¼ï¼‰ã€‚  \n",
      "  - åœ¨å…³é”®æ­¥éª¤ï¼ˆå¦‚æäº¤è®¢å•å‰ï¼‰å¢åŠ è¿›åº¦æç¤ºæˆ–æ“ä½œç¡®è®¤ï¼Œå‡å°‘è¯¯æ“ä½œå¯¼è‡´çš„æµå¤±ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### 3ï¸âƒ£ **å»ºç«‹æµå¤±é¢„è­¦ä¸æŒ½å›æœºåˆ¶**\n",
      "- **å®æ—¶ç›‘æ§**ï¼šå¯¹åœç•™æ—¶é—´è¿‡é•¿ã€åå¤è¿”å›ä¿®æ”¹çš„è®¢å•è¿›è¡Œä¸»åŠ¨å¹²é¢„ï¼ˆå¦‚å¼¹å‡ºå®¢æœå¸®åŠ©æˆ–ä¼˜æƒ æ¿€åŠ±ï¼‰ã€‚\n",
      "- **æµå¤±åè§¦è¾¾**ï¼šå¯¹æ”¾å¼ƒè®¢å•çš„ç”¨æˆ·ï¼Œé€šè¿‡APPæ¨é€æˆ–çŸ­ä¿¡ï¼Œåœ¨é€‚å½“æ—¶æœºï¼ˆå¦‚1å°æ—¶åï¼‰å‘é€ä¸ªæ€§åŒ–æé†’æˆ–é™æ—¶ä¼˜æƒ ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### 4ï¸âƒ£ **åç»­éªŒè¯ä¸è¿­ä»£**\n",
      "- **A/Bæµ‹è¯•**ï¼šå¯¹ä¼˜åŒ–æ–¹æ¡ˆï¼ˆå¦‚æ–°ç‰ˆç»“ç®—é¡µï¼‰è¿›è¡Œå°æµé‡æµ‹è¯•ï¼Œå¯¹æ¯”è½¬åŒ–ç‡ä¸æµå¤±ç‡å˜åŒ–ã€‚\n",
      "- **é•¿æœŸè¿½è¸ª**ï¼šå»ºç«‹æ ¸å¿ƒæŒ‡æ ‡çœ‹æ¿ï¼ˆå¦‚è®¢å•å®Œæˆç‡ã€ç”¨æˆ·å¤è´­ç‡ï¼‰ï¼ŒæŒç»­è§‚å¯Ÿä¼˜åŒ–æ•ˆæœã€‚\n",
      "\n",
      "---\n",
      "\n",
      "å¦‚æœéœ€è¦è¿›ä¸€æ­¥åˆ†æï¼Œå¯ä»¥åˆ†äº«å…·ä½“æµå¤±ç¯èŠ‚çš„æ•°æ®æˆ–ç”¨æˆ·åé¦ˆï¼Œæˆ‘ä¼šå¸®æ‚¨ç»†åŒ–è§£å†³æ–¹æ¡ˆã€‚\n",
      "\n",
      "ç¬¬5è½® - åŠ©æ‰‹å›å¤ï¼š æ ¹æ®æ‘˜è¦ï¼Œé’ˆå¯¹ç”µå•†APPä¸‹å•æµç¨‹çš„é«˜æµå¤±ç‡ï¼Œå»ºè®®ä»ä»¥ä¸‹å››æ–¹é¢ä¼˜åŒ–ï¼š  \n",
      "1. **ç®€åŒ–æ­¥éª¤**ï¼šåˆå¹¶æˆ–åˆ å‡éå¿…è¦é¡µé¢ï¼ˆå¦‚ç¡®è®¤é¡µäºŒæ¬¡è·³è½¬ï¼‰ï¼Œå°è¯•â€œä¸€é”®ä¸‹å•â€æˆ–è¿›åº¦æ¡ç›´è§‚å±•ç¤ºã€‚  \n",
      "2. **ä¿¡æ¯é€æ˜**ï¼šå®æ—¶å±•ç¤ºè¿è´¹ã€åº“å­˜ã€ä¼˜æƒ åˆ¸æŠµæ‰£ï¼Œé¿å…ç”¨æˆ·ä¸­é€”å› ä¿¡æ¯ä¸æ˜ç¡®æ”¾å¼ƒã€‚  \n",
      "3. **å®¹é”™ä¸å¼•å¯¼**ï¼šæä¾›æ¸…æ™°çš„é”™è¯¯æç¤ºï¼ˆå¦‚åœ°å€æ ¼å¼ä¸å¯¹ï¼‰ã€è‡ªåŠ¨ä¿å­˜è‰ç¨¿ï¼Œå¹¶å¢åŠ â€œå®¢æœæ‚¬æµ®çª—â€å³æ—¶ç­”ç–‘ã€‚  \n",
      "4. **æ•°æ®é©±åŠ¨è¿­ä»£**ï¼šé€šè¿‡åŸ‹ç‚¹åˆ†ææµå¤±èŠ‚ç‚¹ï¼Œç»“åˆç”¨æˆ·è®¿è°ˆå®šä½ç—›ç‚¹ï¼Œç”¨A/Bæµ‹è¯•éªŒè¯æ–¹æ¡ˆï¼ˆä¾‹å¦‚å¯¹æ¯”ä¸¤ç§ä¸‹å•æŒ‰é’®è®¾è®¡ï¼‰ã€‚  \n",
      "éœ€è¦æ›´å…·ä½“çš„æŸç¯èŠ‚å»ºè®®ï¼Œå¯è¿›ä¸€æ­¥è®¨è®ºï¼\n",
      "\n",
      "æ‘˜è¦è®°å¿†çš„å®Œæ•´å¯¹è¯å†å²ï¼š\n",
      "human: æˆ‘å«å°æï¼Œæ˜¯ä¸€åäº§å“ç»ç†\n",
      "ai: ä½ å¥½å°æï¼å¾ˆé«˜å…´è®¤è¯†ä½ ï¼ä½œä¸ºäº§å“ç»ç†ï¼Œä½ çš„å·¥ä½œä¸€å®šå……æ»¡æŒ‘æˆ˜å’Œåˆ›æ„å§ï¼Ÿå¦‚æœéœ€è¦è®¨è®ºäº§å“è®¾è®¡ã€ç”¨æˆ·éœ€æ±‚æˆ–ä»»ä½•ç›¸å…³è¯é¢˜ï¼Œæˆ‘éšæ—¶å¯ä»¥å¸®å¿™å“¦ï¼ ğŸ˜Š\n",
      "human: æˆ‘è´Ÿè´£ä¸€æ¬¾ç”µå•†APPçš„è¿­ä»£\n",
      "ai: å¾ˆé«˜å…´èƒ½ä¸ºæ‚¨æä¾›æ”¯æŒï¼ä½œä¸ºäº§å“ç»ç†ï¼Œæ‚¨å¯¹ç”µå•†APPçš„è¿­ä»£æœ‰ä»€ä¹ˆå…·ä½“æƒ³æ³•æˆ–éœ€è¦è®¨è®ºçš„æ–¹å‘å—ï¼Ÿæ¯”å¦‚ç”¨æˆ·éœ€æ±‚åˆ†æã€åŠŸèƒ½ä¼˜åŒ–ï¼Œè¿˜æ˜¯ç”¨æˆ·ä½“éªŒè®¾è®¡ï¼Ÿ\n",
      "human: æœ€è¿‘åœ¨ä¼˜åŒ–ç”¨æˆ·ä¸‹å•æµç¨‹\n",
      "ai: å¥½çš„ï¼Œå°æã€‚ä¼˜åŒ–ä¸‹å•æµç¨‹æ˜¯æå‡è½¬åŒ–ç‡å’Œç”¨æˆ·ä½“éªŒçš„å…³é”®ã€‚åŸºäºæˆ‘ä»¬ä¹‹å‰çš„è®¨è®ºï¼Œæˆ‘ä»¬å¯ä»¥ä»å‡ ä¸ªæ ¸å¿ƒæ–¹å‘åˆ‡å…¥ï¼š\n",
      "\n",
      "1.  **ç®€åŒ–ä¸æé€Ÿ**ï¼šè¿™æ˜¯æœ€ç›´æ¥çš„ä¼˜åŒ–ç‚¹ã€‚æˆ‘ä»¬å¯ä»¥åˆ†æå½“å‰æµç¨‹çš„æ­¥éª¤æ•°ã€å¿…å¡«å­—æ®µå’Œé¡µé¢è·³è½¬ã€‚ç›®æ ‡æ˜¯è®©æ ¸å¿ƒç”¨æˆ·ï¼ˆå¦‚å·²ç™»å½•ã€æœ‰é»˜è®¤åœ°å€ï¼‰èƒ½åœ¨**3æ­¥å†…ã€15ç§’å†…**å®Œæˆä¸‹å•ã€‚å…·ä½“å¯ä»¥ï¼š\n",
      "    *   **å‡å°‘éå¿…è¦ä¿¡æ¯**ï¼šä¾‹å¦‚ï¼Œå¯¹å¤§éƒ¨åˆ†å•†å“éšè—â€œå‘ç¥¨ä¿¡æ¯â€å¡«å†™ï¼Œæ”¹ä¸ºå¯é€‰é¡¹ã€‚\n",
      "    *   **æ™ºèƒ½å¡«å……ä¸é¢„æµ‹**ï¼šåœ°å€è‡ªåŠ¨è”æƒ³ï¼Œæ ¹æ®å†å²è´­ä¹°è®°å½•é¢„é€‰æ”¯ä»˜æ–¹å¼ã€‚\n",
      "    *   **æµç¨‹åˆå¹¶**ï¼šå°†â€œç¡®è®¤è®¢å•â€å’Œâ€œæ”¯ä»˜â€é¡µé¢çš„ä¿¡æ¯å†æ¬¡ç²¾ç®€ï¼Œå°è¯•â€œä¸€é”®ä¸‹å•â€æ¨¡å¼ï¼ˆåœ¨å•†å“é¡µç›´æ¥ç»“ç®—ï¼‰ã€‚\n",
      "\n",
      "2.  **æ¸…æ™°ä¸ä¿¡ä»»**ï¼šåœ¨ç®€åŒ–åŒæ—¶ï¼Œå¿…é¡»ç¡®ä¿å…³é”®ä¿¡æ¯é€æ˜ï¼Œæ¶ˆé™¤ç”¨æˆ·ç–‘è™‘ã€‚\n",
      "    *   **è´¹ç”¨æ˜ç»†å®æ—¶æ±‡æ€»**ï¼šå•†å“ä»·ã€è¿è´¹ã€ä¼˜æƒ åˆ¸æŠµæ‰£ã€å®ä»˜é‡‘é¢å¿…é¡»æ¸…æ™°ã€å®æ—¶è®¡ç®—å¹¶çªå‡ºæ˜¾ç¤ºã€‚\n",
      "    *   **åº“å­˜ä¸æ—¶æ•ˆå¼ºåŒ–æç¤º**ï¼šå¯¹ç´§ä¿å•†å“ï¼Œåœ¨è®¢å•é¡µæ˜æ˜¾æç¤ºåº“å­˜æ•°é‡ï¼›é¢„ä¼°é€è¾¾æ—¶é—´éœ€è¦æ›´é†’ç›®ã€‚\n",
      "    *   **ä¿¡ä»»ç¬¦å·**ï¼šåœ¨æ”¯ä»˜æŒ‰é’®é™„è¿‘å±•ç¤ºå®‰å…¨æ”¯ä»˜ã€éšç§ä¿æŠ¤ç­‰å›¾æ ‡æˆ–ç®€çŸ­æ–‡æ¡ˆã€‚\n",
      "\n",
      "3.  **å®¹é”™ä¸å¼•å¯¼**ï¼šä¼˜åŒ–ä¸ä»…è¦ä¸ºé¡ºåˆ©æµç¨‹è®¾è®¡ï¼Œä¹Ÿè¦ä¸ºä¸­æ–­å’ŒçŠ¹è±«è®¾è®¡ã€‚\n",
      "    *   **éšæ—¶å¯è¿”å›ä¿®æ”¹**ï¼šç”¨æˆ·èƒ½æ–¹ä¾¿åœ°è¿”å›ä¿®æ”¹åœ°å€ã€ä¼˜æƒ åˆ¸æˆ–å•†å“æ•°é‡ï¼Œè€Œæ— éœ€å–æ¶ˆæ•´ä¸ªè®¢å•ã€‚\n",
      "    *   **å¼‚å¸¸çŠ¶æ€å‹å¥½æç¤º**ï¼šå¦‚å•†å“ä»·æ ¼å˜åŠ¨ã€åº“å­˜å”®ç½„ï¼Œæç¤ºè¯­è¦æ¸…æ™°å¹¶ç»™å‡ºæ˜ç¡®æ›¿ä»£æ–¹æ¡ˆï¼ˆå¦‚â€œè¯¥å•†å“å·²å”®ç½„ï¼ŒæŸ¥çœ‹ç›¸ä¼¼å•†å“â€ï¼‰ã€‚\n",
      "    *   **ä¿ƒè¿›å†³ç­–**ï¼šåœ¨ç”¨æˆ·åœç•™æ—¶é—´è¾ƒé•¿çš„ç¯èŠ‚ï¼ˆå¦‚é€‰æ‹©ä¼˜æƒ åˆ¸æ—¶ï¼‰ï¼Œå¯ä»¥åŠ å…¥â€œXX%çš„ç”¨æˆ·é€‰æ‹©äº†XXæ”¯ä»˜â€ç­‰è½»é‡å¼•å¯¼ã€‚\n",
      "\n",
      "**ä¸ºäº†ç²¾å‡†æ¨è¿›ï¼Œæˆ‘å»ºè®®æˆ‘ä»¬ä¸‹ä¸€æ­¥ï¼š**\n",
      "\n",
      "*   **æ•°æ®è¯Šæ–­**ï¼šæˆ‘ä»¬å…ˆæ‹‰å–æœ€è¿‘ä¸€ä¸ªæœˆçš„ä¸‹å•è½¬åŒ–æ¼æ–—æ•°æ®ï¼Œå®šä½æµå¤±æœ€é«˜çš„å…·ä½“æ­¥éª¤ã€‚\n",
      "*   **ç”¨æˆ·è°ƒç ”**ï¼šå¯¹åœ¨å…³é”®æ­¥éª¤æµå¤±çš„ç”¨æˆ·è¿›è¡ŒæŠ½æ ·è®¿è°ˆï¼Œäº†è§£ä»–ä»¬çš„å…·ä½“å›°æƒ‘æˆ–æ”¾å¼ƒåŸå› ã€‚\n",
      "*   **ç«å“å¯¹æ¯”**ï¼šå¿«é€Ÿèµ°æŸ¥2-3ä¸ªä¸»æµç«å“çš„æœ€æ–°ä¸‹å•æµç¨‹ï¼Œæˆªå›¾æ ‡æ³¨å¯å€Ÿé‰´ç‚¹ã€‚\n",
      "\n",
      "ä½ æ›´æƒ³ä¼˜å…ˆä»å“ªä¸ªç¯èŠ‚å¼€å§‹æ·±æŒ–ï¼Ÿæˆ–è€…å¯¹ä¸Šè¿°æ–¹å‘æœ‰ä»€ä¹ˆè¡¥å……æƒ³æ³•ï¼Ÿ\n",
      "human: é‡åˆ°äº†ç”¨æˆ·æµå¤±ç‡é«˜çš„é—®é¢˜\n",
      "ai: é’ˆå¯¹ç”¨æˆ·æµå¤±ç‡é«˜çš„é—®é¢˜ï¼Œç»“åˆæ‚¨ä¹‹å‰å…³æ³¨çš„**ä¸‹å•æµç¨‹ä¼˜åŒ–**ï¼Œå»ºè®®ä»ä»¥ä¸‹è§’åº¦åˆ‡å…¥æ’æŸ¥ä¸æ”¹è¿›ï¼š\n",
      "\n",
      "---\n",
      "\n",
      "### 1ï¸âƒ£ **ä¼˜å…ˆè¯Šæ–­æµå¤±å…³é”®èŠ‚ç‚¹**\n",
      "- **æ•°æ®åˆ†æ**ï¼šé€šè¿‡ç”¨æˆ·è¡Œä¸ºæ¼æ–—ï¼ˆå¦‚æµè§ˆâ†’åŠ è´­â†’ä¸‹å•â†’æ”¯ä»˜ï¼‰ï¼Œå®šä½æµå¤±æœ€ä¸¥é‡çš„æ­¥éª¤ï¼ˆä¾‹å¦‚æ˜¯å¦åœ¨æ”¯ä»˜å‰å¤§é‡æ”¾å¼ƒï¼Ÿï¼‰ã€‚\n",
      "- **ç”¨æˆ·åé¦ˆ**ï¼šæ”¶é›†æµå¤±ç”¨æˆ·çš„è°ƒç ”æˆ–å®¢æœè®°å½•ï¼Œå…³æ³¨â€œæµç¨‹å¤æ‚â€â€œä¿¡æ¯ä¸é€æ˜â€â€œæ“ä½œå¤±è¯¯åæ— æ³•æŒ½å›â€ç­‰é«˜é¢‘é—®é¢˜ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### 2ï¸âƒ£ **é’ˆå¯¹æ€§ä¼˜åŒ–ä¸‹å•æµç¨‹**\n",
      "- **ç®€åŒ–æ­¥éª¤**ï¼šå¦‚åˆå¹¶éå¿…è¦é¡µé¢ï¼ˆåœ°å€/æ”¯ä»˜æ–¹å¼é€‰æ‹©ï¼‰ã€æä¾›â€œä¸€é”®é‡æ–°è´­ä¹°â€åŠŸèƒ½ã€‚\n",
      "- **æå‡é€æ˜åº¦**ï¼šæ˜ç¡®å±•ç¤ºè¿è´¹ã€ä¼˜æƒ åˆ¸æŠµæ‰£ã€é¢„è®¡é€è¾¾æ—¶é—´ï¼Œå‡å°‘ç»“ç®—æ—¶çš„â€œæ„å¤–æˆæœ¬â€ã€‚\n",
      "- **å¼ºåŒ–å®¹é”™ä¸å¼•å¯¼**ï¼š  \n",
      "  - æ”¯ä»˜å¤±è´¥æ—¶è‡ªåŠ¨ä¿å­˜è®¢å•ï¼Œå¹¶æä¾›æ¸…æ™°çš„é”™è¯¯åŸå› ä¸è§£å†³å»ºè®®ï¼ˆå¦‚æ›´æ¢æ”¯ä»˜æ–¹å¼ï¼‰ã€‚  \n",
      "  - åœ¨å…³é”®æ­¥éª¤ï¼ˆå¦‚æäº¤è®¢å•å‰ï¼‰å¢åŠ è¿›åº¦æç¤ºæˆ–æ“ä½œç¡®è®¤ï¼Œå‡å°‘è¯¯æ“ä½œå¯¼è‡´çš„æµå¤±ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### 3ï¸âƒ£ **å»ºç«‹æµå¤±é¢„è­¦ä¸æŒ½å›æœºåˆ¶**\n",
      "- **å®æ—¶ç›‘æ§**ï¼šå¯¹åœç•™æ—¶é—´è¿‡é•¿ã€åå¤è¿”å›ä¿®æ”¹çš„è®¢å•è¿›è¡Œä¸»åŠ¨å¹²é¢„ï¼ˆå¦‚å¼¹å‡ºå®¢æœå¸®åŠ©æˆ–ä¼˜æƒ æ¿€åŠ±ï¼‰ã€‚\n",
      "- **æµå¤±åè§¦è¾¾**ï¼šå¯¹æ”¾å¼ƒè®¢å•çš„ç”¨æˆ·ï¼Œé€šè¿‡APPæ¨é€æˆ–çŸ­ä¿¡ï¼Œåœ¨é€‚å½“æ—¶æœºï¼ˆå¦‚1å°æ—¶åï¼‰å‘é€ä¸ªæ€§åŒ–æé†’æˆ–é™æ—¶ä¼˜æƒ ã€‚\n",
      "\n",
      "---\n",
      "\n",
      "### 4ï¸âƒ£ **åç»­éªŒè¯ä¸è¿­ä»£**\n",
      "- **A/Bæµ‹è¯•**ï¼šå¯¹ä¼˜åŒ–æ–¹æ¡ˆï¼ˆå¦‚æ–°ç‰ˆç»“ç®—é¡µï¼‰è¿›è¡Œå°æµé‡æµ‹è¯•ï¼Œå¯¹æ¯”è½¬åŒ–ç‡ä¸æµå¤±ç‡å˜åŒ–ã€‚\n",
      "- **é•¿æœŸè¿½è¸ª**ï¼šå»ºç«‹æ ¸å¿ƒæŒ‡æ ‡çœ‹æ¿ï¼ˆå¦‚è®¢å•å®Œæˆç‡ã€ç”¨æˆ·å¤è´­ç‡ï¼‰ï¼ŒæŒç»­è§‚å¯Ÿä¼˜åŒ–æ•ˆæœã€‚\n",
      "\n",
      "---\n",
      "\n",
      "å¦‚æœéœ€è¦è¿›ä¸€æ­¥åˆ†æï¼Œå¯ä»¥åˆ†äº«å…·ä½“æµå¤±ç¯èŠ‚çš„æ•°æ®æˆ–ç”¨æˆ·åé¦ˆï¼Œæˆ‘ä¼šå¸®æ‚¨ç»†åŒ–è§£å†³æ–¹æ¡ˆã€‚\n",
      "human: ä½ èƒ½ç»™æˆ‘ä¸€äº›ä¼˜åŒ–å»ºè®®å—ï¼Ÿ\n",
      "ai: æ ¹æ®æ‘˜è¦ï¼Œé’ˆå¯¹ç”µå•†APPä¸‹å•æµç¨‹çš„é«˜æµå¤±ç‡ï¼Œå»ºè®®ä»ä»¥ä¸‹å››æ–¹é¢ä¼˜åŒ–ï¼š  \n",
      "1. **ç®€åŒ–æ­¥éª¤**ï¼šåˆå¹¶æˆ–åˆ å‡éå¿…è¦é¡µé¢ï¼ˆå¦‚ç¡®è®¤é¡µäºŒæ¬¡è·³è½¬ï¼‰ï¼Œå°è¯•â€œä¸€é”®ä¸‹å•â€æˆ–è¿›åº¦æ¡ç›´è§‚å±•ç¤ºã€‚  \n",
      "2. **ä¿¡æ¯é€æ˜**ï¼šå®æ—¶å±•ç¤ºè¿è´¹ã€åº“å­˜ã€ä¼˜æƒ åˆ¸æŠµæ‰£ï¼Œé¿å…ç”¨æˆ·ä¸­é€”å› ä¿¡æ¯ä¸æ˜ç¡®æ”¾å¼ƒã€‚  \n",
      "3. **å®¹é”™ä¸å¼•å¯¼**ï¼šæä¾›æ¸…æ™°çš„é”™è¯¯æç¤ºï¼ˆå¦‚åœ°å€æ ¼å¼ä¸å¯¹ï¼‰ã€è‡ªåŠ¨ä¿å­˜è‰ç¨¿ï¼Œå¹¶å¢åŠ â€œå®¢æœæ‚¬æµ®çª—â€å³æ—¶ç­”ç–‘ã€‚  \n",
      "4. **æ•°æ®é©±åŠ¨è¿­ä»£**ï¼šé€šè¿‡åŸ‹ç‚¹åˆ†ææµå¤±èŠ‚ç‚¹ï¼Œç»“åˆç”¨æˆ·è®¿è°ˆå®šä½ç—›ç‚¹ï¼Œç”¨A/Bæµ‹è¯•éªŒè¯æ–¹æ¡ˆï¼ˆä¾‹å¦‚å¯¹æ¯”ä¸¤ç§ä¸‹å•æŒ‰é’®è®¾è®¡ï¼‰ã€‚  \n",
      "éœ€è¦æ›´å…·ä½“çš„æŸç¯èŠ‚å»ºè®®ï¼Œå¯è¿›ä¸€æ­¥è®¨è®ºï¼\n",
      "\n",
      "æœ€ç»ˆå¯¹è¯æ‘˜è¦ï¼šç”¨æˆ·å°ææ˜¯ç”µå•†APPäº§å“ç»ç†ï¼Œæ­£ä¼˜åŒ–ä¸‹å•æµç¨‹ä»¥åº”å¯¹é«˜æµå¤±ç‡ã€‚æ ¸å¿ƒéœ€æ±‚æ˜¯è·å¾—å…·ä½“ã€å¯è½åœ°çš„ä¼˜åŒ–å»ºè®®ï¼Œé‡ç‚¹å…³æ³¨ç®€åŒ–æ­¥éª¤ã€ä¿¡æ¯é€æ˜å’Œå®¹é”™æœºåˆ¶ã€‚\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.chat_history import BaseChatMessageHistory, InMemoryChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# åŠ è½½ç¯å¢ƒå˜é‡ï¼ˆç¡®ä¿.envæ–‡ä»¶ä¸­é…ç½®äº†API_KEYï¼‰\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "BASE_URL = \"https://api.deepseek.com\"\n",
    "\n",
    "# åˆå§‹åŒ–LLMæ¨¡å‹\n",
    "llm = ChatOpenAI(\n",
    "    api_key=API_KEY,\n",
    "    base_url=BASE_URL,\n",
    "    model=\"deepseek-chat\",\n",
    "    temperature=0.3  # é™ä½éšæœºæ€§ï¼Œä¿è¯è¾“å‡ºç¨³å®š\n",
    ")\n",
    "\n",
    "# 1. å®šä¹‰æ‘˜è¦ç”Ÿæˆæç¤ºè¯ï¼ˆç”¨äºå‹ç¼©å¯¹è¯å†å²ï¼‰\n",
    "summary_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ä½ æ˜¯å¯¹è¯æ‘˜è¦åŠ©æ‰‹ï¼Œéœ€ç®€æ´æ€»ç»“ä»¥ä¸‹å¯¹è¯çš„æ ¸å¿ƒä¿¡æ¯ï¼ˆåŒ…å«ç”¨æˆ·èº«ä»½ã€åå¥½ã€å…³é”®é—®é¢˜ç­‰ï¼‰ï¼Œä¸è¶…è¿‡50å­—ã€‚\"),\n",
    "    (\"human\", \"å¯¹è¯å†å²ï¼š{chat_history_text}\\nè¯·ç”Ÿæˆæ‘˜è¦ï¼š\")\n",
    "])\n",
    "\n",
    "# 2. æ„å»ºæ‘˜è¦ç”Ÿæˆé“¾ï¼ˆè¾“å…¥å®Œæ•´å†å²æ–‡æœ¬ï¼Œè¾“å‡ºæ‘˜è¦ï¼‰\n",
    "summary_chain = summary_prompt | llm\n",
    "\n",
    "# 3. å®šä¹‰å¯¹è¯è®°å¿†æç¤ºè¯ï¼ˆæ³¨å…¥æ‘˜è¦è€Œéå®Œæ•´å†å²ï¼‰\n",
    "summary_memory_prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"ä½ æ˜¯å‹å¥½çš„å¯¹è¯åŠ©æ‰‹ï¼Œéœ€åŸºäºå¯¹è¯æ‘˜è¦å›ç­”ç”¨æˆ·é—®é¢˜ï¼Œæ‘˜è¦åŒ…å«æ ¸å¿ƒä¸Šä¸‹æ–‡ä¿¡æ¯ã€‚\"),\n",
    "    (\"system\", \"å¯¹è¯æ‘˜è¦ï¼š{chat_summary}\"),  # æ³¨å…¥æ‘˜è¦\n",
    "    (\"human\", \"{user_input}\")\n",
    "])\n",
    "\n",
    "# 4. æ„å»ºåŸºç¡€å¯¹è¯é“¾ï¼ˆæç¤ºè¯ + LLMï¼‰\n",
    "summary_base_chain = (\n",
    "    RunnablePassthrough.assign(\n",
    "        chat_summary=lambda x: summary_chain.invoke(\n",
    "            {\n",
    "                \"chat_history_text\": \"\\n\".join(\n",
    "                    [f\"{msg.type}: {msg.content}\" for msg in x[\"chat_history\"]]\n",
    "                )\n",
    "            }\n",
    "        ).content\n",
    "    )\n",
    "    | summary_memory_prompt\n",
    "    | llm\n",
    ")\n",
    "\n",
    "# 5. ä¼šè¯å†å²å­˜å‚¨ï¼ˆä¿å­˜å®Œæ•´å†å²ç”¨äºç”Ÿæˆæ‘˜è¦ï¼‰\n",
    "summary_memory_store = {}\n",
    "\n",
    "# 6. å®šä¹‰ä¼šè¯å†å²è·å–å‡½æ•°\n",
    "def get_summary_memory_history(session_id: str) -> BaseChatMessageHistory:\n",
    "    if session_id not in summary_memory_store:\n",
    "        summary_memory_store[session_id] = InMemoryChatMessageHistory()\n",
    "    return summary_memory_store[session_id]\n",
    "\n",
    "# 7. æ„å»ºå¸¦æ‘˜è¦è®°å¿†çš„å¯¹è¯é“¾\n",
    "summary_memory_chain = RunnableWithMessageHistory(\n",
    "    runnable=summary_base_chain,\n",
    "    get_session_history=get_summary_memory_history,\n",
    "    input_messages_key=\"user_input\",\n",
    "    history_messages_key=\"chat_history\"  # ä¼ å…¥å®Œæ•´å†å²ç”¨äºç”Ÿæˆæ‘˜è¦\n",
    ")\n",
    "\n",
    "# æµ‹è¯•å¤šè½®å¯¹è¯ï¼ˆsession_id=user_003ï¼‰\n",
    "config = {\"configurable\": {\"session_id\": \"user_003\"}}\n",
    "\n",
    "# å¤šè½®å¯¹è¯è¾“å…¥\n",
    "inputs = [\n",
    "    \"æˆ‘å«å°æï¼Œæ˜¯ä¸€åäº§å“ç»ç†\",\n",
    "    \"æˆ‘è´Ÿè´£ä¸€æ¬¾ç”µå•†APPçš„è¿­ä»£\",\n",
    "    \"æœ€è¿‘åœ¨ä¼˜åŒ–ç”¨æˆ·ä¸‹å•æµç¨‹\",\n",
    "    \"é‡åˆ°äº†ç”¨æˆ·æµå¤±ç‡é«˜çš„é—®é¢˜\",\n",
    "    \"ä½ èƒ½ç»™æˆ‘ä¸€äº›ä¼˜åŒ–å»ºè®®å—ï¼Ÿ\"\n",
    "]\n",
    "\n",
    "for i, user_input in enumerate(inputs, 1):\n",
    "    response = summary_memory_chain.invoke({\"user_input\": user_input}, config=config)\n",
    "    print(f\"\\nç¬¬{i}è½® - åŠ©æ‰‹å›å¤ï¼š\", response.content)\n",
    "\n",
    "# æŸ¥çœ‹å®Œæ•´å†å²ä¸æœ€ç»ˆæ‘˜è¦\n",
    "history = get_summary_memory_history(\"user_003\")\n",
    "print(\"\\næ‘˜è¦è®°å¿†çš„å®Œæ•´å¯¹è¯å†å²ï¼š\")\n",
    "for msg in history.messages:\n",
    "    print(f\"{msg.type}: {msg.content}\")\n",
    "\n",
    "# å•ç‹¬ç”Ÿæˆæœ€ç»ˆæ‘˜è¦éªŒè¯\n",
    "final_summary = summary_chain.invoke({\n",
    "    \"chat_history_text\": \"\\n\".join([f\"{msg.type}: {msg.content}\" for msg in history.messages])\n",
    "}).content\n",
    "print(f\"\\næœ€ç»ˆå¯¹è¯æ‘˜è¦ï¼š{final_summary}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81b34761",
   "metadata": {},
   "source": [
    "#### 3.2.1.2 å­¦ä¹ æ¡ˆä¾‹ï¼šæŸ¥å¤©æ°”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a3781b07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m[values]\u001b[0m {'messages': [HumanMessage(content='åŒ—äº¬ä»Šå¤©çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ', additional_kwargs={}, response_metadata={}, id='0db9a6fc-3c72-4fcf-ad68-6a15d900806b')]}\n",
      "\u001b[1m[updates]\u001b[0m {'model': {'messages': [AIMessage(content='æˆ‘æ¥å¸®æ‚¨æŸ¥è¯¢åŒ—äº¬ä»Šå¤©çš„å¤©æ°”æƒ…å†µã€‚', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 51, 'prompt_tokens': 300, 'total_tokens': 351, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 256}, 'prompt_cache_hit_tokens': 256, 'prompt_cache_miss_tokens': 44}, 'model_provider': 'openai', 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_eaab8d114b_prod0820_fp8_kvcache', 'id': 'd36afcda-ff41-4696-84e0-e3cbbb7cc1a5', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019c4ab8-efb2-7af3-ab05-01086480cc91-0', tool_calls=[{'name': 'weather_query', 'args': {'city': 'åŒ—äº¬'}, 'id': 'call_00_AfoX4Qmlpu9zShh9rG2rCp4i', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 300, 'output_tokens': 51, 'total_tokens': 351, 'input_token_details': {'cache_read': 256}, 'output_token_details': {}})]}}\n",
      "\u001b[1m[values]\u001b[0m {'messages': [HumanMessage(content='åŒ—äº¬ä»Šå¤©çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ', additional_kwargs={}, response_metadata={}, id='0db9a6fc-3c72-4fcf-ad68-6a15d900806b'), AIMessage(content='æˆ‘æ¥å¸®æ‚¨æŸ¥è¯¢åŒ—äº¬ä»Šå¤©çš„å¤©æ°”æƒ…å†µã€‚', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 51, 'prompt_tokens': 300, 'total_tokens': 351, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 256}, 'prompt_cache_hit_tokens': 256, 'prompt_cache_miss_tokens': 44}, 'model_provider': 'openai', 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_eaab8d114b_prod0820_fp8_kvcache', 'id': 'd36afcda-ff41-4696-84e0-e3cbbb7cc1a5', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019c4ab8-efb2-7af3-ab05-01086480cc91-0', tool_calls=[{'name': 'weather_query', 'args': {'city': 'åŒ—äº¬'}, 'id': 'call_00_AfoX4Qmlpu9zShh9rG2rCp4i', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 300, 'output_tokens': 51, 'total_tokens': 351, 'input_token_details': {'cache_read': 256}, 'output_token_details': {}})]}\n",
      "\u001b[1m[updates]\u001b[0m {'tools': {'messages': [ToolMessage(content='åŒ—äº¬ä»Šæ—¥å¤©æ°”ï¼šæ™´ï¼Œ-2~8â„ƒ', name='weather_query', id='5f220db8-302b-476b-9c1d-d91aa9e9ca59', tool_call_id='call_00_AfoX4Qmlpu9zShh9rG2rCp4i')]}}\n",
      "\u001b[1m[values]\u001b[0m {'messages': [HumanMessage(content='åŒ—äº¬ä»Šå¤©çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ', additional_kwargs={}, response_metadata={}, id='0db9a6fc-3c72-4fcf-ad68-6a15d900806b'), AIMessage(content='æˆ‘æ¥å¸®æ‚¨æŸ¥è¯¢åŒ—äº¬ä»Šå¤©çš„å¤©æ°”æƒ…å†µã€‚', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 51, 'prompt_tokens': 300, 'total_tokens': 351, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 256}, 'prompt_cache_hit_tokens': 256, 'prompt_cache_miss_tokens': 44}, 'model_provider': 'openai', 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_eaab8d114b_prod0820_fp8_kvcache', 'id': 'd36afcda-ff41-4696-84e0-e3cbbb7cc1a5', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019c4ab8-efb2-7af3-ab05-01086480cc91-0', tool_calls=[{'name': 'weather_query', 'args': {'city': 'åŒ—äº¬'}, 'id': 'call_00_AfoX4Qmlpu9zShh9rG2rCp4i', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 300, 'output_tokens': 51, 'total_tokens': 351, 'input_token_details': {'cache_read': 256}, 'output_token_details': {}}), ToolMessage(content='åŒ—äº¬ä»Šæ—¥å¤©æ°”ï¼šæ™´ï¼Œ-2~8â„ƒ', name='weather_query', id='5f220db8-302b-476b-9c1d-d91aa9e9ca59', tool_call_id='call_00_AfoX4Qmlpu9zShh9rG2rCp4i')]}\n",
      "\u001b[1m[updates]\u001b[0m {'model': {'messages': [AIMessage(content='æ ¹æ®æŸ¥è¯¢ç»“æœï¼ŒåŒ—äº¬ä»Šå¤©çš„å¤©æ°”æƒ…å†µå¦‚ä¸‹ï¼š\\n\\n- **å¤©æ°”çŠ¶å†µ**ï¼šæ™´\\n- **æ¸©åº¦èŒƒå›´**ï¼š-2Â°C åˆ° 8Â°C\\n\\nä»Šå¤©åŒ—äº¬å¤©æ°”æ™´æœ—ï¼Œä½†æ°”æ¸©è¾ƒä½ï¼Œæ—©æ™šæ¸©å·®è¾ƒå¤§ã€‚å»ºè®®æ‚¨ï¼š\\n1. ç™½å¤©å¯ä»¥é€‚å½“å¤–å‡ºæ´»åŠ¨ï¼Œäº«å—é˜³å…‰\\n2. æ—©æ™šæ—¶æ®µè¦æ³¨æ„ä¿æš–ï¼Œç‰¹åˆ«æ˜¯æ—©ä¸Šæ¸©åº¦è¾ƒä½\\n3. å»ºè®®ç©¿ç€åšå¤–å¥—æˆ–ç¾½ç»’æœï¼Œæ³¨æ„é˜²å¯’\\n\\nå¦‚æœæ‚¨éœ€è¦äº†è§£æœªæ¥å‡ å¤©çš„å¤©æ°”é¢„æŠ¥ï¼Œè¯·å‘Šè¯‰æˆ‘ï¼', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 102, 'prompt_tokens': 379, 'total_tokens': 481, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 320}, 'prompt_cache_hit_tokens': 320, 'prompt_cache_miss_tokens': 59}, 'model_provider': 'openai', 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_eaab8d114b_prod0820_fp8_kvcache', 'id': '340c9e93-0fa2-4eda-ae34-2d8ae005ec5a', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c4ab8-f9d5-7870-8f00-a3e80d17a5f1-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 379, 'output_tokens': 102, 'total_tokens': 481, 'input_token_details': {'cache_read': 320}, 'output_token_details': {}})]}}\n",
      "\u001b[1m[values]\u001b[0m {'messages': [HumanMessage(content='åŒ—äº¬ä»Šå¤©çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ', additional_kwargs={}, response_metadata={}, id='0db9a6fc-3c72-4fcf-ad68-6a15d900806b'), AIMessage(content='æˆ‘æ¥å¸®æ‚¨æŸ¥è¯¢åŒ—äº¬ä»Šå¤©çš„å¤©æ°”æƒ…å†µã€‚', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 51, 'prompt_tokens': 300, 'total_tokens': 351, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 256}, 'prompt_cache_hit_tokens': 256, 'prompt_cache_miss_tokens': 44}, 'model_provider': 'openai', 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_eaab8d114b_prod0820_fp8_kvcache', 'id': 'd36afcda-ff41-4696-84e0-e3cbbb7cc1a5', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019c4ab8-efb2-7af3-ab05-01086480cc91-0', tool_calls=[{'name': 'weather_query', 'args': {'city': 'åŒ—äº¬'}, 'id': 'call_00_AfoX4Qmlpu9zShh9rG2rCp4i', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 300, 'output_tokens': 51, 'total_tokens': 351, 'input_token_details': {'cache_read': 256}, 'output_token_details': {}}), ToolMessage(content='åŒ—äº¬ä»Šæ—¥å¤©æ°”ï¼šæ™´ï¼Œ-2~8â„ƒ', name='weather_query', id='5f220db8-302b-476b-9c1d-d91aa9e9ca59', tool_call_id='call_00_AfoX4Qmlpu9zShh9rG2rCp4i'), AIMessage(content='æ ¹æ®æŸ¥è¯¢ç»“æœï¼ŒåŒ—äº¬ä»Šå¤©çš„å¤©æ°”æƒ…å†µå¦‚ä¸‹ï¼š\\n\\n- **å¤©æ°”çŠ¶å†µ**ï¼šæ™´\\n- **æ¸©åº¦èŒƒå›´**ï¼š-2Â°C åˆ° 8Â°C\\n\\nä»Šå¤©åŒ—äº¬å¤©æ°”æ™´æœ—ï¼Œä½†æ°”æ¸©è¾ƒä½ï¼Œæ—©æ™šæ¸©å·®è¾ƒå¤§ã€‚å»ºè®®æ‚¨ï¼š\\n1. ç™½å¤©å¯ä»¥é€‚å½“å¤–å‡ºæ´»åŠ¨ï¼Œäº«å—é˜³å…‰\\n2. æ—©æ™šæ—¶æ®µè¦æ³¨æ„ä¿æš–ï¼Œç‰¹åˆ«æ˜¯æ—©ä¸Šæ¸©åº¦è¾ƒä½\\n3. å»ºè®®ç©¿ç€åšå¤–å¥—æˆ–ç¾½ç»’æœï¼Œæ³¨æ„é˜²å¯’\\n\\nå¦‚æœæ‚¨éœ€è¦äº†è§£æœªæ¥å‡ å¤©çš„å¤©æ°”é¢„æŠ¥ï¼Œè¯·å‘Šè¯‰æˆ‘ï¼', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 102, 'prompt_tokens': 379, 'total_tokens': 481, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 320}, 'prompt_cache_hit_tokens': 320, 'prompt_cache_miss_tokens': 59}, 'model_provider': 'openai', 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_eaab8d114b_prod0820_fp8_kvcache', 'id': '340c9e93-0fa2-4eda-ae34-2d8ae005ec5a', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c4ab8-f9d5-7870-8f00-a3e80d17a5f1-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 379, 'output_tokens': 102, 'total_tokens': 481, 'input_token_details': {'cache_read': 320}, 'output_token_details': {}})]}\n",
      "\n",
      "æœ€ç»ˆå›ç­”ï¼š\n",
      "æ ¹æ®æŸ¥è¯¢ç»“æœï¼ŒåŒ—äº¬ä»Šå¤©çš„å¤©æ°”æƒ…å†µå¦‚ä¸‹ï¼š\n",
      "\n",
      "- **å¤©æ°”çŠ¶å†µ**ï¼šæ™´\n",
      "- **æ¸©åº¦èŒƒå›´**ï¼š-2Â°C åˆ° 8Â°C\n",
      "\n",
      "ä»Šå¤©åŒ—äº¬å¤©æ°”æ™´æœ—ï¼Œä½†æ°”æ¸©è¾ƒä½ï¼Œæ—©æ™šæ¸©å·®è¾ƒå¤§ã€‚å»ºè®®æ‚¨ï¼š\n",
      "1. ç™½å¤©å¯ä»¥é€‚å½“å¤–å‡ºæ´»åŠ¨ï¼Œäº«å—é˜³å…‰\n",
      "2. æ—©æ™šæ—¶æ®µè¦æ³¨æ„ä¿æš–ï¼Œç‰¹åˆ«æ˜¯æ—©ä¸Šæ¸©åº¦è¾ƒä½\n",
      "3. å»ºè®®ç©¿ç€åšå¤–å¥—æˆ–ç¾½ç»’æœï¼Œæ³¨æ„é˜²å¯’\n",
      "\n",
      "å¦‚æœæ‚¨éœ€è¦äº†è§£æœªæ¥å‡ å¤©çš„å¤©æ°”é¢„æŠ¥ï¼Œè¯·å‘Šè¯‰æˆ‘ï¼\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# ======================\n",
    "# 1. ç¯å¢ƒ\n",
    "# ======================\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    api_key=API_KEY,\n",
    "    base_url=\"https://api.deepseek.com\",\n",
    "    model=\"deepseek-chat\",\n",
    "    temperature=0.3,\n",
    ")\n",
    "\n",
    "# ======================\n",
    "# 2. å·¥å…·\n",
    "# ======================\n",
    "@tool\n",
    "def weather_query(city: str) -> str:\n",
    "    \"\"\"æŸ¥è¯¢æŒ‡å®šåŸå¸‚å¤©æ°”\"\"\"\n",
    "    weather_data = {\n",
    "        \"åŒ—äº¬\": \"åŒ—äº¬ä»Šæ—¥å¤©æ°”ï¼šæ™´ï¼Œ-2~8â„ƒ\",\n",
    "        \"ä¸Šæµ·\": \"ä¸Šæµ·ä»Šæ—¥å¤©æ°”ï¼šå¤šäº‘ï¼Œ5~12â„ƒ\",\n",
    "        \"å¹¿å·\": \"å¹¿å·ä»Šæ—¥å¤©æ°”ï¼šå°é›¨ï¼Œ18~25â„ƒ\",\n",
    "    }\n",
    "    return weather_data.get(city, f\"æš‚æ—  {city} æ•°æ®\")\n",
    "\n",
    "tools = [weather_query]\n",
    "\n",
    "# ======================\n",
    "# 3. åˆ›å»º Agentï¼ˆå¼€å¯ debugï¼‰\n",
    "# ======================\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=tools,\n",
    "    debug=True,  # ğŸ‘ˆ æ‰“å¼€è¿‡ç¨‹æ‰“å°\n",
    ")\n",
    "\n",
    "# ======================\n",
    "# 4. è¿è¡Œ\n",
    "# ======================\n",
    "response = agent.invoke({\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"åŒ—äº¬ä»Šå¤©çš„å¤©æ°”æ€ä¹ˆæ ·ï¼Ÿ\"}\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\næœ€ç»ˆå›ç­”ï¼š\")\n",
    "print(response[\"messages\"][-1].content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce871ce",
   "metadata": {},
   "source": [
    "#### 3.2.2.2 å­¦ä¹ æ¡ˆä¾‹:æ¸©åº¦å•ä½è½¬æ¢"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44e29d6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m[values]\u001b[0m {'messages': [HumanMessage(content='å°†37æ‘„æ°åº¦è½¬æ¢ä¸ºåæ°åº¦', additional_kwargs={}, response_metadata={}, id='fc5356d0-28b6-4392-b665-5730bd9b7300')]}\n",
      "\u001b[1m[updates]\u001b[0m {'model': {'messages': [AIMessage(content='æˆ‘æ¥å¸®æ‚¨å°†37æ‘„æ°åº¦è½¬æ¢ä¸ºåæ°åº¦ã€‚', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 72, 'prompt_tokens': 358, 'total_tokens': 430, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 192}, 'prompt_cache_hit_tokens': 192, 'prompt_cache_miss_tokens': 166}, 'model_provider': 'openai', 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_eaab8d114b_prod0820_fp8_kvcache', 'id': 'c4af102e-828e-43f3-ac46-35ac06ec3a28', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019c4abb-9922-7463-ab82-ff91418b5c8d-0', tool_calls=[{'name': 'temperature_converter', 'args': {'temperature': 37, 'from_unit': 'celsius'}, 'id': 'call_00_qnglxQECidoucaLpGWLbZaei', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 358, 'output_tokens': 72, 'total_tokens': 430, 'input_token_details': {'cache_read': 192}, 'output_token_details': {}})]}}\n",
      "\u001b[1m[values]\u001b[0m {'messages': [HumanMessage(content='å°†37æ‘„æ°åº¦è½¬æ¢ä¸ºåæ°åº¦', additional_kwargs={}, response_metadata={}, id='fc5356d0-28b6-4392-b665-5730bd9b7300'), AIMessage(content='æˆ‘æ¥å¸®æ‚¨å°†37æ‘„æ°åº¦è½¬æ¢ä¸ºåæ°åº¦ã€‚', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 72, 'prompt_tokens': 358, 'total_tokens': 430, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 192}, 'prompt_cache_hit_tokens': 192, 'prompt_cache_miss_tokens': 166}, 'model_provider': 'openai', 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_eaab8d114b_prod0820_fp8_kvcache', 'id': 'c4af102e-828e-43f3-ac46-35ac06ec3a28', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019c4abb-9922-7463-ab82-ff91418b5c8d-0', tool_calls=[{'name': 'temperature_converter', 'args': {'temperature': 37, 'from_unit': 'celsius'}, 'id': 'call_00_qnglxQECidoucaLpGWLbZaei', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 358, 'output_tokens': 72, 'total_tokens': 430, 'input_token_details': {'cache_read': 192}, 'output_token_details': {}})]}\n",
      "\u001b[1m[updates]\u001b[0m {'tools': {'messages': [ToolMessage(content='37.0æ‘„æ°åº¦ = 98.60åæ°åº¦', name='temperature_converter', id='08f12e37-0269-4a60-86f5-e4d7d9c5d2f3', tool_call_id='call_00_qnglxQECidoucaLpGWLbZaei')]}}\n",
      "\u001b[1m[values]\u001b[0m {'messages': [HumanMessage(content='å°†37æ‘„æ°åº¦è½¬æ¢ä¸ºåæ°åº¦', additional_kwargs={}, response_metadata={}, id='fc5356d0-28b6-4392-b665-5730bd9b7300'), AIMessage(content='æˆ‘æ¥å¸®æ‚¨å°†37æ‘„æ°åº¦è½¬æ¢ä¸ºåæ°åº¦ã€‚', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 72, 'prompt_tokens': 358, 'total_tokens': 430, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 192}, 'prompt_cache_hit_tokens': 192, 'prompt_cache_miss_tokens': 166}, 'model_provider': 'openai', 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_eaab8d114b_prod0820_fp8_kvcache', 'id': 'c4af102e-828e-43f3-ac46-35ac06ec3a28', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019c4abb-9922-7463-ab82-ff91418b5c8d-0', tool_calls=[{'name': 'temperature_converter', 'args': {'temperature': 37, 'from_unit': 'celsius'}, 'id': 'call_00_qnglxQECidoucaLpGWLbZaei', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 358, 'output_tokens': 72, 'total_tokens': 430, 'input_token_details': {'cache_read': 192}, 'output_token_details': {}}), ToolMessage(content='37.0æ‘„æ°åº¦ = 98.60åæ°åº¦', name='temperature_converter', id='08f12e37-0269-4a60-86f5-e4d7d9c5d2f3', tool_call_id='call_00_qnglxQECidoucaLpGWLbZaei')]}\n",
      "\u001b[1m[updates]\u001b[0m {'model': {'messages': [AIMessage(content='37æ‘„æ°åº¦ç­‰äº98.60åæ°åº¦ã€‚', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 459, 'total_tokens': 469, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 384}, 'prompt_cache_hit_tokens': 384, 'prompt_cache_miss_tokens': 75}, 'model_provider': 'openai', 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_eaab8d114b_prod0820_fp8_kvcache', 'id': 'f72ca619-6334-4777-8cf2-bf436bdcfd5f', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c4abb-a4ef-7e83-9a1b-4ded6fd6d921-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 459, 'output_tokens': 10, 'total_tokens': 469, 'input_token_details': {'cache_read': 384}, 'output_token_details': {}})]}}\n",
      "\u001b[1m[values]\u001b[0m {'messages': [HumanMessage(content='å°†37æ‘„æ°åº¦è½¬æ¢ä¸ºåæ°åº¦', additional_kwargs={}, response_metadata={}, id='fc5356d0-28b6-4392-b665-5730bd9b7300'), AIMessage(content='æˆ‘æ¥å¸®æ‚¨å°†37æ‘„æ°åº¦è½¬æ¢ä¸ºåæ°åº¦ã€‚', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 72, 'prompt_tokens': 358, 'total_tokens': 430, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 192}, 'prompt_cache_hit_tokens': 192, 'prompt_cache_miss_tokens': 166}, 'model_provider': 'openai', 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_eaab8d114b_prod0820_fp8_kvcache', 'id': 'c4af102e-828e-43f3-ac46-35ac06ec3a28', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019c4abb-9922-7463-ab82-ff91418b5c8d-0', tool_calls=[{'name': 'temperature_converter', 'args': {'temperature': 37, 'from_unit': 'celsius'}, 'id': 'call_00_qnglxQECidoucaLpGWLbZaei', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 358, 'output_tokens': 72, 'total_tokens': 430, 'input_token_details': {'cache_read': 192}, 'output_token_details': {}}), ToolMessage(content='37.0æ‘„æ°åº¦ = 98.60åæ°åº¦', name='temperature_converter', id='08f12e37-0269-4a60-86f5-e4d7d9c5d2f3', tool_call_id='call_00_qnglxQECidoucaLpGWLbZaei'), AIMessage(content='37æ‘„æ°åº¦ç­‰äº98.60åæ°åº¦ã€‚', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 10, 'prompt_tokens': 459, 'total_tokens': 469, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 384}, 'prompt_cache_hit_tokens': 384, 'prompt_cache_miss_tokens': 75}, 'model_provider': 'openai', 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_eaab8d114b_prod0820_fp8_kvcache', 'id': 'f72ca619-6334-4777-8cf2-bf436bdcfd5f', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c4abb-a4ef-7e83-9a1b-4ded6fd6d921-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 459, 'output_tokens': 10, 'total_tokens': 469, 'input_token_details': {'cache_read': 384}, 'output_token_details': {}})]}\n",
      "\n",
      "æœ€ç»ˆç»“æœï¼š\n",
      "37æ‘„æ°åº¦ç­‰äº98.60åæ°åº¦ã€‚\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_agent # æœ€æ–° 1.x æ¨èå…¥å£\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_core.tools import tool\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# ======================\n",
    "# 1. ç¯å¢ƒå˜é‡\n",
    "# ======================\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "BASE_URL = \"https://api.deepseek.com\"\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    api_key=API_KEY,\n",
    "    base_url=BASE_URL,\n",
    "    model=\"deepseek-chat\",\n",
    "    temperature=0.3,\n",
    ")\n",
    "\n",
    "# ======================\n",
    "# 2. å‚æ•°æ¨¡å‹\n",
    "# ======================\n",
    "class TemperatureConvertInput(BaseModel):\n",
    "    temperature: float = Field(description=\"éœ€è¦è½¬æ¢çš„æ¸©åº¦å€¼ï¼Œä¾‹å¦‚37.0\")\n",
    "    from_unit: str = Field(description=\"åŸå§‹æ¸©åº¦å•ä½ï¼Œåªèƒ½æ˜¯'celsius'ï¼ˆæ‘„æ°åº¦ï¼‰æˆ–'fahrenheit'ï¼ˆåæ°åº¦ï¼‰\")\n",
    "\n",
    "# ======================\n",
    "# 3. è‡ªå®šä¹‰å·¥å…·\n",
    "# ======================\n",
    "@tool(args_schema=TemperatureConvertInput)\n",
    "def temperature_converter(temperature: float, from_unit: str) -> str:\n",
    "    \"\"\"æ¸©åº¦å•ä½è½¬æ¢å·¥å…·\"\"\"\n",
    "    if from_unit not in [\"celsius\", \"fahrenheit\"]:\n",
    "        return f\"é”™è¯¯ï¼šå•ä½'{from_unit}'ä¸åˆæ³•ï¼Œä»…æ”¯æŒ'celsius'æˆ–'fahrenheit'\"\n",
    "    \n",
    "    if from_unit == \"celsius\":\n",
    "        fahrenheit = temperature * 9/5 + 32\n",
    "        return f\"{temperature}æ‘„æ°åº¦ = {fahrenheit:.2f}åæ°åº¦\"\n",
    "    else:\n",
    "        celsius = (temperature - 32) * 5/9\n",
    "        return f\"{temperature}åæ°åº¦ = {celsius:.2f}æ‘„æ°åº¦\"\n",
    "\n",
    "tools = [temperature_converter]\n",
    "\n",
    "# ======================\n",
    "# 4. Promptæ¨¡æ¿ï¼ˆä¿ç•™ agent_scratchpadï¼‰\n",
    "# ======================\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\",\n",
    "     \"ä½ æ˜¯ä¸€åä¸“ä¸šæ¸©åº¦è½¬æ¢åŠ©æ‰‹ï¼Œä»…ä½¿ç”¨TemperatureConverterå·¥å…·å®Œæˆä»»åŠ¡ã€‚\"\n",
    "     \"ä¸¥æ ¼æ ¡éªŒå‚æ•°ï¼Œå·¥å…·è¿”å›ç»“æœåŸæ ·è¾“å‡ºã€‚\"),\n",
    "    (\"human\", \"{input}\"),\n",
    "    MessagesPlaceholder(variable_name=\"agent_scratchpad\"),  # è®°å½•æ€è€ƒå’Œå·¥å…·è°ƒç”¨\n",
    "])\n",
    "\n",
    "# ======================\n",
    "# 5. åˆ›å»º Agent\n",
    "# ======================\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=tools,\n",
    "    debug=True,  # ğŸ‘ˆ æ‰“å¼€è°ƒè¯•ï¼Œæ˜¾ç¤ºæ¨¡å‹è°ƒç”¨è¿‡ç¨‹\n",
    ")\n",
    "\n",
    "# ======================\n",
    "# 6. æ‰§è¡Œä»»åŠ¡\n",
    "# ======================\n",
    "if __name__ == \"__main__\":\n",
    "    # ç¤ºä¾‹è¾“å…¥\n",
    "    query = \"å°†37æ‘„æ°åº¦è½¬æ¢ä¸ºåæ°åº¦\"\n",
    "    \n",
    "    # è°ƒç”¨ agent\n",
    "    response = agent.invoke({\n",
    "        \"messages\": [{\"role\": \"user\", \"content\": query}]\n",
    "    })\n",
    "\n",
    "    # è¾“å‡ºæœ€ç»ˆå›ç­”\n",
    "    print(\"\\næœ€ç»ˆç»“æœï¼š\")\n",
    "    print(response[\"messages\"][-1].content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e80a67f",
   "metadata": {},
   "source": [
    "#### 3.2.3.1 å­¦ä¹ æ¡ˆä¾‹ï¼šåˆ›å»ºæ–‡ä»¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c55c18e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m[values]\u001b[0m {'messages': [HumanMessage(content='è¯·åˆ›å»ºä¸€ä¸ªåä¸º llmè¯—è¯.txt çš„æ–‡ä»¶ï¼Œå¹¶åœ¨æ–‡ä»¶ä¸­å†™å…¥ä¸€é¦–åŸåˆ›ä¸ƒè¨€ç»å¥ï¼Œä¸»é¢˜å›´ç»•ç§‘æŠ€ä¸äººæ–‡çš„èåˆã€‚', additional_kwargs={}, response_metadata={}, id='5d74eb6e-8bd9-4b5e-a155-5ac3f551f15e')]}\n",
      "\u001b[1m[updates]\u001b[0m {'model': {'messages': [AIMessage(content='æˆ‘å°†ä¸ºæ‚¨åˆ›å»ºä¸€ä¸ªåä¸º\"llmè¯—è¯.txt\"çš„æ–‡ä»¶ï¼Œå¹¶å†™å…¥ä¸€é¦–åŸåˆ›çš„ä¸ƒè¨€ç»å¥ã€‚', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 113, 'prompt_tokens': 823, 'total_tokens': 936, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 192}, 'prompt_cache_hit_tokens': 192, 'prompt_cache_miss_tokens': 631}, 'model_provider': 'openai', 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_eaab8d114b_prod0820_fp8_kvcache', 'id': '647c09cf-f6ec-4e6a-8119-d4985bdee6c3', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019c4ac4-5068-7741-b9e3-e04e61e70fb8-0', tool_calls=[{'name': 'write_file', 'args': {'file_path': 'llmè¯—è¯.txt', 'text': 'ã€Šæ™ºè”å¤ä»Šã€‹\\nç¡…åŸºç®—åŠ›ç»‡äº‘é”¦ï¼Œ\\nä»£ç å¦‚è¯—ç»˜å¤ä»Šã€‚\\näººæ–‡ç§‘æŠ€ç›¸è¾‰æ˜ ï¼Œ\\næ™ºèƒ½æ—¶ä»£å…±çŸ¥éŸ³ã€‚'}, 'id': 'call_00_rUHSU9OKqzbzTuK6pJcF4pLO', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 823, 'output_tokens': 113, 'total_tokens': 936, 'input_token_details': {'cache_read': 192}, 'output_token_details': {}})]}}\n",
      "\u001b[1m[values]\u001b[0m {'messages': [HumanMessage(content='è¯·åˆ›å»ºä¸€ä¸ªåä¸º llmè¯—è¯.txt çš„æ–‡ä»¶ï¼Œå¹¶åœ¨æ–‡ä»¶ä¸­å†™å…¥ä¸€é¦–åŸåˆ›ä¸ƒè¨€ç»å¥ï¼Œä¸»é¢˜å›´ç»•ç§‘æŠ€ä¸äººæ–‡çš„èåˆã€‚', additional_kwargs={}, response_metadata={}, id='5d74eb6e-8bd9-4b5e-a155-5ac3f551f15e'), AIMessage(content='æˆ‘å°†ä¸ºæ‚¨åˆ›å»ºä¸€ä¸ªåä¸º\"llmè¯—è¯.txt\"çš„æ–‡ä»¶ï¼Œå¹¶å†™å…¥ä¸€é¦–åŸåˆ›çš„ä¸ƒè¨€ç»å¥ã€‚', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 113, 'prompt_tokens': 823, 'total_tokens': 936, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 192}, 'prompt_cache_hit_tokens': 192, 'prompt_cache_miss_tokens': 631}, 'model_provider': 'openai', 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_eaab8d114b_prod0820_fp8_kvcache', 'id': '647c09cf-f6ec-4e6a-8119-d4985bdee6c3', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019c4ac4-5068-7741-b9e3-e04e61e70fb8-0', tool_calls=[{'name': 'write_file', 'args': {'file_path': 'llmè¯—è¯.txt', 'text': 'ã€Šæ™ºè”å¤ä»Šã€‹\\nç¡…åŸºç®—åŠ›ç»‡äº‘é”¦ï¼Œ\\nä»£ç å¦‚è¯—ç»˜å¤ä»Šã€‚\\näººæ–‡ç§‘æŠ€ç›¸è¾‰æ˜ ï¼Œ\\næ™ºèƒ½æ—¶ä»£å…±çŸ¥éŸ³ã€‚'}, 'id': 'call_00_rUHSU9OKqzbzTuK6pJcF4pLO', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 823, 'output_tokens': 113, 'total_tokens': 936, 'input_token_details': {'cache_read': 192}, 'output_token_details': {}})]}\n",
      "\u001b[1m[updates]\u001b[0m {'tools': {'messages': [ToolMessage(content='File written successfully to llmè¯—è¯.txt.', name='write_file', id='666e0778-3ea6-4211-b747-de65ae4d046c', tool_call_id='call_00_rUHSU9OKqzbzTuK6pJcF4pLO')]}}\n",
      "\u001b[1m[values]\u001b[0m {'messages': [HumanMessage(content='è¯·åˆ›å»ºä¸€ä¸ªåä¸º llmè¯—è¯.txt çš„æ–‡ä»¶ï¼Œå¹¶åœ¨æ–‡ä»¶ä¸­å†™å…¥ä¸€é¦–åŸåˆ›ä¸ƒè¨€ç»å¥ï¼Œä¸»é¢˜å›´ç»•ç§‘æŠ€ä¸äººæ–‡çš„èåˆã€‚', additional_kwargs={}, response_metadata={}, id='5d74eb6e-8bd9-4b5e-a155-5ac3f551f15e'), AIMessage(content='æˆ‘å°†ä¸ºæ‚¨åˆ›å»ºä¸€ä¸ªåä¸º\"llmè¯—è¯.txt\"çš„æ–‡ä»¶ï¼Œå¹¶å†™å…¥ä¸€é¦–åŸåˆ›çš„ä¸ƒè¨€ç»å¥ã€‚', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 113, 'prompt_tokens': 823, 'total_tokens': 936, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 192}, 'prompt_cache_hit_tokens': 192, 'prompt_cache_miss_tokens': 631}, 'model_provider': 'openai', 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_eaab8d114b_prod0820_fp8_kvcache', 'id': '647c09cf-f6ec-4e6a-8119-d4985bdee6c3', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019c4ac4-5068-7741-b9e3-e04e61e70fb8-0', tool_calls=[{'name': 'write_file', 'args': {'file_path': 'llmè¯—è¯.txt', 'text': 'ã€Šæ™ºè”å¤ä»Šã€‹\\nç¡…åŸºç®—åŠ›ç»‡äº‘é”¦ï¼Œ\\nä»£ç å¦‚è¯—ç»˜å¤ä»Šã€‚\\näººæ–‡ç§‘æŠ€ç›¸è¾‰æ˜ ï¼Œ\\næ™ºèƒ½æ—¶ä»£å…±çŸ¥éŸ³ã€‚'}, 'id': 'call_00_rUHSU9OKqzbzTuK6pJcF4pLO', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 823, 'output_tokens': 113, 'total_tokens': 936, 'input_token_details': {'cache_read': 192}, 'output_token_details': {}}), ToolMessage(content='File written successfully to llmè¯—è¯.txt.', name='write_file', id='666e0778-3ea6-4211-b747-de65ae4d046c', tool_call_id='call_00_rUHSU9OKqzbzTuK6pJcF4pLO')]}\n",
      "\u001b[1m[updates]\u001b[0m {'model': {'messages': [AIMessage(content='æ–‡ä»¶å·²æˆåŠŸåˆ›å»ºï¼æˆ‘åœ¨\"llmè¯—è¯.txt\"æ–‡ä»¶ä¸­å†™å…¥äº†ä¸€é¦–åŸåˆ›çš„ä¸ƒè¨€ç»å¥ã€Šæ™ºè”å¤ä»Šã€‹ã€‚\\n\\nè¿™é¦–è¯—çš„ä¸»é¢˜å›´ç»•ç§‘æŠ€ä¸äººæ–‡çš„èåˆï¼š\\n- ç¬¬ä¸€å¥\"ç¡…åŸºç®—åŠ›ç»‡äº‘é”¦\"ï¼šä»¥ç¡…åŸºèŠ¯ç‰‡çš„ç®—åŠ›æ¯”å–»ç»‡é€ äº‘é”¦ï¼Œä½“ç°ç§‘æŠ€ä¹‹ç¾\\n- ç¬¬äºŒå¥\"ä»£ç å¦‚è¯—ç»˜å¤ä»Š\"ï¼šå°†ç¼–ç¨‹ä»£ç æ¯”ä½œè¯—æ­Œï¼Œæç»˜å¤ä»Šæ–‡æ˜\\n- ç¬¬ä¸‰å¥\"äººæ–‡ç§‘æŠ€ç›¸è¾‰æ˜ \"ï¼šç‚¹æ˜äººæ–‡ä¸ç§‘æŠ€ç›¸äº’è¾‰æ˜ çš„ä¸»é¢˜\\n- ç¬¬å››å¥\"æ™ºèƒ½æ—¶ä»£å…±çŸ¥éŸ³\"ï¼šè¡¨è¾¾åœ¨äººå·¥æ™ºèƒ½æ—¶ä»£ï¼Œç§‘æŠ€ä¸äººæ–‡æˆä¸ºçŸ¥éŸ³ä¼™ä¼´\\n\\nè¿™é¦–è¯—ç¬¦åˆä¸ƒè¨€ç»å¥çš„æ ¼å¾‹è¦æ±‚ï¼Œæ¯å¥ä¸ƒä¸ªå­—ï¼Œå…±å››å¥ï¼ŒæŠ¼éŸµå·¥æ•´ï¼Œæ„å¢ƒæ·±è¿œã€‚', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 165, 'prompt_tokens': 961, 'total_tokens': 1126, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 896}, 'prompt_cache_hit_tokens': 896, 'prompt_cache_miss_tokens': 65}, 'model_provider': 'openai', 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_eaab8d114b_prod0820_fp8_kvcache', 'id': 'f8385ba9-d817-43e1-8be8-d09eaf9bfa96', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c4ac4-612a-7cb0-a289-1335c4d39ad9-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 961, 'output_tokens': 165, 'total_tokens': 1126, 'input_token_details': {'cache_read': 896}, 'output_token_details': {}})]}}\n",
      "\u001b[1m[values]\u001b[0m {'messages': [HumanMessage(content='è¯·åˆ›å»ºä¸€ä¸ªåä¸º llmè¯—è¯.txt çš„æ–‡ä»¶ï¼Œå¹¶åœ¨æ–‡ä»¶ä¸­å†™å…¥ä¸€é¦–åŸåˆ›ä¸ƒè¨€ç»å¥ï¼Œä¸»é¢˜å›´ç»•ç§‘æŠ€ä¸äººæ–‡çš„èåˆã€‚', additional_kwargs={}, response_metadata={}, id='5d74eb6e-8bd9-4b5e-a155-5ac3f551f15e'), AIMessage(content='æˆ‘å°†ä¸ºæ‚¨åˆ›å»ºä¸€ä¸ªåä¸º\"llmè¯—è¯.txt\"çš„æ–‡ä»¶ï¼Œå¹¶å†™å…¥ä¸€é¦–åŸåˆ›çš„ä¸ƒè¨€ç»å¥ã€‚', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 113, 'prompt_tokens': 823, 'total_tokens': 936, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 192}, 'prompt_cache_hit_tokens': 192, 'prompt_cache_miss_tokens': 631}, 'model_provider': 'openai', 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_eaab8d114b_prod0820_fp8_kvcache', 'id': '647c09cf-f6ec-4e6a-8119-d4985bdee6c3', 'finish_reason': 'tool_calls', 'logprobs': None}, id='lc_run--019c4ac4-5068-7741-b9e3-e04e61e70fb8-0', tool_calls=[{'name': 'write_file', 'args': {'file_path': 'llmè¯—è¯.txt', 'text': 'ã€Šæ™ºè”å¤ä»Šã€‹\\nç¡…åŸºç®—åŠ›ç»‡äº‘é”¦ï¼Œ\\nä»£ç å¦‚è¯—ç»˜å¤ä»Šã€‚\\näººæ–‡ç§‘æŠ€ç›¸è¾‰æ˜ ï¼Œ\\næ™ºèƒ½æ—¶ä»£å…±çŸ¥éŸ³ã€‚'}, 'id': 'call_00_rUHSU9OKqzbzTuK6pJcF4pLO', 'type': 'tool_call'}], invalid_tool_calls=[], usage_metadata={'input_tokens': 823, 'output_tokens': 113, 'total_tokens': 936, 'input_token_details': {'cache_read': 192}, 'output_token_details': {}}), ToolMessage(content='File written successfully to llmè¯—è¯.txt.', name='write_file', id='666e0778-3ea6-4211-b747-de65ae4d046c', tool_call_id='call_00_rUHSU9OKqzbzTuK6pJcF4pLO'), AIMessage(content='æ–‡ä»¶å·²æˆåŠŸåˆ›å»ºï¼æˆ‘åœ¨\"llmè¯—è¯.txt\"æ–‡ä»¶ä¸­å†™å…¥äº†ä¸€é¦–åŸåˆ›çš„ä¸ƒè¨€ç»å¥ã€Šæ™ºè”å¤ä»Šã€‹ã€‚\\n\\nè¿™é¦–è¯—çš„ä¸»é¢˜å›´ç»•ç§‘æŠ€ä¸äººæ–‡çš„èåˆï¼š\\n- ç¬¬ä¸€å¥\"ç¡…åŸºç®—åŠ›ç»‡äº‘é”¦\"ï¼šä»¥ç¡…åŸºèŠ¯ç‰‡çš„ç®—åŠ›æ¯”å–»ç»‡é€ äº‘é”¦ï¼Œä½“ç°ç§‘æŠ€ä¹‹ç¾\\n- ç¬¬äºŒå¥\"ä»£ç å¦‚è¯—ç»˜å¤ä»Š\"ï¼šå°†ç¼–ç¨‹ä»£ç æ¯”ä½œè¯—æ­Œï¼Œæç»˜å¤ä»Šæ–‡æ˜\\n- ç¬¬ä¸‰å¥\"äººæ–‡ç§‘æŠ€ç›¸è¾‰æ˜ \"ï¼šç‚¹æ˜äººæ–‡ä¸ç§‘æŠ€ç›¸äº’è¾‰æ˜ çš„ä¸»é¢˜\\n- ç¬¬å››å¥\"æ™ºèƒ½æ—¶ä»£å…±çŸ¥éŸ³\"ï¼šè¡¨è¾¾åœ¨äººå·¥æ™ºèƒ½æ—¶ä»£ï¼Œç§‘æŠ€ä¸äººæ–‡æˆä¸ºçŸ¥éŸ³ä¼™ä¼´\\n\\nè¿™é¦–è¯—ç¬¦åˆä¸ƒè¨€ç»å¥çš„æ ¼å¾‹è¦æ±‚ï¼Œæ¯å¥ä¸ƒä¸ªå­—ï¼Œå…±å››å¥ï¼ŒæŠ¼éŸµå·¥æ•´ï¼Œæ„å¢ƒæ·±è¿œã€‚', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 165, 'prompt_tokens': 961, 'total_tokens': 1126, 'completion_tokens_details': None, 'prompt_tokens_details': {'audio_tokens': None, 'cached_tokens': 896}, 'prompt_cache_hit_tokens': 896, 'prompt_cache_miss_tokens': 65}, 'model_provider': 'openai', 'model_name': 'deepseek-chat', 'system_fingerprint': 'fp_eaab8d114b_prod0820_fp8_kvcache', 'id': 'f8385ba9-d817-43e1-8be8-d09eaf9bfa96', 'finish_reason': 'stop', 'logprobs': None}, id='lc_run--019c4ac4-612a-7cb0-a289-1335c4d39ad9-0', tool_calls=[], invalid_tool_calls=[], usage_metadata={'input_tokens': 961, 'output_tokens': 165, 'total_tokens': 1126, 'input_token_details': {'cache_read': 896}, 'output_token_details': {}})]}\n",
      "\n",
      "ä»»åŠ¡æ‰§è¡Œå®Œæˆï¼æ–‡ä»¶å·²å†™å…¥ã€‚\n",
      "Agentæœ€ç»ˆè¾“å‡ºï¼š\n",
      " æ–‡ä»¶å·²æˆåŠŸåˆ›å»ºï¼æˆ‘åœ¨\"llmè¯—è¯.txt\"æ–‡ä»¶ä¸­å†™å…¥äº†ä¸€é¦–åŸåˆ›çš„ä¸ƒè¨€ç»å¥ã€Šæ™ºè”å¤ä»Šã€‹ã€‚\n",
      "\n",
      "è¿™é¦–è¯—çš„ä¸»é¢˜å›´ç»•ç§‘æŠ€ä¸äººæ–‡çš„èåˆï¼š\n",
      "- ç¬¬ä¸€å¥\"ç¡…åŸºç®—åŠ›ç»‡äº‘é”¦\"ï¼šä»¥ç¡…åŸºèŠ¯ç‰‡çš„ç®—åŠ›æ¯”å–»ç»‡é€ äº‘é”¦ï¼Œä½“ç°ç§‘æŠ€ä¹‹ç¾\n",
      "- ç¬¬äºŒå¥\"ä»£ç å¦‚è¯—ç»˜å¤ä»Š\"ï¼šå°†ç¼–ç¨‹ä»£ç æ¯”ä½œè¯—æ­Œï¼Œæç»˜å¤ä»Šæ–‡æ˜\n",
      "- ç¬¬ä¸‰å¥\"äººæ–‡ç§‘æŠ€ç›¸è¾‰æ˜ \"ï¼šç‚¹æ˜äººæ–‡ä¸ç§‘æŠ€ç›¸äº’è¾‰æ˜ çš„ä¸»é¢˜\n",
      "- ç¬¬å››å¥\"æ™ºèƒ½æ—¶ä»£å…±çŸ¥éŸ³\"ï¼šè¡¨è¾¾åœ¨äººå·¥æ™ºèƒ½æ—¶ä»£ï¼Œç§‘æŠ€ä¸äººæ–‡æˆä¸ºçŸ¥éŸ³ä¼™ä¼´\n",
      "\n",
      "è¿™é¦–è¯—ç¬¦åˆä¸ƒè¨€ç»å¥çš„æ ¼å¾‹è¦æ±‚ï¼Œæ¯å¥ä¸ƒä¸ªå­—ï¼Œå…±å››å¥ï¼ŒæŠ¼éŸµå·¥æ•´ï¼Œæ„å¢ƒæ·±è¿œã€‚\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import create_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_community.agent_toolkits import FileManagementToolkit\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# -------------------\n",
    "# 1. åˆå§‹åŒ–ç¯å¢ƒ\n",
    "# -------------------\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "BASE_URL = \"https://api.deepseek.com\"\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    api_key=API_KEY,\n",
    "    base_url=BASE_URL,\n",
    "    model=\"deepseek-chat\",\n",
    "    temperature=0.3,\n",
    ")\n",
    "\n",
    "# -------------------\n",
    "# 2. åˆ›å»ºæ–‡ä»¶ç®¡ç†å·¥å…·\n",
    "# -------------------\n",
    "toolkit = FileManagementToolkit(root_dir=\".\")\n",
    "tools = toolkit.get_tools()\n",
    "\n",
    "# -------------------\n",
    "# 3. åˆ›å»º Agentï¼ˆæœ€æ–°ç‰ˆï¼‰\n",
    "# -------------------\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=tools,\n",
    "    debug=True,  # æ‰“å¼€è°ƒè¯•ï¼Œæ˜¾ç¤ºæ¨¡å‹æ€è€ƒå’Œå·¥å…·è°ƒç”¨è¿‡ç¨‹\n",
    ")\n",
    "\n",
    "# -------------------\n",
    "# 4. æ‰§è¡Œä»»åŠ¡\n",
    "# -------------------\n",
    "response = agent.invoke({\n",
    "    \"messages\": [\n",
    "        {\"role\": \"user\", \"content\": \"è¯·åˆ›å»ºä¸€ä¸ªåä¸º llmè¯—è¯.txt çš„æ–‡ä»¶ï¼Œå¹¶åœ¨æ–‡ä»¶ä¸­å†™å…¥ä¸€é¦–åŸåˆ›ä¸ƒè¨€ç»å¥ï¼Œä¸»é¢˜å›´ç»•ç§‘æŠ€ä¸äººæ–‡çš„èåˆã€‚\"}\n",
    "    ]\n",
    "})\n",
    "\n",
    "print(\"\\nä»»åŠ¡æ‰§è¡Œå®Œæˆï¼æ–‡ä»¶å·²å†™å…¥ã€‚\")\n",
    "print(\"Agentæœ€ç»ˆè¾“å‡ºï¼š\\n\", response[\"messages\"][-1].content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86999cba",
   "metadata": {},
   "source": [
    "### 3.3.1 å®è·µ1ï¼šå¸¦è®°å¿†çš„å¯¹è¯æœºå™¨äºº"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4ffac184",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== çª—å£è®°å¿†æ•°å­¦åŠ©æ‰‹ï¼ˆé¢„è®¾å¯¹è¯ï¼‰ =====\n",
      "\n",
      "ç”¨æˆ·ï¼šä½ å¥½ï¼Œæˆ‘ä»Šå¤©æƒ³é—®ä¸€ä¸‹37æ‘„æ°åº¦æ˜¯å¤šå°‘åæ°åº¦ï¼Ÿ\n",
      "åŠ©æ‰‹ï¼š37æ‘„æ°åº¦æ¢ç®—æˆåæ°åº¦æ˜¯ **98.6åæ°åº¦**ã€‚  \n",
      "å¦‚æœä½ æœ‰å…¶ä»–æ¸©åº¦éœ€è¦æ¢ç®—ï¼Œæˆ–è€…æœ‰å…¶ä»–é—®é¢˜ï¼Œéšæ—¶å‘Šè¯‰æˆ‘ï¼\n",
      "\n",
      "ç”¨æˆ·ï¼šå¦‚æœæŠŠ212åæ°åº¦è½¬æ¢æˆæ‘„æ°åº¦æ˜¯å¤šå°‘ï¼Ÿ\n",
      "åŠ©æ‰‹ï¼š212åæ°åº¦æ¢ç®—æˆæ‘„æ°åº¦æ˜¯ **100æ‘„æ°åº¦**ã€‚  \n",
      "è¿™ä¸ªæ¸©åº¦æ­£å¥½æ˜¯æ°´çš„æ²¸ç‚¹ï¼ˆåœ¨æ ‡å‡†å¤§æ°”å‹ä¸‹ï¼‰ï¼Œæ‰€ä»¥å®ƒæ˜¯ä¸ªå¾ˆå¸¸è§çš„å‚è€ƒå€¼ï¼æœ‰å…¶ä»–é—®é¢˜å¯ä»¥ç»§ç»­é—®æˆ‘å“¦ã€‚\n",
      "\n",
      "ç”¨æˆ·ï¼šå¸®æˆ‘ç®—ä¸€ä¸‹ 15 + 28 Ã— 2\n",
      "åŠ©æ‰‹ï¼šæ ¹æ®æ•°å­¦è¿ç®—é¡ºåºï¼ˆå…ˆä¹˜é™¤ååŠ å‡ï¼‰ï¼Œè®¡ç®—å¦‚ä¸‹ï¼š\n",
      "\n",
      "\\[\n",
      "15 + 28 \\times 2 = 15 + 56 = 71\n",
      "\\]\n",
      "\n",
      "æ‰€ä»¥ç»“æœæ˜¯ **71**ã€‚  \n",
      "æœ‰å…¶ä»–éœ€è¦è®¡ç®—çš„é¢˜ç›®ï¼Œéšæ—¶å‘Šè¯‰æˆ‘ï¼\n",
      "\n",
      "ç”¨æˆ·ï¼šè°¢è°¢ä½ ï¼Œä»Šå¤©çš„æ¸©åº¦çœŸçƒ­å•Š\n",
      "åŠ©æ‰‹ï¼šä¸å®¢æ°”ï¼ç¡®å®ï¼Œæœ€è¿‘å¤©æ°”è¶Šæ¥è¶Šçƒ­äº†ï¼Œè®°å¾—å¤šå–æ°´ã€æ³¨æ„é˜²æš‘é™æ¸©å“¦ï½ ğŸŒ  \n",
      "å¦‚æœè¿˜æœ‰å…¶ä»–é—®é¢˜æˆ–éœ€è¦å¸®å¿™çš„åœ°æ–¹ï¼Œéšæ—¶å‘Šè¯‰æˆ‘ï¼\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_experimental.tools import PythonREPLTool\n",
    "import re\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# -------------------------\n",
    "# 1. åˆå§‹åŒ–ç¯å¢ƒä¸æ¨¡å‹\n",
    "# -------------------------\n",
    "load_dotenv()\n",
    "API_KEY = os.getenv(\"API_KEY\")\n",
    "BASE_URL = \"https://api.deepseek.com\"\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    api_key=API_KEY,\n",
    "    base_url=BASE_URL,\n",
    "    model=\"deepseek-chat\",\n",
    "    temperature=0.3\n",
    ")\n",
    "\n",
    "calc_tool = PythonREPLTool()  # æ•°å­¦è®¡ç®—å·¥å…·\n",
    "WINDOW_SIZE = 2  # çª—å£è®°å¿†è½®æ•°\n",
    "\n",
    "# -------------------------\n",
    "# 2. æç¤ºæ¨¡æ¿\n",
    "# -------------------------\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", f\"\"\"\n",
    "ä½ æ˜¯ä¸€åå‹å¥½çš„ä¸ªäººåŠ©æ‰‹ï¼Œèƒ½è®°ä½æœ€è¿‘{WINDOW_SIZE}è½®å¯¹è¯ã€‚\n",
    "å¦‚æœç”¨æˆ·é—®é¢˜åŒ…å«æ•°å­¦è®¡ç®—ï¼Œè¯·å…ˆè°ƒç”¨è®¡ç®—å·¥å…·ï¼Œå†ç”Ÿæˆè‡ªç„¶è¯­è¨€å›ç­”ã€‚\n",
    "\"\"\"),\n",
    "    MessagesPlaceholder(variable_name=\"chat_history\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])\n",
    "\n",
    "# -------------------------\n",
    "# 3. å·¥å…·è°ƒç”¨é€»è¾‘\n",
    "# -------------------------\n",
    "def judge_and_calc(inputs):\n",
    "    user_input = inputs[\"input\"]\n",
    "    \n",
    "    calc_pattern = r\"(\\+|\\-|\\*|/|Ã—|Ã·|=|è®¡ç®—|æ±‚å’Œ|æ±‚å·®|å¹³æ–¹|ç«‹æ–¹|å¤šå°‘|ç­‰äº)\"\n",
    "    if re.search(calc_pattern, user_input):\n",
    "        # æå–è¡¨è¾¾å¼ï¼ˆç®€åŒ–ç‰ˆï¼‰\n",
    "        expr = re.sub(r\"[^\\d\\+\\-\\*\\/\\(\\)\\.]\", \"\", user_input)\n",
    "        calc_result = calc_tool.run(expr) if expr else \"æœªè¯†åˆ«åˆ°å¯è®¡ç®—çš„è¡¨è¾¾å¼\"\n",
    "        inputs[\"input\"] = f\"ç”¨æˆ·é—®é¢˜ï¼š{user_input}\\nè®¡ç®—ç»“æœï¼š{calc_result}\\nè¯·ç»“åˆè®¡ç®—ç»“æœå›ç­”\"\n",
    "    return inputs\n",
    "\n",
    "# -------------------------\n",
    "# 4. çª—å£è®°å¿†ç®¡ç†\n",
    "# -------------------------\n",
    "window_memory_store = {}\n",
    "\n",
    "def get_window_session_history(session_id: str):\n",
    "    if session_id not in window_memory_store:\n",
    "        window_memory_store[session_id] = InMemoryChatMessageHistory()\n",
    "    history = window_memory_store[session_id]\n",
    "    # ä¿ç•™æœ€è¿‘Nè½®\n",
    "    total = len(history.messages)\n",
    "    if total > 2 * WINDOW_SIZE:\n",
    "        history.messages = history.messages[-2 * WINDOW_SIZE:]\n",
    "    return history\n",
    "\n",
    "# -------------------------\n",
    "# 5. æ„å»ºé“¾\n",
    "# -------------------------\n",
    "chain = (\n",
    "    RunnablePassthrough.assign(chat_history=lambda x: x.get(\"chat_history\", []))\n",
    "    | RunnableLambda(judge_and_calc)\n",
    "    | prompt\n",
    "    | llm\n",
    ")\n",
    "\n",
    "chain_with_memory = RunnableWithMessageHistory(\n",
    "    runnable=chain,\n",
    "    get_session_history=get_window_session_history,\n",
    "    input_messages_key=\"input\",\n",
    "    history_messages_key=\"chat_history\",\n",
    "    output_messages_key=\"output\"\n",
    ")\n",
    "\n",
    "# -------------------------\n",
    "# 6. é¢„è®¾å¯¹è¯åˆ—è¡¨ï¼ˆæ¨¡æ‹Ÿç”¨æˆ·è¾“å…¥ï¼‰\n",
    "# -------------------------\n",
    "predefined_dialogues = [\n",
    "    \"ä½ å¥½ï¼Œæˆ‘ä»Šå¤©æƒ³é—®ä¸€ä¸‹37æ‘„æ°åº¦æ˜¯å¤šå°‘åæ°åº¦ï¼Ÿ\",\n",
    "    \"å¦‚æœæŠŠ212åæ°åº¦è½¬æ¢æˆæ‘„æ°åº¦æ˜¯å¤šå°‘ï¼Ÿ\",\n",
    "    \"å¸®æˆ‘ç®—ä¸€ä¸‹ 15 + 28 Ã— 2\",\n",
    "    \"è°¢è°¢ä½ ï¼Œä»Šå¤©çš„æ¸©åº¦çœŸçƒ­å•Š\"\n",
    "]\n",
    "\n",
    "# -------------------------\n",
    "# 7. æ¨¡æ‹Ÿå¤šè½®å¯¹è¯æ‰§è¡Œ\n",
    "# -------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    session_id = \"student_001\"\n",
    "    print(\"===== çª—å£è®°å¿†æ•°å­¦åŠ©æ‰‹ï¼ˆé¢„è®¾å¯¹è¯ï¼‰ =====\\n\")\n",
    "    \n",
    "    for idx, user_input in enumerate(predefined_dialogues, 1):\n",
    "        print(f\"ç”¨æˆ·ï¼š{user_input}\")\n",
    "        \n",
    "        response = chain_with_memory.invoke(\n",
    "            {\"input\": user_input},\n",
    "            config={\"configurable\": {\"session_id\": session_id}}\n",
    "        )\n",
    "        \n",
    "        print(f\"åŠ©æ‰‹ï¼š{response.content}\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14bf08d",
   "metadata": {},
   "source": [
    "### 3.3.2 å®è·µ2ï¼šå¸¦è®°å¿†çš„æ–‡ä»¶å¤¹æ“ä½œåŠ©æ‰‹"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2466c091",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== ğŸ§  LangChain v1.2 Agent =====\n",
      "\n",
      "ğŸ‘¤ã€ç”¨æˆ·è¾“å…¥ã€‘\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# =========================\n",
    "# 1. åŸºç¡€ä¾èµ–\n",
    "# =========================\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.tools import tool\n",
    "from langchain_core.chat_history import InMemoryChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "from langchain.agents import create_agent\n",
    "\n",
    "from langchain_core.messages import AIMessage, ToolMessage\n",
    "\n",
    "# =========================\n",
    "# 2. æ¨¡å‹\n",
    "# =========================\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    api_key=os.getenv(\"API_KEY\"),\n",
    "    base_url=\"https://api.deepseek.com\",\n",
    "    model=\"deepseek-chat\",\n",
    "    temperature=0.3\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# 3. è®°å¿†\n",
    "# =========================\n",
    "WINDOW_SIZE = 3\n",
    "memory_store = {}\n",
    "\n",
    "def get_session_history(session_id: str):\n",
    "    if session_id not in memory_store:\n",
    "        memory_store[session_id] = InMemoryChatMessageHistory()\n",
    "\n",
    "    history = memory_store[session_id]\n",
    "\n",
    "    if len(history.messages) > 2 * WINDOW_SIZE:\n",
    "        history.messages = history.messages[-2 * WINDOW_SIZE:]\n",
    "\n",
    "    return history\n",
    "\n",
    "# =========================\n",
    "# 4. å·¥å…·\n",
    "# =========================\n",
    "@tool\n",
    "def list_files(path: str = \".\") -> str:\n",
    "    \"\"\"æŸ¥çœ‹æŒ‡å®šç›®å½•ä¸‹çš„æ–‡ä»¶åˆ—è¡¨\"\"\"\n",
    "    if not os.path.exists(path):\n",
    "        return f\"è·¯å¾„ä¸å­˜åœ¨ï¼š{path}\"\n",
    "\n",
    "    items = os.listdir(path)\n",
    "    if not items:\n",
    "        return \"ç›®å½•ä¸ºç©º\"\n",
    "\n",
    "    result = []\n",
    "    for item in items:\n",
    "        full = os.path.join(path, item)\n",
    "        if os.path.isfile(full):\n",
    "            result.append(f\"æ–‡ä»¶ï¼š{item}ï¼ˆ{os.path.getsize(full)} å­—èŠ‚ï¼‰\")\n",
    "        else:\n",
    "            result.append(f\"æ–‡ä»¶å¤¹ï¼š{item}\")\n",
    "\n",
    "    return \"\\n\".join(result)\n",
    "\n",
    "\n",
    "@tool\n",
    "def create_file(path: str, content: str = \"\") -> str:\n",
    "    \"\"\"åˆ›å»ºæ–‡ä»¶å¹¶å†™å…¥å†…å®¹\"\"\"\n",
    "    folder = os.path.dirname(path)\n",
    "    if folder and not os.path.exists(folder):\n",
    "        os.makedirs(folder)\n",
    "\n",
    "    with open(path, \"w\", encoding=\"utf-8\") as f:\n",
    "        f.write(content)\n",
    "\n",
    "    return f\"æ–‡ä»¶å·²åˆ›å»ºï¼š{path}\"\n",
    "\n",
    "tools = [list_files, create_file]\n",
    "\n",
    "# =========================\n",
    "# 5. åˆ›å»º Agent\n",
    "# =========================\n",
    "agent = create_agent(\n",
    "    model=llm,\n",
    "    tools=tools,\n",
    "    system_prompt=\"ä½ æ˜¯ä¸€ä¸ªæ–‡ä»¶æ“ä½œæ™ºèƒ½åŠ©æ‰‹ã€‚\"\n",
    ")\n",
    "\n",
    "agent_with_memory = RunnableWithMessageHistory(\n",
    "    agent,\n",
    "    get_session_history,\n",
    "    input_messages_key=\"messages\",\n",
    "    history_messages_key=\"messages\"\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# 6. CLI\n",
    "# =========================\n",
    "if __name__ == \"__main__\":\n",
    "    session_id = \"tool_agent_demo\"\n",
    "\n",
    "    print(\"===== ğŸ§  LangChain v1.2 Agent =====\")\n",
    "\n",
    "    while True:\n",
    "        user_input = input(\"ä½ ï¼š\")\n",
    "\n",
    "        if user_input in [\"q\", \"quit\", \"é€€å‡º\"]:\n",
    "            print(\"åŠ©æ‰‹ï¼šå†è§ ğŸ‘‹\")\n",
    "            break\n",
    "\n",
    "        # âœ… æ‰“å°ç”¨æˆ·è¾“å…¥\n",
    "        print(\"\\nğŸ‘¤ã€ç”¨æˆ·è¾“å…¥ã€‘\")\n",
    "        print(user_input)\n",
    "\n",
    "        result = agent_with_memory.invoke(\n",
    "            {\n",
    "                \"messages\": [\n",
    "                    {\"role\": \"user\", \"content\": user_input}\n",
    "                ]\n",
    "            },\n",
    "            config={\"configurable\": {\"session_id\": session_id}}\n",
    "        )\n",
    "\n",
    "        messages = result[\"messages\"]\n",
    "\n",
    "        # =====================\n",
    "        # âœ… æ‰“å°å·¥å…·è°ƒç”¨è¿‡ç¨‹\n",
    "        # =====================\n",
    "        print(\"\\nğŸ§ ã€Agentæ‰§è¡Œè¿‡ç¨‹ã€‘\")\n",
    "\n",
    "        for msg in messages:\n",
    "            # ===== AI å†³å®šè°ƒç”¨å·¥å…· =====\n",
    "            if isinstance(msg, AIMessage) and msg.tool_calls:\n",
    "                for call in msg.tool_calls:\n",
    "                    print(\"\\nğŸ”§ AI å†³å®šè°ƒç”¨å·¥å…·\")\n",
    "                    print(\"å·¥å…·åï¼š\", call[\"name\"])\n",
    "                    print(\"å‚æ•°ï¼š\", call[\"args\"])\n",
    "\n",
    "            # ===== å·¥å…·è¿”å›ç»“æœ =====\n",
    "            if isinstance(msg, ToolMessage):\n",
    "                print(\"\\nğŸ“¦ å·¥å…·æ‰§è¡Œç»“æœ\")\n",
    "                print(msg.content)\n",
    "\n",
    "        # =====================\n",
    "        # âœ… æœ€ç»ˆå›ç­”\n",
    "        # =====================\n",
    "        print(\"\\nâœ…ã€æœ€ç»ˆå›ç­”ã€‘\")\n",
    "        print(messages[-1].content)\n",
    "        print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
